<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://blog.bioprinting.site</id>
    <title>Li Zhenzhu, Ph.D</title>
    <updated>2019-06-13T11:53:35.248Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://blog.bioprinting.site"/>
    <link rel="self" href="https://blog.bioprinting.site/atom.xml"/>
    <subtitle>Binzhou Medical University Hospital, Email: timeanddoctor@gmail.com.</subtitle>
    <logo>https://blog.bioprinting.site/images/avatar.png</logo>
    <icon>https://blog.bioprinting.site/favicon.ico</icon>
    <rights>All rights reserved 2019, Li Zhenzhu, Ph.D</rights>
    <entry>
        <title type="html"><![CDATA[PyAutoGui]]></title>
        <id>https://blog.bioprinting.site/post/BI_VpZjOp</id>
        <link href="https://blog.bioprinting.site/post/BI_VpZjOp">
        </link>
        <updated>2019-06-13T11:48:21.000Z</updated>
        <content type="html"><![CDATA[<h1 id="pyautogui">PyAutoGUI</h1>
<p>PyAutoGUI是一个面向人类的跨平台GUI自动化Python模块。用于以编程方式控制鼠标和键盘。</p>
<p><code>pip install pyautogui</code></p>
<p>完整文档可在<a href="https://pyautogui.readthedocs.org/">https://pyautogui.readthedocs.org获得</a></p>
<p>简体中文文档可从<a href="https://muxuezi.github.io/posts/doc-pyautogui.html">https://muxuezi.github.io/posts/doc-pyautogui.html获得</a></p>
<p>源代码可在<a href="https://github.com/asweigart/pyautogui">https://github.com/asweigart/pyautogui获得</a></p>
<h1 id=""><a href="https://github.com/3dprintingdoctor/pyautogui#dependencies"></a>依赖</h1>
<p>PyAutoGUI支持Python 2和3.如果使用pip从PyPI安装PyAutoGUI：</p>
<p>Windows没有依赖项。不需要安装Win32扩展。</p>
<p>OS X需要安装pyobjc-core和pyobjc模块（按此顺序）。</p>
<p>Linux需要安装python3-xlib（或Python 2的python-xlib）模块。</p>
<p>需要安装Pillow，在Linux上，您可能需要安装其他库以确保Pillow的PNG / JPEG正常工作。看到：</p>
<p><code>https://stackoverflow.com/questions/7648200/pip-install-pil-e-tickets-1-no-jpeg-png-support</p>
<p>http://ubuntuforums.org/showthread.php?t=1751455</code></p>
<p>如果您想进行开发并为PyAutoGUI做出贡献，您需要从PyPI安装这些模块：</p>
<ul>
<li>pyscreeze</li>
<li>pymsgbox</li>
<li>pytweening</li>
</ul>
<h1 id="-2"><a href="https://github.com/3dprintingdoctor/pyautogui#example-usage"></a>示例用法</h1>
<h2 id="-3"><a href="https://github.com/3dprintingdoctor/pyautogui#keyboard-and-mouse-control"></a>键盘和鼠标控制</h2>
<pre><code> &gt;&gt; &gt;  进口 pyautogui
 &gt;&gt; &gt;屏幕宽度，screenHeight = pyautogui.size（）
 &gt;&gt; &gt; currentMouseX，currentMouseY = pyautogui.position（）
 &gt;&gt; &gt; pyautogui.moveTo（100，150）
 &gt;&gt; &gt; pyautogui.click（）
 &gt;&gt; &gt; pyautogui.moveRel（无，10）   ＃移动鼠标10个像素向下
&gt;&gt; &gt; pyautogui.doubleClick（）
 &gt;&gt; &gt; pyautogui。moveTo（ 500，500，duration = 2，tween = pyautogui.tweens.easeInOutQuad）   ＃使用补间/缓动功能将鼠标移动超过2秒。
&gt;&gt; &gt; pyautogui.typewrite（'世界，你好！'，间隔= 0.25）   ＃在每个键之间以1/4秒的暂停型
&gt;&gt; &gt; pyautogui.press（' ESC '）
 &gt;&gt; &gt; pyautogui.keyDown（'移'）
 &gt;&gt; &gt; pyautogui.typewrite（['左'， '左'， '左'， '左'， '左'， '左' ]）
&gt;&gt; &gt; pyautogui.keyUp（ '移'）
&gt;&gt; &gt; pyautogui.hotkey（ ' CTRL '， ' Ç '）
</code></pre>
<h2 id="-4"><a href="https://github.com/3dprintingdoctor/pyautogui#display-message-boxes"></a>显示消息框</h2>
<pre><code> &gt;&gt; &gt;  进口 pyautogui
 &gt;&gt; &gt; pyautogui.alert（'这是一个警告框。'）
 ' OK '
&gt;&gt; &gt; pyautogui.confirm（'要我继续吗？'）
 '取消'
&gt;&gt; &gt; pyautogui.confirm（'输入选项。'，buttons = [ ' A '，' B '，' C ' ]）
 'B '
 &gt;&gt;&gt; pyautogui.prompt（“你叫什么名字？”）
 “铝”
&gt;&gt; &gt; pyautogui.password（“请输入密码（文本将被隐藏）”），
 “剑鱼”
</code></pre>
<h2 id="-5"><a href="https://github.com/3dprintingdoctor/pyautogui#screenshot-functions"></a>截图功能</h2>
<p>（PyAutoGUI使用Pillow来处理与图像相关的功能。）</p>
<pre><code> &gt;&gt; &gt;  进口 pyautogui
 &gt;&gt; &gt; IM1 = pyautogui.screenshot（）
 &gt;&gt; &gt; im1.save（' my_screenshot.png '）
 &gt;&gt; &gt; IM2 = pyautogui.screenshot（' my_screenshot2.png '）
</code></pre>
<p>您还可以找到屏幕上图像的位置：</p>
<pre><code> &gt;&gt; &gt;  进口 pyautogui
 &gt;&gt; &gt; button7location = pyautogui.locateOnScreen（' button.png '）＃匹配区域的返回（左，上，宽度，高度）
&gt;&gt; &gt; button7location
（1416，562，50，41）
 &gt;&gt; &gt; buttonx，buttony = pyautogui.center（button7location）
 &gt;&gt; &gt; buttonx，buttony
（1441，582）
 &gt;&gt; &gt; pyautogui.click（buttonx，buttony）  ＃点击其中按钮被发现的中心
</code></pre>
<p>locateCenterOnScreen（）函数返回此匹配区域的中心：</p>
<pre><code> &gt;&gt; &gt;  进口 pyautogui
 &gt;&gt; &gt; buttonx，buttony = pyautogui.locateCenterOnScreen（' button.png '）＃返回（X，Y）的匹配区域的
&gt;&gt; &gt; buttonx，buttony
（1441，582）
 &gt;&gt; &gt; pyautogui.click（buttonx，buttony）  ＃点击其中按钮被发现的中心
</code></pre>
<h2 id="pyautogui让所有gui都自动化">PyAutoGUI——让所有GUI都自动化</h2>
<p>本教程译自大神<a href="http://inventwithpython.com/">Al Sweigart</a>的<a href="https://pyautogui.readthedocs.org/">PyAutoGUI</a>项目，Python自动化工具，更适合处理GUI任务，网页任务推荐：</p>
<ul>
<li><a href="https://selenium-python.readthedocs.org/">Selenium</a>+Firefox记录（Chromedriver和Phantomjs也很给力，Phantomjs虽然是无头浏览器，但有时定位不准），然后用Python写单元测试</li>
<li><a href="http://www.python-requests.org/en/latest/">request</a>处理get/post请求写一堆代码自动化处理，都在后台运行，不用运行浏览器，非常适合处理表单</li>
</ul>
<p>没有<a href="http://www.sikuli.org/">sikuli</a>功能多，但是Python让生活更简单，<a href="http://cn.pycon.org/2015/">人生苦短，Python当歌</a>。</p>
<p>同时推荐一本Python网络数据采集（图灵社区取的名字^_^）的基础书籍<a href="http://shop.oreilly.com/product/0636920034391.do">Ryan Mitchell的《Web Scraping with Python》</a>，可以和PyAutoGUI结合使用。</p>
<p>tl;dr</p>
<p>2015-08-17：输入中文bug没有解决，目前的解决方案是Python 2.X环境下安装<a href="https://github.com/asweigart/pyperclip">pyperclip</a>和pyautogui，用复制粘贴来实现。</p>
<p>In [ ]:</p>
<p>import pyperclip
import pyautogui</p>
<h1 id="pyautogui中文输入需要用粘贴实现">PyAutoGUI中文输入需要用粘贴实现</h1>
<h1 id="python-2版本的pyperclip提供中文复制">Python 2版本的pyperclip提供中文复制</h1>
<p>def paste(foo):
pyperclip.copy(foo)
pyautogui.hotkey('ctrl', 'v')</p>
<p>foo = u'学而时习之'</p>
<h1 id="移动到文本框">移动到文本框</h1>
<p>pyautogui.click(130,30)
paste(foo)</p>
<h2 id="1简介">1.简介</h2>
<h3 id="11-目的">1.1 目的</h3>
<p>PyAutoGUI是一个纯Python的GUI自动化工具，其目的是可以用程序自动控制鼠标和键盘操作，多平台支持（Windows，OS X，Linux）。可以用<code>pip</code>安装，Github上有<a href="https://github.com/asweigart/pyautogui">源代码</a>。</p>
<p>下面的代码让鼠标移到屏幕中央。</p>
<p>In [ ]:</p>
<p>import pyautogui
screenWidth, screenHeight = pyautogui.size()
pyautogui.moveTo(screenWidth / 2, screenHeight / 2)</p>
<p>PyAutoGUI可以模拟鼠标的移动、点击、拖拽，键盘按键输入、按住操作，以及鼠标+键盘的热键同时按住等操作，可以说手能动的都可以。</p>
<h3 id="12-例子">1.2 例子</h3>
<p>In [ ]:</p>
<p>import pyautogui
screenWidth, screenHeight = pyautogui.size()
currentMouseX, currentMouseY = pyautogui.position()
pyautogui.moveTo(100, 150)
pyautogui.click()</p>
<h1 id="鼠标向下移动10像素">鼠标向下移动10像素</h1>
<p>pyautogui.moveRel(None, 10)
pyautogui.doubleClick()</p>
<h1 id="用缓动渐变函数让鼠标2秒后移动到500500位置">用缓动/渐变函数让鼠标2秒后移动到(500,500)位置</h1>
<h1 id="use-tweeningeasing-function-to-move-mouse-over-2-seconds">use tweening/easing function to move mouse over 2 seconds.</h1>
<p>pyautogui.moveTo(1800, 500, duration=2, tween=pyautogui.easeInOutQuad)</p>
<h1 id="在每次输入之间暂停025秒">在每次输入之间暂停0.25秒</h1>
<p>pyautogui.typewrite('Hello world!', interval=0.25)
pyautogui.press('esc')
pyautogui.keyDown('shift')
pyautogui.press(['left', 'left', 'left', 'left', 'left', 'left'])
pyautogui.keyUp('shift')
pyautogui.hotkey('ctrl', 'c')</p>
<p>In [ ]:</p>
<p>distance = 200
while distance &gt; 0:
pyautogui.dragRel(distance, 0, duration=0.5) # 向右
distance -= 5
pyautogui.dragRel(0, distance, duration=0.5) # 向下
pyautogui.draIn gRel(-distance, 0, duration=0.5) # 向左
distance -= 5
pyautogui.dragRel(0, -distance, duration=0.5) # 向上</p>
<h3 id="14-保护措施fail-safes">1.4 保护措施（Fail-Safes）</h3>
<p>就像《魔法师的学徒》(Sorcerer’s Apprentice)会担水的扫帚，可以担水，却无力阻止水漫浴室。你的程序也可能会失控（即使是按照你的意思执行的），那时就需要中断。如果鼠标还在自动操作，就很难在程序窗口关闭它。</p>
<p>为了能够及时中断，PyAutoGUI提供了一个保护措施。当<code>pyautogui.FAILSAFE = True</code>时，如果把鼠标光标在屏幕左上角，PyAutoGUI函数就会产生<code>pyautogui.FailSafeException</code>异常。如果失控了，需要中断PyAutoGUI函数，就把鼠标光标在屏幕左上角。要禁用这个特性，就把<code>FAILSAFE</code>设置成<code>False</code>：</p>
<p>In [ ]:</p>
<p>import pyautogui
pyautogui.FAILSAFE = False</p>
<p>通过把<code>pyautogui.PAUSE</code>设置成<code>float</code>或<code>int</code>时间（秒），可以为所有的PyAutoGUI函数增加延迟。默认延迟时间是0.1秒。在函数循环执行的时候，这样做可以让PyAutoGUI运行的慢一点，非常有用。例如：</p>
<p>In [ ]:</p>
<p>import pyautogui
pyautogui.PAUSE = 2.5
pyautogui.moveTo(100,100); pyautogui.click()</p>
<p>所有的PyAutoGUI函数在延迟完成前都处于阻塞状态（block）。（未来计划增加一个可选的非阻塞模式来调用函数。）</p>
<p><strong>建议<code>PAUSE</code>和<code>FAILSAFE</code>一起使用。</strong></p>
<h2 id="2-安装与依赖">2 安装与依赖</h2>
<p>PyAutoGUI支持Python 2.x和Python 3.x</p>
<ul>
<li>Windows：PyAutoGUI没有任何依赖，因为它用Python的<code>ctypes</code>模块所以不需要<code>pywin32</code><code>pip3 install pyautogui</code></li>
<li>OS X：PyAutoGUI需要<a href="http://pythonhosted.org/pyobjc/install.html">PyObjC</a>运行AppKit和Quartz模块。这个模块在PyPI上的按住顺序是<code>pyobjc-core</code>和<code>pyobjc</code><code>sudo pip3 install pyobjc-core
sudo pip3 install pyobjc
sudo pip3 install pyautogui</code></li>
<li>Linux：PyAutoGUI需要<code>python-xlib</code>（Python 2）、<code>python3-Xlib</code>（Python 3）<code>sudo pip3 install python3-xlib
sudo apt-get scrot
sudo apt-get install python-tk
sudo apt-get install python3-dev
sudo pip3 install pyautogui</code></li>
</ul>
<h3 id="3速查表小抄cheat-sheet">3.速查表（小抄，Cheat Sheet）</h3>
<h4 id="31-常用函数">3.1 常用函数</h4>
<p>In [ ]:</p>
<p>import pyautogui</p>
<h1 id="当前鼠标的坐标">当前鼠标的坐标</h1>
<p>pyautogui.position()</p>
<p>Out[ ]:</p>
<p>(123, 372)</p>
<p>In [ ]:</p>
<h1 id="当前屏幕的分辨率宽度和高度">当前屏幕的分辨率（宽度和高度）</h1>
<p>pyautogui.size()</p>
<p>Out[ ]:</p>
<p>(1920, 1080)</p>
<p>In [ ]:</p>
<h1 id="xy是否在屏幕上">(x,y)是否在屏幕上</h1>
<p>x, y = 122, 244
pyautogui.onScreen(x, y)</p>
<p>Out[ ]:</p>
<p>True</p>
<h4 id="32-保护措施">3.2 保护措施</h4>
<p>PyAutoGUI函数增加延迟为2.5秒：</p>
<p>In [ ]:</p>
<p>import pyautogui
pyautogui.PAUSE = 2.5</p>
<p>当pyautogui.FAILSAFE = True时，如果把鼠标光标在屏幕左上角，PyAutoGUI函数就会产生pyautogui.FailSafeException异常。</p>
<p>In [ ]:</p>
<p>import pyautogui
pyautogui.FAILSAFE = True</p>
<h4 id="33-鼠标函数">3.3 鼠标函数</h4>
<p>坐标系的原点是左上角。X轴（水平）坐标向右增大，Y轴（竖直）坐标向下增大。</p>
<p>In [ ]:</p>
<p>num_seconds = 1.2</p>
<h1 id="用num_seconds秒的时间把光标移动到x-y位置">用num_seconds秒的时间把光标移动到(x, y)位置</h1>
<p>pyautogui.moveTo(x, y, duration=num_seconds)</p>
<h1 id="用num_seconds秒的时间把光标的x轴水平坐标移动xoffset">用num_seconds秒的时间把光标的X轴（水平）坐标移动xOffset，</h1>
<h1 id="y轴竖直坐标向下移动yoffset">Y轴（竖直）坐标向下移动yOffset。</h1>
<p>xOffset, yOffset = 50, 100
pyautogui.moveRel(xOffset, yOffset, duration=num_seconds)</p>
<p><code>click()</code>函数就是让鼠标点击，默认是单击左键，参数可以设置：</p>
<p>In [ ]:</p>
<p>pyautogui.click(x=moveToX, y=moveToY, clicks=num_of_clicks, interval=secs_between_clicks, button='left')</p>
<p>其中，<code>button</code>属性可以设置成<code>left</code>，<code>middle</code>和<code>right</code>。</p>
<p>所有的点击都可以用这个函数，不过下面的函数可读性更好：</p>
<p>In [ ]:</p>
<p>pyautogui.rightClick(x=moveToX, y=moveToY)
pyautogui.middleClick(x=moveToX, y=moveToY)
pyautogui.doubleClick(x=moveToX, y=moveToY)
pyautogui.tripleClick(x=moveToX, y=moveToY)</p>
<p><code>scroll</code>函数控制鼠标滚轮的滚动，<code>amount_to_scroll</code>参数表示滚动的格数。正数则页面向上滚动，负数则向下滚动：</p>
<p>In [ ]:</p>
<p>pyautogui.scroll(clicks=amount_to_scroll, x=moveToX, y=moveToY)</p>
<p>每个按键按下和松开两个事件可以分开处理：</p>
<p>In [ ]:</p>
<p>pyautogui.mouseDown(x=moveToX, y=moveToY, button='left')
pyautogui.mouseUp(x=moveToX, y=moveToY, button='left')</p>
<h4 id="34-键盘函数">3.4 键盘函数</h4>
<p>键盘上可以按的键都可以调用：</p>
<p>In [ ]:</p>
<h1 id="每次键入的时间间隔">每次键入的时间间隔</h1>
<p>secs_between_keys = 0.1
pyautogui.typewrite('Hello world!\n', interval=secs_between_keys)</p>
<p>多个键也可以：</p>
<p>In [ ]:</p>
<p>pyautogui.typewrite(['a', 'b', 'c', 'left', 'backspace', 'enter', 'f1'], interval=secs_between_keys)</p>
<p>按键名称列表：</p>
<p>In [ ]:</p>
<p>pyautogui.KEYBOARD_KEYS[:10]</p>
<p>Out[ ]:</p>
<p>['\t', '\n', '\r', ' ', '!', '&quot;', '#', '$', '%', '&amp;']</p>
<p>键盘的一些热键像<code>Ctrl-S</code>或<code>Ctrl-Shift-1</code>都可以用<code>hotkey()</code>函数来实现：</p>
<p>In [ ]:</p>
<p>pyautogui.hotkey('ctrl', 'a') # 全选
pyautogui.hotkey('ctrl', 'c') # 复制
pyautogui.hotkey('ctrl', 'v') # 粘贴</p>
<p>每个按键的按下和松开也可以单独调用：</p>
<p>In [ ]:</p>
<p>pyautogui.keyDown(key_name)
pyautogui.keyUp(key_name)</p>
<h4 id="35-消息弹窗函数">3.5 消息弹窗函数</h4>
<p>如果你需要消息弹窗，通过单击OK暂停程序，或者向用户显示一些信息，消息弹窗函数就会有类似JavaScript的功能：</p>
<p>In [ ]:</p>
<p>pyautogui.alert('这个消息弹窗是文字+OK按钮')
pyautogui.confirm('这个消息弹窗是文字+OK+Cancel按钮')
pyautogui.prompt('这个消息弹窗是让用户输入字符串，单击OK')</p>
<p>Out[ ]:</p>
<p>''</p>
<p>在<code>prompt()</code>函数中，如果用户什么都不输入，就会返回<code>None</code>。</p>
<h4 id="36-截屏函数">3.6 截屏函数</h4>
<p>PyAutoGUI用Pillow/PIL库实现图片相关的识别和操作。</p>
<p>在Linux里面，你必须执行<code>sudo apt-get install scrot</code>来使用截屏特性。</p>
<p>In [ ]:</p>
<h1 id="返回一个pillowpil的image对象">返回一个Pillow/PIL的Image对象</h1>
<p>pyautogui.screenshot()
pyautogui.screenshot('foo.png')</p>
<p>如果你有一个图片文件想在上面做点击操作，你可以用<code>locateOnScreen()</code>函数来定位。</p>
<p>In [ ]:</p>
<h1 id="返回最左x坐标最顶y坐标宽度高度">返回(最左x坐标，最顶y坐标，宽度，高度)</h1>
<p>pyautogui.locateOnScreen('pyautogui/looks.png')</p>
<p>Out[ ]:</p>
<p>(0, 1040, 48, 40)</p>
<p><code>locateAllOnScreen()</code>函数会寻找所有相似图片，返回一个生成器：</p>
<p>In [ ]:</p>
<p>for i in pyautogui.locateAllOnScreen('pyautogui/looks.png'):
print(i)</p>
<p>(0, 1040, 48, 40)</p>
<p>In [ ]:</p>
<p>list(pyautogui.locateAllOnScreen('pyautogui/looks.png'))</p>
<p>Out[ ]:</p>
<p>[(0, 1040, 48, 40)]</p>
<p><code>locateCenterOnScreen()</code>函数会返回图片在屏幕上的中心XY轴坐标值：</p>
<p>In [ ]:</p>
<p>pyautogui.locateCenterOnScreen('pyautogui/looks.png')</p>
<p>Out[ ]:</p>
<p>(24, 1060)</p>
<p>如果没找到图片会返回<code>None</code>。</p>
<blockquote>
<p>定位比较慢，一般得用1~2秒</p>
</blockquote>
<h2 id="4-常用函数">4 常用函数</h2>
<ul>
<li><code>position()</code>：返回整数元组(x, y)，分别表示鼠标光标所在位置的XY轴坐标</li>
<li><code>size()</code>：返回显示器的尺寸整数元组(x, y)。未来将加入多屏支持</li>
</ul>
<h2 id="5-鼠标控制函数">5 鼠标控制函数</h2>
<h3 id="51-屏幕与鼠标位置">5.1 屏幕与鼠标位置</h3>
<p>屏幕位置使用X和Y轴的笛卡尔坐标系。原点<code>(0,0)</code>在左上角，分别向右、向下增大。</p>
<p>如果屏幕像素是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1920</mn><mo>×</mo><mn>1080</mn></mrow><annotation encoding="application/x-tex">1920 \times 1080</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">9</span><span class="mord">2</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">8</span><span class="mord">0</span></span></span></span>，那么右下角的坐标是<code>(1919, 1079)</code>。</p>
<p>分辨率大小可以通过<code>size()</code>函数返回整数元组。光标的位置用<code>position()</code>返回。例如：</p>
<p>In [ ]:</p>
<p>pyautogui.size()</p>
<p>Out[ ]:</p>
<p>(1920, 1080)</p>
<p>In [ ]:</p>
<p>pyautogui.position()</p>
<p>Out[ ]:</p>
<p>(272, 688)</p>
<p>下面是Python 3版本的光标位置记录程序：</p>
<p>In [ ]:</p>
<h1 id="python-3">! python 3</h1>
<p>import pyautogui
print('Press Ctrl-C to quit')
try:
while True:
x, y = pyautogui.position()
positionStr = 'X: {} Y: {}'.format(*[str(x).rjust(4) for x in [x, y]])
print(positionStr, end='')
print('\b' * len(positionStr), end='', flush=True)
except KeyboardInterrupt:
print('\n')</p>
<p>Python 2版本是：</p>
<p>In [ ]:</p>
<h1 id="python">! python</h1>
<p>import pyautogui, sys
print('Press Ctrl-C to quit.')
try:
while True:
x, y = pyautogui.position()
positionStr = 'X: ' + str(x).rjust(4) + ' Y: ' + str(y).rjust(4)
print positionStr,
print '\b' * (len(positionStr) + 2),
sys.stdout.flush()
except KeyboardInterrupt:
print '\n'</p>
<p>要检查XY坐标是否在屏幕上，需要用<code>onScreen()</code>函数来检验，如果在屏幕上返回<code>True</code>：</p>
<p>In [ ]:</p>
<p>import pyautogui
pyautogui.onScreen(0, 0)</p>
<p>Out[ ]:</p>
<p>True</p>
<p>In [ ]:</p>
<p>pyautogui.onScreen(0, -1)</p>
<p>Out[ ]:</p>
<p>False</p>
<p>In [ ]:</p>
<p>pyautogui.onScreen(0, 2080)</p>
<p>Out[ ]:</p>
<p>False</p>
<p>In [ ]:</p>
<p>pyautogui.onScreen(1920, 1080)</p>
<p>Out[ ]:</p>
<p>False</p>
<p>In [ ]:</p>
<p>pyautogui.onScreen(1919, 1079)</p>
<p>Out[ ]:</p>
<p>True</p>
<h3 id="52-鼠标行为">5.2 鼠标行为</h3>
<p><code>moveTo()</code>函数会把鼠标光标移动到指定的XY轴坐标处。如果传入<code>None</code>值，则表示使用当前光标的对象轴坐标值。</p>
<p>In [ ]:</p>
<p>pyautogui.moveTo(100, 200)     # 光标移动到(100, 200)位置
pyautogui.moveTo(None, 500)   # 光标移动到(100, 500)位置
pyautogui.moveTo(600, None)   # 光标移动到(600, 500)位置</p>
<p>一般鼠标光标都是瞬间移动到指定的位置，如果你想让鼠标移动的慢点，可以设置持续时间：</p>
<p>In [ ]:</p>
<p>pyautogui.moveTo(100, 200, duration=2)     # 用2秒把光标移动到(100, 200)位置</p>
<p>默认的持续时间<code>pyautogui.MINIMUM_DURATION</code>是0.1秒，如果你设置的时间比默认值还短，那么就会瞬间执行。</p>
<p>如果你想让光标以当前位置为原点，进行相对移动，就用<code>pyautogui.moveRel()</code>函数。例如：</p>
<p>In [ ]:</p>
<p>pyautogui.moveTo(100, 200) #把光标移动到(100, 200)位置
pyautogui.moveRel(0, 50)   #向下移动50
pyautogui.moveRel(30, 0, 2)   #向右移动30
pyautogui.moveRel(30, None)   #向右移动30</p>
<h3 id="53-鼠标拖拽">5.3 鼠标拖拽</h3>
<p>PyAutoGUI的<code>dragTo()</code>和<code>dragRel()</code>函数与<code>moveTo()</code>和<code>moveRel()</code>函数类似。另外，他们有一个<code>button</code>参数可以设置成<code>left</code>，<code>middle</code>和<code>right</code>三个键。例如：</p>
<p>In [ ]:</p>
<h1 id="按住鼠标左键把鼠标拖拽到100-200位置">按住鼠标左键，把鼠标拖拽到(100, 200)位置</h1>
<p>pyautogui.dragTo(100, 200, button='left')</p>
<h1 id="按住鼠标左键用2秒钟把鼠标拖拽到300-400位置">按住鼠标左键，用2秒钟把鼠标拖拽到(300, 400)位置</h1>
<p>pyautogui.dragTo(300, 400, 2, button='left')</p>
<h1 id="按住鼠标右键用2秒钟把鼠标拖拽到300位置">按住鼠标右键，用2秒钟把鼠标拖拽到(30,0)位置</h1>
<p>pyautogui.dragTo(30, 0, 2, button='right')</p>
<h3 id="54-缓动渐变tween-easing函数">5.4 缓动/渐变（Tween / Easing）函数</h3>
<p>缓动/渐变函数的作用是让光标的移动更炫。如果你不需要用到的话，你可以忽略这些。</p>
<p>缓动/渐变函数可以改变光标移动过程的速度和方向。通常鼠标是匀速直线运动，这就是线性缓动/渐变函数。PyAutoGUI有30种缓动/渐变函数，可以通过<code>pyautogui.ease*?</code>查看。其中，<code>pyautogui.easeInQuad()</code>函数可以用于<code>moveTo()</code>，<code>moveRel()</code>，<code>dragTo()</code>和<code>dragRel()</code>函数，光标移动呈现先慢后快的效果，整个过程的时间还是和原来一样。而<code>pyautogui.easeOutQuad</code>函数的效果相反：光标开始移动很快，然后慢慢减速。<code>pyautogui.easeOutElastic</code>是弹簧效果，首先越过终点，然后再反弹回来。例如：</p>
<p>In [ ]:</p>
<h1 id="开始很慢不断加速">开始很慢，不断加速</h1>
<p>pyautogui.moveTo(100, 100, 2, pyautogui.easeInQuad)</p>
<h1 id="开始很快不断减速">开始很快，不断减速</h1>
<p>pyautogui.moveTo(100, 100, 2, pyautogui.easeOutQuad)</p>
<h1 id="开始和结束都快中间比较慢">开始和结束都快，中间比较慢</h1>
<p>pyautogui.moveTo(100, 100, 2, pyautogui.easeInOutQuad)</p>
<h1 id="一步一徘徊前进">一步一徘徊前进</h1>
<p>pyautogui.moveTo(100, 100, 2, pyautogui.easeInBounce)</p>
<h1 id="徘徊幅度更大甚至超过起点和终点">徘徊幅度更大，甚至超过起点和终点</h1>
<p>pyautogui.moveTo(100, 100, 2, pyautogui.easeInElastic)</p>
<p>这些效果函数是模仿Al Sweigart的<a href="https://github.com/asweigart/pytweening">PyTweening</a>模块，可以直接使用，不需要额外安装。</p>
<p>如果你想创建自己的效果，也可以定义一个函数，其参数是(0.0,1.0)，表示起点和终点，返回值是介于[0.0,1.0]之间的数。</p>
<h3 id="55-鼠标单击">5.5 鼠标单击</h3>
<p><code>click()</code>函数模拟单击鼠标左键一次的行为。例如：</p>
<p>In [ ]:</p>
<p>pyautogui.click()</p>
<p>如果单机之前要先移动，可以把目标的XY坐标值传入函数：</p>
<p>In [ ]:</p>
<h1 id="先移动到100-200再单击">先移动到(100, 200)再单击</h1>
<p>pyautogui.click(x=100, y=200, duration=2)</p>
<p>可以通过<code>button</code>参数设置<code>left</code>，<code>middle</code>和<code>right</code>三个键。例如：</p>
<p>In [ ]:</p>
<p>pyautogui.click(button='right')</p>
<p>要做多次单击可以设置<code>clicks</code>参数，还有<code>interval</code>参数可以设置每次单击之间的时间间隔。例如：</p>
<p>In [ ]:</p>
<h1 id="双击左键">双击左键</h1>
<p>pyautogui.click(clicks=2)</p>
<h1 id="两次单击之间停留025秒">两次单击之间停留0.25秒</h1>
<p>pyautogui.click(clicks=2, interval=0.25)</p>
<h1 id="三击右键">三击右键</h1>
<p>pyautogui.click(button='right', clicks=2, interval=0.25)</p>
<p>为了操作方便，PyAutoGUI提供了<code>doubleClick()</code>，<code>tripleClick()</code>和<code>rightClick()</code>来实现双击、三击和右击操作。</p>
<h3 id="56-鼠标按下和松开函数">5.6 鼠标按下和松开函数</h3>
<p><code>mouseDown()</code>和<code>mouseUp()</code>函数可以实现鼠标按下和鼠标松开的操作。两者参数相同，有<code>x</code>，<code>y</code>和<code>button</code>。例如：</p>
<p>In [ ]:</p>
<h1 id="鼠标左键按下再松开">鼠标左键按下再松开</h1>
<p>pyautogui.mouseDown(); pyautogui.mouseUp()</p>
<h1 id="按下鼠标右键">按下鼠标右键</h1>
<p>pyautogui.mouseDown(button='right')</p>
<h1 id="移动到100-200位置然后松开鼠标右键">移动到(100, 200)位置，然后松开鼠标右键</h1>
<p>pyautogui.mouseUp(button='right', x=100, y=200)</p>
<h3 id="57-滚轮滚动函数">5.7 滚轮滚动函数</h3>
<p>鼠标滚轮滚动可以用<code>scroll()</code>函数和<code>clicks</code>次数参数来模拟。不同平台上的<code>clicks</code>次数不太一样。还有<code>x</code>和<code>y</code>参数可以在滚动之前定位到(x, y)位置。例如：</p>
<p>In [ ]:</p>
<h1 id="向上滚动10格">向上滚动10格</h1>
<p>pyautogui.scroll(10)</p>
<h1 id="向下滚动10格">向下滚动10格</h1>
<p>pyautogui.scroll(-10)</p>
<h1 id="移动到100-100位置再向上滚动10格">移动到(100, 100)位置再向上滚动10格</h1>
<p>pyautogui.scroll(10, x=100, y=100)</p>
<p>在OS X和Linux平台上，PyAutoGUI还可以用<code>hscroll()</code>实现水平滚动。例如：</p>
<p>In [ ]:</p>
<h1 id="向右滚动10格">向右滚动10格</h1>
<p>pyautogui.hscroll(10)</p>
<h1 id="向左滚动10格">向左滚动10格</h1>
<p>pyautogui.hscroll(-10)</p>
<p><code>scroll()</code>函数是<code>vscroll()</code>的一个包装（<code>wrapper</code>），执行竖直滚动。</p>
<h3 id="6-键盘控制函数">6 键盘控制函数</h3>
<h3 id="61-typewrite输入函数">6.1 <code>typewrite()</code>输入函数</h3>
<p>键盘控制的主要函数就是<code>typewrite()</code>。这个函数可以实现字符输入。要在两次输入间增加时间间隔，可以用<code>interval</code>参数。例如：</p>
<p>In [ ]:</p>
<h1 id="输入hello-world">输入Hello world!</h1>
<p>pyautogui.typewrite('Hello world!')</p>
<h1 id="每次输入间隔025秒输入hello-world">每次输入间隔0.25秒，输入Hello world!</h1>
<p>pyautogui.typewrite('Hello world!', interval=0.25)</p>
<p><code>typewrite()</code>函数只能用于单个字符键，不能按SHITF和F1这些功能键。</p>
<h3 id="62-presskeydown和keyup函数">6.2 <code>press()</code>，<code>keyDown()</code>和<code>keyUp()</code>函数</h3>
<p>要按那些功能键，可以用<code>press()</code>函数把<code>pyautogui.KEYBOARD_KEYS</code>里面按键对应的字符串输入进去。例如：</p>
<p>In [ ]:</p>
<h1 id="enter键">ENTER键</h1>
<p>pyautogui.press('enter')</p>
<h1 id="f1键">F1键</h1>
<p>pyautogui.press('f1')</p>
<h1 id="左方向键">左方向键</h1>
<p>pyautogui.press('left')</p>
<p><code>press()</code>函数其实是<code>keyDown()</code>和<code>keyUp()</code>函数的包装，模拟的按下然后松开两个动作。这两个函数可以单独调用。例如，按下<code>shift</code>键的同时按3次左方向键：</p>
<p>In [ ]:</p>
<h1 id="按下shift键">按下<code>shift</code>键</h1>
<p>pyautogui.keyDown('shift')
pyautogui.press('left')
pyautogui.press('left')
pyautogui.press('left')</p>
<h1 id="松开shift键">松开<code>shift</code>键</h1>
<p>pyautogui.keyUp('shift')</p>
<p>和<code>typewrite()</code>函数一样，可以用数组把一组键传入<code>press()</code>。例如：</p>
<p>In [ ]:</p>
<p>pyautogui.press(['left', 'left', 'left'])</p>
<h3 id="63-hotkey函数">6.3 <code>hotkey()</code>函数</h3>
<p>为了更高效的输入热键，PyAutoGUI提供了<code>hotkey()</code>函数来绑定若干按键：</p>
<p>In [ ]:</p>
<p>pyautogui.hotkey('ctrl', 'shift', 'ese')</p>
<p>等价于：</p>
<p>In [ ]:</p>
<p>pyautogui.keyDown('ctrl')
pyautogui.keyDown('shift')
pyautogui.keyDown('esc')
pyautogui.keyUp('esc')
pyautogui.keyUp('shift')
pyautogui.keyUp('ctrl')</p>
<h3 id="64-keyboard_keys">6.4 KEYBOARD_KEYS</h3>
<p>下面就是<code>press()</code>，<code>keyDown()</code>，<code>keyUp()</code>和<code>hotkey()</code>函数可以输入的按键名称：</p>
<p>In [ ]:</p>
<p>print(pyautogui.KEYBOARD_KEYS)</p>
<p>['\t', '\n', '\r', ' ', '!', '&quot;', '#', '$', '%', '&amp;', &quot;'&quot;, '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '&lt;', '=', '&gt;', '?', '@', '[', '\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', 'accept', 'add', 'alt', 'altleft', 'altright', 'apps', 'backspace', 'browserback', 'browserfavorites', 'browserforward', 'browserhome', 'browserrefresh', 'browsersearch', 'browserstop', 'capslock', 'clear', 'convert', 'ctrl', 'ctrlleft', 'ctrlright', 'decimal', 'del', 'delete', 'divide', 'down', 'end', 'enter', 'esc', 'escape', 'execute', 'f1', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f2', 'f20', 'f21', 'f22', 'f23', 'f24', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'final', 'fn', 'hanguel', 'hangul', 'hanja', 'help', 'home', 'insert', 'junja', 'kana', 'kanji', 'launchapp1', 'launchapp2', 'launchmail', 'launchmediaselect', 'left', 'modechange', 'multiply', 'nexttrack', 'nonconvert', 'num0', 'num1', 'num2', 'num3', 'num4', 'num5', 'num6', 'num7', 'num8', 'num9', 'numlock', 'pagedown', 'pageup', 'pause', 'pgdn', 'pgup', 'playpause', 'prevtrack', 'print', 'printscreen', 'prntscrn', 'prtsc', 'prtscr', 'return', 'right', 'scrolllock', 'select', 'separator', 'shift', 'shiftleft', 'shiftright', 'sleep', 'stop', 'subtract', 'tab', 'up', 'volumedown', 'volumemute', 'volumeup', 'win', 'winleft', 'winright', 'yen', 'command', 'option', 'optionleft', 'optionright']</p>
<h3 id="7-消息弹窗函数">7 消息弹窗函数</h3>
<p>PyAutoGUI通过Tkinter实现了4种纯Python的消息弹窗函数，和JavaScript类似。</p>
<h3 id="71-alert函数">7.1 alert()函数</h3>
<p>In [ ]:</p>
<p>pyautogui.alert(text='', title='', button='OK')</p>
<p>Out[ ]:</p>
<p>'OK'</p>
<p>显示一个简单的带文字和OK按钮的消息弹窗。用户点击后返回<code>button</code>的文字。</p>
<h3 id="72-the-confirm-function">7.2 The confirm() Function</h3>
<p>In [ ]:</p>
<h1 id="ok和cancel按钮的消息弹窗">OK和Cancel按钮的消息弹窗</h1>
<p>pyautogui.confirm(text='', title='', buttons=['OK', 'Cancel'])</p>
<h1 id="10个按键0-9的消息弹窗">10个按键0-9的消息弹窗</h1>
<p>pyautogui.confirm(text='', title='', buttons=range(10))</p>
<p>Out[ ]:</p>
<p>'0'</p>
<p>显示一个简单的带文字、OK和Cancel按钮的消息弹窗，用户点击后返回被点击button的文字，支持自定义数字、文字的列表。</p>
<h3 id="73-the-prompt-function">7.3 The prompt() Function</h3>
<p>In [ ]:</p>
<p>pyautogui.prompt(text='', title='' , default='')</p>
<p>可以输入的消息弹窗，带OK和Cancel按钮。用户点击OK按钮返回输入的文字，点击Cancel按钮返回<code>None</code>。</p>
<h3 id="74-the-password-function">7.4 The password() Function</h3>
<p>In [ ]:</p>
<p>pyautogui.password(text='', title='', default='', mask='*')</p>
<p>样式同<code>prompt()</code>，用于输入密码，消息用<code>*</code>表示。带OK和Cancel按钮。用户点击OK按钮返回输入的文字，点击Cancel按钮返回<code>None</code>。</p>
<h3 id="8-截屏函数">8 截屏函数</h3>
<p>PyAutoGUI可以截屏并保存为图片文件，然后定位这些截屏在屏幕上的位置。与<a href="http://www.sikuli.org/">sikuli</a>类似，把屏幕上的按键截取下来，然后定位，就可以执行点击等操作了。</p>
<p>截屏功能需要安装Pillow模块。OS X用<code>screencapture</code>命令，是系统自带的。Linux用户用<code>scrot</code>命令，可以通过<code>sudo apt-get install scrot</code>安装。</p>
<h3 id="81-ubuntu注意事项">8.1 Ubuntu注意事项</h3>
<p>由于Ubuntu上安装Pillow时缺少PNG和JPEG依赖，所以安装比较复杂，具体可以看<a href="http://conda.pydata.org/miniconda.html">Ubuntu论坛</a>。不过用<a href="http://conda.pydata.org/miniconda.html">miniconda</a>可以解决这些问题，如果Ubuntu或Mint上安装了miniconda，可以直接<code>conda install pillow</code>来安装。</p>
<h3 id="82-screenshot函数">8.2 <code>screenshot()</code>函数</h3>
<p><code>screenshot()</code>函数会返回<code>Image</code>对象（参考<a href="http://python-pillow.github.io/">Pillow或PIL模块文档</a>），也可以设置文件名：</p>
<p>In [ ]:</p>
<p>import pyautogui
im1 = pyautogui.screenshot()
im2 = pyautogui.screenshot('my_screenshot.png')</p>
<p>在一个<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1920</mn><mo>×</mo><mn>1080</mn></mrow><annotation encoding="application/x-tex">1920 \times 1080</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">9</span><span class="mord">2</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">8</span><span class="mord">0</span></span></span></span>的屏幕上，<code>screenshot()</code>函数要消耗100微秒——不快也不慢。</p>
<p>如果你不需要截取整个屏幕，还有一个可选的<code>region</code>参数。你可以把截取区域的左上角XY坐标值和宽度、高度传入截取。</p>
<p>In [ ]:</p>
<p>im = pyautogui.screenshot(region=(0, 0, 300 ,400))</p>
<h3 id="83-定位函数">8.3 定位函数</h3>
<p>可以定位截图在屏幕上的坐标位置。比如，你需要在计算器里输入：<img src="https://muxuezi.github.io/posts/pyautogui/calc.png" alt=""></p>
<p>如果你不知道按钮的位置，就不能用<code>moveTo()</code>定位和<code>click()</code>点击。而且每次计算器的位置可能会变化，这时即使有来坐标也不好用了。但是如果你有要点击按钮的截图，比如数字<code>7</code>：<img src="https://muxuezi.github.io/posts/pyautogui/calc7key.png" alt=""></p>
<p>你可以调用<code>pyautogui.locateOnScreen('calc7key.png')</code>函数来获得<code>7</code>的屏幕坐标。返回的是一个元组<code>(top, left, width, height)</code>。这个元组可以用<code>pyautogui.center()</code>函数来获取截图屏幕的中心坐标。如果截图没找到，<code>pyautogui.locateOnScreen()</code>函数返回<code>None</code>：</p>
<p>In [ ]:</p>
<p>import pyautogui
button7location = pyautogui.locateOnScreen('pyautogui/calc7key.png')
button7location</p>
<p>Out[ ]:</p>
<p>(1226, 546, 29, 28)</p>
<p>In [ ]:</p>
<p>button7x, button7y = pyautogui.center(button7location)
button7x, button7y</p>
<p>Out[ ]:</p>
<p>(1240, 560)</p>
<p>In [ ]:</p>
<p>pyautogui.click(button7x, button7y)</p>
<p><code>locateCenterOnScreen()</code>等价于上面的前两布操作，直接获得截屏屏幕中心坐标：</p>
<p>In [ ]:</p>
<p>import pyautogui
x, y = pyautogui.locateCenterOnScreen('pyautogui/calc7key.png')
pyautogui.click(x, y)</p>
<p>在<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1920</mn><mo>×</mo><mn>1080</mn></mrow><annotation encoding="application/x-tex">1920 \times 1080</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">9</span><span class="mord">2</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">8</span><span class="mord">0</span></span></span></span>的屏幕上，定位函数需要1~2秒时间。对视频游戏（LOL、DOTA）来说就太慢了，但是上班干活还是绰绰有余。</p>
<p>还是几个定位函数。都是从左上角原点开始向右向下搜索截图位置：</p>
<ul>
<li>locateOnScreen(image, grayscale=False)：返回找到的第一个截图<code>Image</code>对象在屏幕上的坐标<code>(left, top, width, height)</code>，如果没找到返回<code>None</code></li>
<li>locateCenterOnScreen(image, grayscale=False)：返回找到的第一个截图<code>Image</code>对象在屏幕上的中心坐标<code>(x, y)</code>，如果没找到返回<code>None</code></li>
<li>locateAllOnScreen(image, grayscale=False)：返回找到的所有相同截图<code>Image</code>对象在屏幕上的坐标<code>(left, top, width, height)</code>的生成器</li>
<li>locate(needleImage, haystackImage, grayscale=False)：返回找到的第一个截图<code>Image</code>对象在<code>haystackImage</code>里面的坐标<code>(left, top, width, height)</code>，如果没找到返回<code>None</code></li>
<li>locateAll(needleImage, haystackImage, grayscale=False)：返回找到的所有相同截图<code>Image</code>对象在<code>haystackImage</code>里面的坐标<code>(left, top, width, height)</code>的生成器</li>
</ul>
<p>两个<code>locateAll*</code>函数都可以用<code>for</code>循环和<code>list()</code>输出：</p>
<p>In [ ]:</p>
<p>for pos in pyautogui.locateAllOnScreen('pyautogui/calc7key.png'):
print(pos)</p>
<p>(1227, 546, 29, 28)</p>
<p>In [ ]:</p>
<p>list(pyautogui.locateAllOnScreen('pyautogui/calc7key.png'))</p>
<p>Out[ ]:</p>
<p>[(1227, 546, 29, 28)]</p>
<h4 id="831-灰度值匹配">8.3.1 灰度值匹配</h4>
<p>可以把<code>grayscale</code>参数设置为<code>True</code>来加速定位（大约提升30%），默认为<code>False</code>。这种去色（desaturate）方法可以加速定位，但是也可能导致假阳性（false-positive）匹配：</p>
<p>In [ ]:</p>
<p>import pyautogui
button7location = pyautogui.locateOnScreen('pyautogui/calc7key.png', grayscale=True)
button7location</p>
<p>Out[ ]:</p>
<p>(1227, 546, 29, 28)</p>
<h4 id="832-像素匹配">8.3.2 像素匹配</h4>
<p>要获取截屏某个位置的RGB像素值，可以用<code>Image</code>对象的<code>getpixel()</code>方法：</p>
<p>In [ ]:</p>
<p>import pyautogui
im = pyautogui.screenshot()
im.getpixel((100, 200))</p>
<p>Out[ ]:</p>
<p>(255, 255, 255)</p>
<p>也可以用PyAutoGUI的<code>pixel()</code>函数，是之前调用的包装：</p>
<p>In [ ]:</p>
<p>pyautogui.pixel(100, 200)</p>
<p>Out[ ]:</p>
<p>(255, 255, 255)</p>
<p>如果你只是要检验一下指定位置的像素值，可以用<code>pixelMatchesColor()</code>函数，把X、Y和RGB元组值穿入即可：</p>
<p>In [ ]:</p>
<p>pyautogui.pixelMatchesColor(100, 200, (255, 255, 255))</p>
<p>Out[ ]:</p>
<p>True</p>
<p>In [ ]:</p>
<p>pyautogui.pixelMatchesColor(100, 200, (255, 255, 245))</p>
<p>Out[ ]:</p>
<p>False</p>
<p><code>tolerance</code>参数可以指定红、绿、蓝3种颜色误差范围：</p>
<p>In [ ]:</p>
<p>pyautogui.pixelMatchesColor(100, 200, (255, 255, 245), tolerance=10)</p>
<p>Out[ ]:</p>
<p>True</p>
<p>In [ ]:</p>
<p>pyautogui.pixelMatchesColor(100, 200, (248, 250, 245), tolerance=10)</p>
<p>Out[ ]:</p>
<p>True</p>
<p>In [ ]:</p>
<p>pyautogui.pixelMatchesColor(100, 200, (205, 255, 245), tolerance=10)</p>
<p>Out[ ]:</p>
<p>False</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[3D slicer 机械臂（ROS）]]></title>
        <id>https://blog.bioprinting.site/post/WBh3a3s5z</id>
        <link href="https://blog.bioprinting.site/post/WBh3a3s5z">
        </link>
        <updated>2019-06-02T09:05:47.000Z</updated>
        <content type="html"><![CDATA[<h1 id="ismr-2019规划">ISMR 2019规划</h1>
<h2 id=""><a href="https://github.com/rosmed/rosmed.github.io/wiki/ISMR2019#organizers"></a>主办单位</h2>
<ul>
<li>Junichi Tokuda，布莱根妇女医院和哈佛医学院（<a href="mailto:tokuda@bwh.harvard.edu">tokuda@bwh.harvard.edu</a>）</li>
<li>女王大学Tamas Ungi（<a href="mailto:ungi@queensu.ca">ungi@queensu.ca</a>）</li>
<li>马里兰大学Axel Krieger（<a href="mailto:axel@umd.edu">axel@umd.edu</a>）</li>
<li>约翰霍普金斯大学Simon Leonard（<a href="mailto:sleonard@jhu.edu">sleonard@jhu.edu</a>）</li>
</ul>
<h2 id="-2"><a href="https://github.com/rosmed/rosmed.github.io/wiki/ISMR2019#invited-talk"></a>特邀演讲</h2>
<ul>
<li>Junichi Tokuda，博士，布莱根妇女医院</li>
<li>Tamas Ungi，医学博士，女王大学博士，图像引导治疗原型软件</li>
<li>Axel Krieger，马里兰大学自主外科软件系统博士</li>
<li>伍斯特理工学院Gregory Fischer博士</li>
<li>范德比尔特大学博士罗伯特韦伯斯特
<ul>
<li>（演讲者变更）范德比尔特大学Stanley D. Herrell博士</li>
</ul>
</li>
<li>Niguhiko Hata，博士，布莱根妇女医院</li>
</ul>
<h2 id="-3"><a href="https://github.com/rosmed/rosmed.github.io/wiki/ISMR2019#time-table-draft"></a>时间表（草案）</h2>
<ul>
<li>下午1:30 - 1：40：开场白和介绍（Junichi Tokuda）</li>
<li>下午1:40至下午2:30：特邀演讲
<ul>
<li>下午1:40 :( Stanley Herrel）</li>
<li>下午1:50 :( Nobuhiko Hata）</li>
<li>下午2:00 :( Axel Krieger）</li>
<li>下午2:10 :(格雷戈里菲舍尔）</li>
<li>下午2:20 :( Tamas Ungi）</li>
</ul>
</li>
<li>下午2:30 - 下午3:00：教程第1节</li>
<li>下午3:00 - 下午3:30：喝咖啡休息时间</li>
<li>下午3:30 - 下午5:00：教程第2节</li>
</ul>
<h2 id="-4"><a href="https://github.com/rosmed/rosmed.github.io/wiki/ISMR2019#tutorial---workflow"></a>教程 - 工作流程</h2>
<p>请参见<a href="https://dl.dropboxusercontent.com/s/kamqj85tdhrgbgc/ROSIGTLTutorial-ISMR2019.pptx">教程幻灯片</a>。</p>
<p>以下工作流程是草稿。</p>
<ul>
<li>条件
<ul>
<li>切片机工作站
<ul>
<li>请参阅<a href="https://www.slicer.org/wiki/Documentation/4.8/SlicerApplication/HardwareConfiguration">www.slicer.org上的切片机4.8的硬件要求</a></li>
</ul>
</li>
<li>ROS计算机
<ul>
<li>[选项1]原生Linux机器 - 请参考[安装页面]）<a href="http://wiki.ros.org/kinetic/Installation">http://wiki.ros.org/kinetic/Installation</a>）</li>
<li>[选项2] Docker - 在这种情况下，不需要专用的ROS计算机。Docker容器可以在Slicer工作站上运行。</li>
<li>[选项3]可以使用其他虚拟化环境（VMWare，VirtualBox等）。VirtualBox在3D图形方面存在一些性能问题（rviz需要），此时不建议使用。</li>
</ul>
</li>
</ul>
</li>
<li><a href="https://github.com/rosmed/rosmed.github.io/wiki/ROS_Environment">设置ROS环境</a>
<ul>
<li>安装ROS
<ul>
<li>[选项1/3]使用原生Linux或虚拟盒（不推荐）</li>
<li>[选项2]使用Docker</li>
</ul>
</li>
</ul>
</li>
<li><a href="https://github.com/rosmed/rosmed.github.io/wiki/Slicer">设置3D切片器</a>
<ul>
<li>安装扩展（插件）</li>
<li>使用ROS-IGTL-Bridge测试3D Slicer-ROS通信</li>
</ul>
</li>
<li><a href="https://github.com/rosmed/rosmed.github.io/wiki/ROS_Robot">在ROS上设置通用机器人手臂</a>
<ul>
<li>使用rviz在ROS场景中加载机器人和患者模型</li>
<li>使用rviz上的指针功能将患者模型移动到机器人的工作空间中</li>
</ul>
</li>
<li><a href="https://github.com/rosmed/rosmed.github.io/wiki/Slicer_Planning">规划3D切片机</a>
<ul>
<li>加载患者模型</li>
<li>定义目标针轨迹（插入前和插入后）</li>
<li>加载机器人模型</li>
</ul>
</li>
<li><a href="https://github.com/rosmed/rosmed.github.io/wiki/Connecting_Slicer_and_ROS">在Slicer和ROS之间建立连接</a>
<ul>
<li>使用ROS-IGTL-Bridge将3D切片机与ROS连接</li>
<li>检查3D Slicer和ROS上的机器人模型的同步</li>
</ul>
</li>
<li><a href="https://github.com/rosmed/rosmed.github.io/wiki/Registration">注册</a>
<ul>
<li>（切片器）启动Fiducial Registration Wizard</li>
<li>（rviz）手动将末端执行器移动到头骨上的第一个界标</li>
<li>（切片器）记录尖端的当前位置，然后单击ull模型上的相应点</li>
<li>重复前两个步骤</li>
<li>运行地标注册。</li>
<li>将变换应用于机器人</li>
</ul>
</li>
<li><a href="https://github.com/rosmed/rosmed.github.io/wiki/Slicer_Visualization">规划针位置</a>
<ul>
<li>（切片器）设置音量Reslice驱动程序</li>
<li>（切片器）将插入前的末端效应器位置发送到ROS</li>
</ul>
</li>
<li><a href="https://github.com/rosmed/rosmed.github.io/wiki/Execution">执行计划</a>
<ul>
<li>（ROS）将手臂移至原位</li>
<li>（ROS）将手臂移动到插入前的位置</li>
<li>（ROS）将手臂移动到插入后位置</li>
</ul>
</li>
</ul>
<h2 id="-5"><a href="https://github.com/rosmed/rosmed.github.io/wiki/ISMR2019#memos"></a>备忘录</h2>
<ul>
<li>3D切片机教程
<ul>
<li><a href="https://www.slicer.org/wiki/Documentation/4.8/Training">入门教程</a></li>
<li><a href="https://onedrive.live.com/view.aspx?resid=7230D4DEC6058018!29379&amp;ithint=file%2cpptx&amp;authkey=!AL2fpr9tHQTEWNA">脑外科教程</a></li>
</ul>
</li>
<li><a href="https://github.com/rosmed/rosmed.github.io/wiki/VirtualEnvironments">虚拟环境解决方案</a></li>
<li><a href="https://github.com/rosmed/rosmed.github.io/wiki/DockerROS">设置Docker镜像</a></li>
</ul>
<p>关注<a href="https://github.com/openigtlink/ROS-IGTL-Bridge">https://github.com/openigtlink/ROS-IGTL-Bridge</a></p>
<h1 id="ros-igtl桥">ROS-IGTL桥</h1>
<p>作者：Tobias Frank，Junichi Tokuda（布莱根妇女医院）</p>
<p>该ROS-Node提供了一个OpenIGTLink桥，用于与ROS交换数据。它支持发送和接收转换，图像，字符串，PolyData，Points和Pointcloud。有关OpenIGTLink协议的更多信息，请参阅：</p>
<ul>
<li><a href="http://openigtlink.org/">http://openigtlink.org/</a></li>
</ul>
<hr>
<h2 id="-6"><a href="https://github.com/openigtlink/ROS-IGTL-Bridge#build-instruction"></a>构建指令</h2>
<p>测试了以下步骤：</p>
<ul>
<li>Ubuntu 14.04 + ROS Indigo</li>
<li>Ubuntu 16.04 + ROS Kinetic Kame</li>
</ul>
<p>首先，在本地计算机中安装OpenIGTLink。有关详细说明，请访问<a href="http://openigtlink.org/">http://openigtlink.org/</a>。在以下指令中，我们假设OpenIGTLink库的构建目录位于：〜/ igtl / OpenIGTLink-build</p>
<p><code>$ cd <your OpenIGTLink directory>
$ git clone https://github.com/openigtlink/OpenIGTLink.git
$ mkdir OpenIGTLink-build
$ cd OpenIGTLink-build
$ cmake -DBUILD_SHARED_LIBS:BOOL=ON ../OpenIGTLink
$ make</code></p>
<p>安装<a href="http://wiki.ros.org/">ROS</a>并按照标准<a href="http://wiki.ros.org/catkin/Tutorials/create_a_workspace">ROS说明</a>创建ROS工作区（如有必要）。</p>
<p><code>$ mkdir -p ~/catkin_ws/src
$ cd ~/catkin_ws
$ catkin_make
$ source devel/setup.bash</code></p>
<p>ROS-IGTL-Bridge需要VTK。您可以使用apt-get安装它：</p>
<p><code>$ sudo apt-get install libvtk6-dev</code></p>
<p>然后从GitHub下载ros_igtl_bridge包：</p>
<p><code>$ cd ~/catkin_ws/src
$ git clone https://github.com/openigtlink/ROS-IGTL-Bridge</code></p>
<p>并在工作区目录中执行catkin_make：</p>
<p><code>$ cd ~/catkin_ws/
$ catkin_make --cmake-args -DOpenIGTLink_DIR:PATH=<your OpenIGTLink directory>/OpenIGTLink-build</code></p>
<p>要运行网桥，请键入：</p>
<p><code>$ roslaunch ros_igtl_bridge bridge.launch</code></p>
<p>如果已设置桥接，则可以启动与[3D Slicer]（<a href="https://www.slicer.org/">https://www.slicer.org/</a>）进行通信的测试程序：</p>
<p><code>$ roslaunch ros_igtl_bridge test.launch</code></p>
<p>可以编辑启动文件并在文件中设置IP和端口。通过调整参数RIB_type将节点作为服务器或客户端运行。打开文件并取消注释行：</p>
<p><code>$ <!--param name="RIB_server_ip" value="111.111.111.111" type="str"/-->
$ <!--param name="RIB_port" value="18944" type="int"/-->
$ <!--param name="RIB_type" value="client" type="str"/--></code></p>
<p>该节点可以作为服务器或客户端运行。如果您执行了测试程序，该节点将发送带有随机翻译的“ROS_IGTL_Test_Transform”，随机的“ROS_IGTL_Test_Point”，包含20个点的随机“ROS_IGTL_Test_Pointcloud”，“ROS_IGTL_Test_String”和“ROS_IGTL_Test_PolyData”，这是一个渲染模型。 3D Slicer MRHead样本数据。从3D切片器接收的任何数据都由桥节点发布到ROS主题并由测试节点显示。</p>
<h2 id="-7"><a href="https://github.com/openigtlink/ROS-IGTL-Bridge#references"></a>参考</h2>
<ol>
<li>Frank T，Krieger A，Leonard S，Patel NA，Tokuda J. ROS-IGTL-Bridge：一种开放式网络接口，用于使用ROS环境进行图像引导治疗。Int J Comput Assist Radiol Surg。2017年5月31日doi：10.1007 / s11548-017-1618-1。PubMed PMID：<a href="https://www.ncbi.nlm.nih.gov/pubmed/?term=28567563">28567563</a>。</li>
</ol>
<h2 id="docker-image">Docker Image</h2>
<p>由Christian Henkel开发的基础Docker映像（vnc-ros-kinetic-full）源自<a href="https://hub.docker.com/r/ct2034/vnc-ros-kinetic-full/">Docker Hub存储库</a>。此Docker镜像附带：</p>
<ul>
<li>Ubuntu 16.04</li>
<li>ROS动力学</li>
<li>HTML5 VNC服务器</li>
</ul>
<p>我们的Docker镜像包含以下附加包：</p>
<ul>
<li>ROS-工业</li>
<li>ROS通用机器人包</li>
<li>ROS MoveIt！包</li>
<li>OpenIGTLink</li>
<li>ROS-IGTL桥</li>
</ul>
<p>我们的Dockerfile可以在<a href="https://github.com/rosmed/docker-ros-igtl">GitHub上获得</a>，它的图像在<a href="https://cloud.docker.com/u/rosmed/repository/docker/rosmed/docker-ros-igtl">Docker Hub上发布</a>。</p>
<h2 id="-8"><a href="https://github.com/rosmed/rosmed.github.io/wiki/DockerROS#building-docker-image-not-needed"></a>构建Docker镜像（不需要）</h2>
<p>要使用修改后的Dockerfile构建Docker镜像，请运行以下命令：</p>
<p><code>$ cd <working directory>
$ git clone https://github.com/rosmed/docker-ros-igtl
$ cd docker-ros-igtl
$ docker build -t docker-ros-igtl .</code></p>
<h2 id="-9"><a href="https://github.com/rosmed/rosmed.github.io/wiki/DockerROS#running-docker-image"></a>运行Docker镜像</h2>
<p>要执行docker镜像，请调用以下命令：</p>
<p><code>$ docker pull docker pull rosmed/docker-ros-igtl
$ docker run -it --rm -p 6080:80 rosmed/docker-ros-igtl</code></p>
<p>在此示例中，docker容器上的Web端口将映射到主机上的端口6080。' - rm'选项将在终止时删除容器。</p>
<h1 id="connecting_slicer_and_ros">Connecting_Slicer_and_ROS</h1>
<p>Junichi Tokuda编辑了这个页面 on 21 Mar · <a href="https://github.com/rosmed/rosmed.github.io/wiki/Connecting_Slicer_and_ROS/_history">3次修订</a></p>
<h1 id="-10"><a href="https://github.com/rosmed/rosmed.github.io/wiki/Connecting_Slicer_and_ROS#connecting-3d-slicer-with-ros"></a>连接3D切片机与ROS</h1>
<p>确保以下组件正在运行：</p>
<ul>
<li>ROS计算机
<ul>
<li>rviz上的通用机器人</li>
<li>IGTL出口商</li>
<li>ROS-IGTL桥</li>
</ul>
</li>
<li>切片机工作站
<ul>
<li>3D切片机</li>
</ul>
</li>
</ul>
<p>现在我们连接3D Slicer和来自OpenIGTLinkIF模块的ROS，正如我们在<a href="https://github.com/rosmed/rosmed.github.io/wiki/Slicer">上一步中</a>测试<a href="https://github.com/rosmed/rosmed.github.io/wiki/Slicer">的那样</a>。打开OpenIGTLinkIF模块（模块菜单 - &gt;“IGT” - &gt;“OpenIGTLinkIF”）。然后单击“连接器”列表下的“+”按钮创建一个新节点，并从“属性”部分进行配置，如下所示：</p>
<ul>
<li>名称：“IGTLConnector”（默认）</li>
<li>键入：“客户端”（默认）</li>
<li>状态：未选中（默认）</li>
<li>MRMLNodeAlgorithm：保持未选中状态</li>
<li>主机名：localhost（如果使用Docker）或ROS机器的IP（用于非Docker环境）</li>
<li>端口：28944（如果Docker与“-p 28944：18944”选项一起使用）或18944（非Docker环境的默认值）</li>
</ul>
<p>配置连接器后，单击“活动”复选框。如果3D Slicer成功连接到ROS-IGTL-Bridge，则OpenIGTLinkIF的连接器列表上的状态字段将显示为“ON”。</p>
<h1 id="加载mr图像和患者模型">加载MR图像和患者模型</h1>
<p>首先，下载<a href="http://bit.ly/2UZ8OaR">ISMR19的切片器场景</a>。这个场景包含：</p>
<ul>
<li>场景描述文件（Scene-ISMR19.mrml）</li>
<li>患者的MR图像（MRI.nrrd）</li>
<li>患者的3D模型（SkullDrilled1.stl）</li>
<li>机器人链接的3D模型（* .stl除了SkullDrilled1.stl）</li>
<li>链接的转换矩阵（* .h5）</li>
</ul>
<p>解压缩zip文件。在Linux / Mac上的终端上，可以通过以下方式完成：</p>
<p><code>$ unzip SlicerScene-ISMR19.zip
Archive:  SlicerScene-ISMR19.zip
inflating: SlicerScene/MRI.nrrd<br>
inflating: SlicerScene/Scene-ISMR19.mrml<br>
inflating: SlicerScene/Scene-ISMR19.png<br>
inflating: SlicerScene/SkullDrilled1_mm.stl<br>
inflating: SlicerScene/base_mm.stl<br>
inflating: SlicerScene/forearm_link.h5<br>
inflating: SlicerScene/forearm_mm.stl<br>
inflating: SlicerScene/needle.h5<br>
inflating: SlicerScene/needle_holder.h5<br>
inflating: SlicerScene/needle_holder_mm.stl<br>
inflating: SlicerScene/shoulder_link.h5<br>
inflating: SlicerScene/shoulder_mm.stl<br>
inflating: SlicerScene/tool0.h5<br>
inflating: SlicerScene/upper_arm_link.h5<br>
inflating: SlicerScene/upperarm_mm.stl<br>
inflating: SlicerScene/wrist1_mm.stl<br>
inflating: SlicerScene/wrist2_mm.stl<br>
inflating: SlicerScene/wrist3_mm.stl<br>
inflating: SlicerScene/wrist_1_link.h5<br>
inflating: SlicerScene/wrist_2_link.h5<br>
inflating: SlicerScene/wrist_3_link.h5</code></p>
<p>请注意，STL格式不包含单位信息。虽然文件应该以适当的比例加载到3D Slicer上，但它们可能无法在其他环境中运行。</p>
<p>提取完所有文件后，我们从3D Slicer加载场景，如下所示：</p>
<ul>
<li>打开“添加数据”对话框（“文件” - &gt;“添加数据”）。</li>
<li>单击“选择要添加的文件”按钮。</li>
<li>从“打开”对话框中选择“Scene-ISMR19.mrml”。</li>
<li>单击“打开”。文件名应出现在“选择要添加的文件”对话框中。单击“确定”后，3D切片器开始将文件加载到场景中。</li>
</ul>
<p>如果文件成功加载，您应该能够在红色/黄色/绿色查看器上看到MR图像，并在3D查看器上看到头骨和机器人的模型。头骨相对于机器人的位置是不现实的，但这是因为它们尚未注册（或校准）。我们将在本教程的后面注册它们。</p>
<h1 id="-11"><a href="https://github.com/rosmed/rosmed.github.io/wiki/Slicer_Planning#planning-needle-placement"></a>规划针位置</h1>
<p>我们通过定义1）目标点和2）皮肤上的针入口点来计划针放置轨迹。</p>
<p>首先，我们使头骨模型的部分在3轴平面上可见，如下所示：</p>
<ul>
<li>打开“模型”模块（“模块”菜单 - &gt;“模型”）</li>
<li>从模型列表中选择“SkullDrilled1_mm”。</li>
<li>在“切片显示”框中，选中“可见”。现在您应该看到头骨模型的部分覆盖在MR图像上。</li>
</ul>
<p>要定义条目和目标点：</p>
<ul>
<li>单击工具栏中的“创建并放置基准”按钮。</li>
<li>单击肿瘤中心作为目标点。（基准“F-1”应出现在MR图像上）</li>
<li>单击头骨上的孔的中心作为入口点。（基准“F-2”应出现在MR图像上）</li>
<li>从模块菜单中打开“Markups”模块。</li>
<li>下拉列表菜单，然后选择“重命名当前MarkupsFiducials”。</li>
<li>在弹出窗口中，键入“Plan”（区分大小写）作为新名称，然后单击“确定”。</li>
<li>通过单击名称（即“F-1”和“F-2”）将点的名称从“F-1”和“F-2”更改为“目标”和“条目”，然后输入新的名称名。名称区分大小写，因为它们将被转移到ROS并用于识别点。</li>
</ul>
<h1 id="ros_robot">ROS_Robot</h1>
<p>Simon Leonard编辑了此页面 on 29 Mar · <a href="https://github.com/rosmed/rosmed.github.io/wiki/ROS_Robot/_history">19次修订</a></p>
<h1 id="-12"><a href="https://github.com/rosmed/rosmed.github.io/wiki/ROS_Robot#installing-ros-packages"></a>安装ROS包</h1>
<p>（如果使用本教程中提供的Docker镜像设置ROS环境，则可以跳过此步骤。）</p>
<p>在ROS计算机上，我们打开一个终端并将两个ROS包复制到katkin工作区：</p>
<p><code>cd ~/catkin_ws/src
git clone https://github.com/rosmed/ismr19_description
git clone https://github.com/rosmed/ismr19_moveit
git clone https://github.com/rosmed/ismr19_control</code></p>
<p>此外，我们还复制了IGTL Exporter，它通过ROS-IGTL-Bridge将机器人链接的转换流式传输到3D Slicer。</p>
<p><code>cd ~/catkin_ws/src
git clone https://github.com/tokjun/ros_bx_robot_bridge</code></p>
<p>然后，运行catkin_make</p>
<p><code>cd ~/catkin_ws
catkin_make
source devel/setup.bash</code></p>
<h1 id="-13"><a href="https://github.com/rosmed/rosmed.github.io/wiki/ROS_Robot#launching-the-ros-packages"></a>启动ROS包</h1>
<p>！以下步骤将被修改 - 不确定我们是否将使用demo.launch !!</p>
<p>我们使用以下命令在rviz上使用自定义针头hodler启动通用机器人：</p>
<p><code>roslaunch ismr19_moveit demo.launch</code></p>
<h1 id="-14"><a href="https://github.com/rosmed/rosmed.github.io/wiki/ROS_Robot#launching-igtl-exporter"></a>启动IGTL Exporter</h1>
<p>要启动IGTL导出器，请打开另一个终端并运行以下命令：</p>
<p><code>cd ~/catkin_ws
source devel/setup.bash
rosrun bx_robot_bridge igtl_exporter.py</code></p>
<h1 id="-15"><a href="https://github.com/rosmed/rosmed.github.io/wiki/ROS_Robot#loading-patient-model"></a>加载患者模型</h1>
<p>我们将加载患者的表面模型。首先，我们下载模型：</p>
<p><code>cd ~
mkdir models
cd models
wget -O ismr19.scene https://bit.ly/2OpSdKM</code></p>
<p>从rviz中，打开“MotionPlanning”框中的“Scene Objects”选项卡，单击“Current Scene Objects”部分右下方区域的“Import From Text”按钮，选择下载的文件（“ismr19.scene”） ）在“导入场景几何体”对话框中，单击“打开”按钮。头骨模型出现在3D查看器上。</p>
<p>看到头骨后，单击“发布场景”按钮。</p>
<h1 id="切片机">切片机</h1>
<p>Simon Leonard编辑了此页面 on 29 Mar · <a href="https://github.com/rosmed/rosmed.github.io/wiki/Slicer/_history">19次修订</a></p>
<h1 id="-16"><a href="https://github.com/rosmed/rosmed.github.io/wiki/Slicer#installing-3d-slicer-and-extensions"></a>安装3D切片器和扩展</h1>
<p>在本教程中，我们将使用3D Slicer版本4.8.1二进制文件可从以下链接获得：</p>
<ul>
<li><a href="http://slicer.kitware.com/midas3/download/item/330417/Slicer-4.8.1-linux-amd64.tar.gz">适用于Linux的切片器4.8.1（Intel 64位）</a></li>
<li><a href="http://slicer.kitware.com/midas3/download/item/330418/Slicer-4.8.1-macosx-amd64.dmg">用于macOS的切片器4.8.1（Intel 64位）</a></li>
<li><a href="http://slicer.kitware.com/midas3/download/item/329467/Slicer-4.8.1-win-amd64.exe">适用于Windows的切片器4.8.1（Intel 64位）</a></li>
</ul>
<p>**Mac用户注意事项：**如果首次启动3D Slicer时系统弹出一个窗口警告“Slicer.app无法打开，因为它来自一位身份不明的开发人员”，请点击图标启动Slicer应用程序用鼠标右键（或用Ctrl键单击），然后从下拉菜单中选择“打开”。然后，系统将提示您确认是否正在打开该应用程序。单击“打开”按钮后将启动切片器。</p>
<p>在本教程中，我们不会使用最新版本的3D Slicer（自2019年3月起为4.10.1），因为它仍然存在一些与ROS-IGTL-Bridge之间传输点和多边形数据的问题。</p>
<p>安装并启动3D Slicer后，打开Extension Manager（“查看” - &gt;“Extension Manager”），并安装以下扩展名：</p>
<ul>
<li><strong>SlicerIGT</strong></li>
</ul>
<p>重新启动3D切片器后，您应该会在模块菜单的“IGT”部分下看到扩展中包含的插件模块。</p>
<h1 id="-17"><a href="https://github.com/rosmed/rosmed.github.io/wiki/Slicer#testing-communication-with-ros-using-ros-igtl-bridge"></a>使用ROS-IGTL-Bridge测试与ROS的通信</h1>
<p>首先，我们从Linux上的终端（使用ROS）启动roscore：</p>
<p><code>roscore</code></p>
<p>然后我们启动了ROS-IGTL-Bridge。打开另一个终端，然后运行以下命令：</p>
<p><code>cd ~/catkin_ws
source devel/setup.bash
roslaunch ros_igtl_bridge bridge.launch
..
[ROS-IGTL-Bridge] Please type &lt;1&gt; or &lt;2&gt; to run node as OpenIGTLink client or server
1 : Server
2 : Client</code></p>
<p>终端将提示选择类型（服务器或客户端），然后选择主机信息（两种情况下的端口号，如果网桥作为服务器启动，则为IP）。在本教程中，我们将桥接器作为服务器运行并使用端口18944.还可以编辑启动文件并在文件中设置IP和端口。通过调整参数RIB_type将节点作为服务器或客户端运行。打开文件并取消注释行：</p>
<p><code>$ <!--param name="RIB_server_ip" value="111.111.111.111" type="str"/-->
$ <!--param name="RIB_port" value="18944" type="int"/-->
$ <!--param name="RIB_type" value="client" type="str"/--></code></p>
<p>桥接器准备就绪后，打开3D Slicer（如果尚未打开），打开OpenIGTLinkIF模块（模块菜单 - &gt;“IGT” - &gt;“OpenIGTLinkIF”）。然后单击“连接器”列表下的“+”按钮创建一个新节点，并从“属性”部分进行配置，如下所示：</p>
<ul>
<li>名称：“IGTLConnector”（默认）</li>
<li>键入：“客户端”（默认）</li>
<li>状态：未选中（默认）</li>
<li>MRMLNodeAlgorithm：保持未选中状态</li>
<li>主机名：localhost（如果使用Docker）或ROS机器的IP（用于非Docker环境）</li>
<li>端口：28944（如果Docker与“-p 28944：18944”选项一起使用）或18944（非Docker环境的默认值）</li>
</ul>
<p>配置连接器后，单击“活动”复选框。如果3D Slicer成功连接到ROS-IGTL-Bridge，则OpenIGTLinkIF的连接器列表上的状态字段将显示为“ON”。</p>
<p>在Linux（使用ROS）上打开一个新终端，然后运行以下命令：</p>
<p><code>cd ~/catkin_ws
source devel/setup.bash
roslaunch ros_igtl_bridge test.launch</code></p>
<p>测试节点发送带有随机翻译的“ROS_IGTL_Test_Transform”，随机的“ROS_IGTL_Test_Point”，包括20个点的随机“ROS_IGTL_Test_Pointcloud”，“ROS_IGTL_Test_String”和“ROS_IGTL_Test_PolyData”。您可以在OpenIGTLinkIF模块的“I / O配置”中确认它们。（确保展开“场景” - &gt;“IGTLConnector1” - &gt;“IN”）。</p>
<p>这些数据将显示在3D Slicer上。在3D Slicer显示患者的表面模型之前，可能需要几秒到一分钟。</p>
<p>确认桥接器正常工作后，通过取消选中“Active”复选框来断开3D Slicer。在3D Slicer上连接状态变为“OFF”后，按终端上的Ctrl-C停止桥接和测试节点。关闭3D切片器上的场景（“文件” - &gt;“关闭场景”）或关闭3D切片器应用程序。</p>
<h1 id="ros_environment">ROS_Environment</h1>
<p>Simon Leonard编辑了此页面 3月29日 · <a href="https://github.com/rosmed/rosmed.github.io/wiki/ROS_Environment/_history">16次修订</a></p>
<h1 id="-18"><a href="https://github.com/rosmed/rosmed.github.io/wiki/ROS_Environment#setting-up-ros-environment-for-tutorial"></a>为教程设置ROS环境</h1>
<h2 id="-19"><a href="https://github.com/rosmed/rosmed.github.io/wiki/ROS_Environment#prerequisite"></a>条件</h2>
<p>在本教程中，我们将使用ROS Kinetic，它支持Wily（Ubuntu 15.10），Xenial（Ubuntu 16.04）和Jessie（Debian 8）用于Debian。请参阅<a href="http://wiki.ros.org/kinetic/Installation/Ubuntu">安装页面</a>了解详细信</p>
<h2 id="-20"><a href="https://github.com/rosmed/rosmed.github.io/wiki/ROS_Environment#option-1-installing-ros-on-dedicated-ros-computer"></a>[选项1]在专用ROS计算机上安装ROS</h2>
<p>请按照<a href="http://wiki.ros.org/kinetic/Installation/Ubuntu">安装页面</a>。</p>
<h3 id="-21"><a href="https://github.com/rosmed/rosmed.github.io/wiki/ROS_Environment#installing-ros-kinetic"></a>安装ROS Kinetic</h3>
<p>然后我们安装其他软件包，包括ROS-Industrial，MoveIt！，Universal Robot和libvtk6-dev。从终端，</p>
<p><code>sudo rosdep update -y
sudo apt-get update -y
sudo apt-get dist-upgrade -y
sudo apt-get install -y ros-kinetic-industrial-core
sudo apt-get install -y ros-kinetic-universal-robot
sudo apt-get install -y ros-kinetic-moveit
sudo apt-get install -y ros-kinetic-moveit-visual-tools
sudo apt-get install libvtk6-dev</code></p>
<h3 id="-22"><a href="https://github.com/rosmed/rosmed.github.io/wiki/ROS_Environment#building-openigtlink"></a>构建OpenIGTLink</h3>
<p>ROS-IGTL-Bridge依赖于OpenIGTLink库。我们在〜/ igtl / OpenIGTLink下安装libary的源文件，并在〜/ igtl / OpenIGTLink-build下构建文件</p>
<p><code>cd ~
mkdir igtl
cd igtl
git clone https://github.com/openigtlink/OpenIGTLink.git
mkdir OpenIGTLink-build
cd OpenIGTLink-build
cmake -DBUILD_SHARED_LIBS:BOOL=ON ../OpenIGTLink
make</code></p>
<h3 id="-23"><a href="https://github.com/rosmed/rosmed.github.io/wiki/ROS_Environment#installing-ros-igtl-bridge"></a>安装ROS-IGTL-Bridge</h3>
<p>首先，设置catkin工作目录（如果尚未设置）。我们将使用标准的ROS工作区“catkin_ws”。如果您已有现有的，我们建议您在本教程的持续时间内将其移至其他位置</p>
<p><code>mv ~/catkin_ws ~/catkin_ws_old</code></p>
<p>然后，继续创建一个干净的工作区</p>
<p><code>mkdir -p ~/catkin_ws/src
cd ~/catkin_ws
catkin_make
source devel/setup.bash</code></p>
<p>然后从github存储库中获取代码：</p>
<p><code>cd ~/catkin_ws/src
git clone https://github.com/openigtlink/ROS-IGTL-Bridge</code></p>
<p>要构建ROS-IGTL-Bridge，请运行</p>
<p><code>cd ~/catkin_ws/
catkin_make --cmake-args -DOpenIGTLink_DIR:PATH=~/igtl/OpenIGTLink-build</code></p>
<h2 id="-24"><a href="https://github.com/rosmed/rosmed.github.io/wiki/ROS_Environment#option-2-installing-ros-using-docker"></a>[选项2]使用Docker安装ROS</h2>
<p>必须在安装之前安装<a href="https://www.docker.com/">Docker</a>。要安装教程的Docker镜像，请打开终端并运行以下命令：</p>
<p><code>sudo docker pull rosmed/docker-ros-igtl
sudo docker run -it --rm -p 6080:80 -p 28944:18944 rosmed/docker-ros-igtl</code></p>
<p>在此示例中，docker容器上的HTTP端口（端口80）和OpenIGTLink端口（端口18944）分别映射到主机上的端口6080和28944。' - rm'选项将在终止时删除容器。</p>
<p>要访问桌面，请在同一台计算机上打开Web浏览器（与HTML5兼容），然后在地址栏中键入以下地址：</p>
<p><code>http://localhost:6080</code></p>
<p>如果Docker镜像容器成功运行，则浏览器应显示桌面屏幕。</p>
<p>此docker镜像包含本教程所需的所有软件，无需安装其他软件包（即OpenIGTLink和ROS-IGTL-Bridge）</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[机械臂类似UR5]]></title>
        <id>https://blog.bioprinting.site/post/9WyZd7kxa</id>
        <link href="https://blog.bioprinting.site/post/9WyZd7kxa">
        </link>
        <updated>2019-06-02T08:32:46.000Z</updated>
        <content type="html"><![CDATA[<p>This is part 2 of my 3D printed robot arm. You can watch part 1 at <a href="https://www.youtube.com/watch?v=tEbJV32GyYU">https://www.youtube.com/watch?v=tEbJV...</a> in case you missed it. The CAD design of the extended wrist cap with the electronics inside is available at <a href="https://www.youtube.com/redirect?q=https%3A%2F%2Fgallery.autodesk.com%2Ffusion360%2Fprojects%2Frobot-arm-esp32-drv8825-actuator-controller&amp;event=video_description&amp;v=RdmdFIhCo4M&amp;redir_token=ii2yaoab_KuAW516O-i_OhpUBRh8MTU1OTU1MDI3OEAxNTU5NDYzODc4">https://gallery.autodesk.com/fusion36...</a> The PCB Eagle Board design is available at <a href="https://www.youtube.com/redirect?q=https%3A%2F%2Fgithub.com%2Fchilipeppr%2Frobot-actuator-controller-v1&amp;event=video_description&amp;v=RdmdFIhCo4M&amp;redir_token=ii2yaoab_KuAW516O-i_OhpUBRh8MTU1OTU1MDI3OEAxNTU5NDYzODc4">https://github.com/chilipeppr/robot-a...</a> as well as the Lua code that I used to test the actuators in this video. The NodeMCU.bin firmware is there too. This has the latest release of the firmware plus the stepper library built in. Just flash NodeMCU.bin via esptool to your ESP32 board. The ChiliPeppr ESP32 for Lua Workspace was used to program the board and is available at <a href="https://www.youtube.com/redirect?q=http%3A%2F%2Fchilipeppr.com%2Fesp32&amp;event=video_description&amp;v=RdmdFIhCo4M&amp;redir_token=ii2yaoab_KuAW516O-i_OhpUBRh8MTU1OTU1MDI3OEAxNTU5NDYzODc4">http://chilipeppr.com/esp32</a> Video on how to use the ESP32 for Lua workspace to upload firmware and Lua code on your ESP32. <a href="https://www.youtube.com/watch?v=njAeHfoVIoY">https://www.youtube.com/watch?v=njAeH...</a> Jeff Kerr's (LoboCNC) original 3D printed robot arm design is on Thingiverse at <a href="https://www.youtube.com/redirect?q=https%3A%2F%2Fwww.thingiverse.com%2Fthing%3A3327968%2F&amp;event=video_description&amp;v=RdmdFIhCo4M&amp;redir_token=ii2yaoab_KuAW516O-i_OhpUBRh8MTU1OTU1MDI3OEAxNTU5NDYzODc4">https://www.thingiverse.com/thing:332...</a> PCB Components ESP32 Wemos $8 (Many ESP32 devices are cheaper, but this is the smallest size broadly available to fit inside the small actuators) <a href="https://www.youtube.com/redirect?q=https%3A%2F%2Fwww.aliexpress.com%2Fitem%2FESP32-wemos-ESP32-WiFi-Modules-Bluetooth-Dual-ESP-32-ESP-32S-ESP8266%2F32815190965.html&amp;event=video_description&amp;v=RdmdFIhCo4M&amp;redir_token=ii2yaoab_KuAW516O-i_OhpUBRh8MTU1OTU1MDI3OEAxNTU5NDYzODc4">https://www.aliexpress.com/item/ESP32...</a> DRV8825 Stepper Board $0.95 <a href="https://www.youtube.com/redirect?q=https%3A%2F%2Fwww.aliexpress.com%2Fitem%2F5pcs-lot-3D-Printer-Stepstick-Drv8825-Stepper-Motor-Driver-Reprap-4-PCB-Board-Free-shipping-replace%2F32514641632.html&amp;event=video_description&amp;v=RdmdFIhCo4M&amp;redir_token=ii2yaoab_KuAW516O-i_OhpUBRh8MTU1OTU1MDI3OEAxNTU5NDYzODc4">https://www.aliexpress.com/item/5pcs-...</a> DC to DC Converter $0.90 (Pick the 5V version, not 3.3V) <a href="https://www.youtube.com/redirect?q=https%3A%2F%2Fwww.aliexpress.com%2Fitem%2FDC-DC-Power-Supply-Module-Step-Down-3A-output-24V-12V-to-5V-3-3V-Buck%2F32904709711.html&amp;event=video_description&amp;v=RdmdFIhCo4M&amp;redir_token=ii2yaoab_KuAW516O-i_OhpUBRh8MTU1OTU1MDI3OEAxNTU5NDYzODc4">https://www.aliexpress.com/item/DC-DC...</a> WS2812B LED $0.15 per (Choose white and WS2812B) <a href="https://www.youtube.com/redirect?q=https%3A%2F%2Fwww.aliexpress.com%2Fitem%2F10-1000pcs-4-Pin-WS2812B-WS2812-LED-Chip-Heatsink-5V-5050-RGB-WS2811-IC-Built-in%2F32634454437.html&amp;event=video_description&amp;v=RdmdFIhCo4M&amp;redir_token=ii2yaoab_KuAW516O-i_OhpUBRh8MTU1OTU1MDI3OEAxNTU5NDYzODc4">https://www.aliexpress.com/item/10-10...</a> Slide Switch $0.29 for 20 pieces <a href="https://www.youtube.com/redirect?q=https%3A%2F%2Fwww.aliexpress.com%2Fitem%2F20Pcs-Interruptor-on-off-mini-Slide-Switch-SS12D00-SS12D00G3-3pin-1P2T-2-Position-High-quality-toggle%2F32964400942.html&amp;event=video_description&amp;v=RdmdFIhCo4M&amp;redir_token=ii2yaoab_KuAW516O-i_OhpUBRh8MTU1OTU1MDI3OEAxNTU5NDYzODc4">https://www.aliexpress.com/item/20Pcs...</a> Screw Terminal <a href="https://www.youtube.com/redirect?q=https%3A%2F%2Fwww.aliexpress.com%2Fitem%2F20-pcs-2-Pin-Screw-blue-green-PCB-Terminal-Block-Connector-5mm-Pitch%2F32814618602.html&amp;event=video_description&amp;v=RdmdFIhCo4M&amp;redir_token=ii2yaoab_KuAW516O-i_OhpUBRh8MTU1OTU1MDI3OEAxNTU5NDYzODc4">https://www.aliexpress.com/item/20-pc...</a> 26AWG Silicone Ultra Flexible Wire for 24v (Use 2 of the 4 wires) <a href="https://www.youtube.com/redirect?q=https%3A%2F%2Fwww.aliexpress.com%2Fitem%2F2metre-26AWG-28AWG-30AWG-Silicone-Wire-Ultra-Flexiable-Test-Line-3P-4P-6P-0-08mm-Tinned%2F32870367030.html&amp;event=video_description&amp;v=RdmdFIhCo4M&amp;redir_token=ii2yaoab_KuAW516O-i_OhpUBRh8MTU1OTU1MDI3OEAxNTU5NDYzODc4">https://www.aliexpress.com/item/2metr...</a></p>
<p>这个机器人手臂（非常）粗略地称为UR3工业机器人的80％缩放版本。它采用了相同的设计理念，即在每个接头处简单地放置一个电机/减速器执行器单元，六个执行器堆叠起来形成一个6轴臂。现在UR3使用空心力矩电机和谐振驱动器（$$$）作为执行器，这个机器人使用我在这里发布的步进电机/复合行星执行器：<a href="https://www.thingiverse.com/thing:3293562">https</a>：//www.thingiverse.com/thing:3293562 。两个大型执行器用于前两个基座接头，其中一个中型执行器用于肘关节，三个小型执行器用于腕关节。还有我在这里发布的抓手*：<a href="https://www.thingiverse.com/thing:3116728">https</a>：<a href="https://www.thingiverse.com/thing:3116728">//www.thingiverse.com/thing</a>：<a href="https://www.thingiverse.com/thing:3116728">3116728</a>。</p>
<p>对于控制器，我使用了Pololu的Tic T500步进控制器中的七个，并使用我编写的自定义固件来支持协调运动。您可以在此处找到血淋淋的详细信息，包括Windows测试实用程序：<a href="https://drive.google.com/open?id=1rKRuWC4jAOekrds_WGUC7DkwlVsk2zdb">https</a>：<a href="https://drive.google.com/open?id=1rKRuWC4jAOekrds_WGUC7DkwlVsk2zdb">//drive.google.com/open？id = 1rKRuWC4jAOekrds_WGUC7DkwlVsk2zdb</a></p>
<p>这是一项非常重要的工作，我会在时间充裕的情况下填补空白。在此期间，如果您需要我尚未获得的详细信息，请随时在评论部分发布问题。请仔细阅读这里的所有材料，并在开始构建之前向我提出任何问题 - 这_不是_一个简单的周末项目！</p>
<p><a href="https://youtu.be/7u_UjMB8tJI">https://youtu.be/7u_UjMB8tJI</a></p>
<p>这是jlauer发布的关于他的手臂的精彩视频：<a href="https://www.youtube.com/watch?v=tEbJV32GyYU">https</a>：<a href="https://www.youtube.com/watch?v=tEbJV32GyYU">//www.youtube.com/watch？v =</a>tEbJV32GyYU</p>
<p>另外，jlauer开发了他的自定义控制器板：<a href="https://www.youtube.com/watch?v=RdmdFIhCo4M">https</a>：<a href="https://www.youtube.com/watch?v=RdmdFIhCo4M">//www.youtube.com/watch？v =</a> RMmdFIhCo4M</p>
<p>*视频中显示的抓手与贴出的抓手略有不同。</p>
<p>更新：我刚刚发布了一款小型手腕执行器的防反冲版本，它具有更大的扭矩，更小的间隙并且运行更平稳：<a href="https://www.thingiverse.com/thing:3566678">https</a>：<a href="https://www.thingiverse.com/thing:3566678">//www.thingiverse.com/thing</a>：<a href="https://www.thingiverse.com/thing:3566678">3566678</a></p>
<p><strong>购买零件</strong></p>
<p><em>螺丝（近似数字）</em>
20 4-40插头1/4“ 
20 4-40插头x 3/8” 
30 6-32插头x 3/8“ 
20 4-40螺母
20 6-32螺母
30 2- 56 x 1/8“螺丝</p>
<p><em>电机</em>
这些是推荐的电机，但你可以在ebay等上找到相同的电机：
基座旋转：17HS15-1504S1（OMC）
肩高：17HS19-2004S1（OMC）
弯头：17HS13-1334S（OMC）
手腕+ 抓手（ 4）：35 PM048S8-08001（月亮）</p>
<p><em>控制器</em>
7 Pololu Tic T500（使用自定义固件编程）
4英尺24ga，2根双绞线电缆（总共4根线）
100 Jameco 100766母压接针
3/32“ 热缩管</p>
<p><em>杂项。硬件</em>
150 6毫米直径。气枪BB</p>
<p><strong>部件</strong></p>
<p>首先打印组装执行器（<a href="https://www.thingiverse.com/thing:3293562">https://www.thingiverse.com/thing:3293562</a>） - 2个大型20节距执行器，30个节距执行器中的1个，以及3个小型40节距执行器。您还需要点击每个减速器外壳背面的安装孔。对于20和30螺距执行器，使用6-32螺距，对于40螺距执行器，使用4-40螺距。</p>
<p>装配最容易从基础开始。首先将基础锥体装配到20节距执行器，使用带有6-32螺钉的中等长度电机。将四个6-32螺母压入肩板底部的凹槽中，然后将肩板连接到第一个执行器的顶部。接下来，将肩部外壳拧到肩板上。要完成肩部，请将第二个20节距执行器（带有最长电机）插入肩部外壳。</p>
<p>对于肘部，首先敲击上臂末端的四个6-32孔，然后连接弯头外壳。将30节距执行器（使用最短的NEMA 17电机）插入外壳。然后将上臂连接到肩部提升执行器的表面。</p>
<p>手腕开始时轻拍上臂末端的四个4-40孔，然后连接其中一个腕壳。然后将40个俯仰执行器中的一个插入该外壳中。接下来，将第二个腕壳连接到该执行器的表面，然后插入另一个40螺距的执行器。最后，为最终关节添加最后一个外壳和执行器。</p>
<p><strong>布线</strong></p>
<p>接线是构建机器人手臂时最棘手的问题之一。不幸的是，这些执行器没有空心中心，如花式UR3执行器，因此电缆必须以足够的松弛度绕每个关节跳动以允许关节运动。为了最大限度地减少接线，串行总线（V +，GND，TX，RX）用于分布在臂上的小型控制器板，每个电机上有一个板。</p>
<p>每个控制器板都有一组冗余的V +，GND，TX和RX引脚。这样可以很容易地使用菊花链电缆从一块板到另一块板。对于V +和GND，电路板上实际上有第二组孔用于可选的螺钉端子，但是我焊接在第二组插头中。对于TX和RX，我选择了未使用的Step和Dir引脚（您必须移除两个限流电阻以隔离这些引脚），然后在Dir和RX之间以及Step和TX之间添加跳线。</p>
<p>在制作电缆时，您需要使用GND扭转RX，使用V +扭曲TX线以提高抗噪性。因为并非每个电缆末端的所有引脚都在一起（并且因为在某些接头中没有连接器外壳的空间），所以我只是将一个母针压接到每根电线上并用热缩管绝缘。然后，您必须非常小心地将每根导线分别连接到每个引脚。（V +引脚全部连接在一起，GND引脚全部连接在一起，来自主机的TX与所有Tic RX引脚连接在一起，主机的RX与所有Tic TX引脚连接在一起。</p>
<p>请注意，在连接机器人之前（事实上，在组装之前），您应该在工作台上布置所有控制器和电机，将它们连接起来并使用测试软件测试所有内容。</p>
<p>每个Tic板应安装在其中一个Tic底座上。对于接头1和3（基座旋转和弯头），您可以使用双面胶带将每个Tic基座直接安装到电机背面。对于腕关节，Tic板和底座也将位于电机的末端，但是您需要轻松地将底座拉开以拆卸接头。因此，您可以将其塞入到位并穿上贝壳帽将它固定在那里。在底座高度接头上，电机末端没有足够的空间，因此在插入电线后，可以将其滑入电机侧面。</p>
<p>我在每个外壳中都有凹槽，用于进出电缆，还有一个小孔，用于固定拉链以将电缆固定到位。在前臂和上臂，你可以在内部蛇行电缆。</p>
<p><strong>软件和测试</strong></p>
<p>Pololu的Tic T500主板的标准固件不支持这样的手臂所需的多轴协调运动。所以我编写了自己的固件，您需要将其编程到Tic控制器中。（你可以使用标准固件，但你不能很好地同步所有的手臂关节。）不幸的是，你不能使用Pololu的USB bootloader（他们不会给我访问）所以你有使用PicKit编程器直接对板载PIC18F25K50芯片进行编程。您可以在以下位置找到此固件的所有详细信息（源代码，文档）以及如何对电路板进行编程：</p>
<p><a href="https://drive.google.com/open?id=1rKRuWC4jAOekrds_WGUC7DkwlVsk2zdb">https://drive.google.com/open?id=1rKRuWC4jAOekrds_WGUC7DkwlVsk2zdb</a></p>
<p>该目录还包含一个Windows测试程序，可用于测试单个关节，并且（非常粗略地）执行简单的机器人运动序列。包含测试程序的C ++源代码。我使用C ++ Builder的古老版本（v5.0）编写了这个，但现在有一个免费的，更现代的C ++ Builder版本（Community Edition）。</p>
<p><strong>还有待做的东西......</strong></p>
<p><em>关节限位器</em>
您会注意到每个执行器在固定环中都有一个插槽。其设计用于保持浮动关节止动件，该止动件也接合下一个关节的配合部分上的槽，以形成大于360度的关节止动件。范围。不是必须在任何地方连接限位开关，而是计划在每个关节上运行以防止归位。这种浮动止动件仍然需要设计和测试。</p>
<p><em>修改Gripper</em>
我最初发布的夹具使用了一个小型直流电机，我计划从Tic步进驱动器的一个通道运行。不幸的是，电机刷噪声会对驱动芯片造成严重破坏，因此在视频中，我使用了较早的步进驱动夹具。步进夹具有点弱，需要一些工作。</p>
<p><em>机器人运动学</em>
我到目前为止所使用的测试软件非常简陋，并且没有任何正向或反向机器人运动学。我需要添加这些函数来获得笛卡尔运动，或者更好地获取，让整个手臂在ROS（一个开源机器人操作系统）内运行。</p>
<p><em>真实文档</em>
我需要编写一本真正的手册来打印，组装，接线和运行这个机器人</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[IKPY]]></title>
        <id>https://blog.bioprinting.site/post/9J9NEqOgl</id>
        <link href="https://blog.bioprinting.site/post/9J9NEqOgl">
        </link>
        <updated>2019-05-20T14:11:18.000Z</updated>
        <content type="html"><![CDATA[<h1 id="入门">入门</h1>
<p>本教程将向您介绍IKPy的基本概念。您可以在相应的<a href="https://github.com/Phylliade/ikpy/blob/master/tutorials/Quickstart.ipynb">IPython Notebook中</a>测试实时版本。</p>
<h1 id=""><a href="https://github.com/Phylliade/ikpy/wiki#the-chain-object"></a>Chain对象</h1>
<p>这<a href="https://github.com/Phylliade/ikpy/blob/dev/src/ikpy/chain.py"><code>Chain</code></a>是您将使用的主要对象：它是您可以移动，检查和绘制的链接列表。</p>
<h2 id="-2"><a href="https://github.com/Phylliade/ikpy/wiki#creating-a-chain-from-a-urdf-file"></a>从URDF文件创建链</h2>
<p>IKPy的一个重要特性是您可以从URDF文件创建链。如果您的文件符合URDF，它将起作用！</p>
<p><code>my_chain = Chain.from_urdf_file(&quot;poppy_ergo.URDF&quot;)</code></p>
<p>要发现URDF解析的更多高级功能，请转到专用<a href="https://github.com/Phylliade/ikpy/wiki/URDF">页面</a>。</p>
<h2 id="-3"><a href="https://github.com/Phylliade/ikpy/wiki#creating-a-chain-manually"></a>手动创建链</h2>
<p>如果你不想弄乱URDF文件（还），你可以手动创建你的链：</p>
<p>来自 ikpy.link 进口链
从 ikpy.link 导入 OriginLink，URDFLink</p>
<p>left_arm_chain = Chain（name = ' left_arm '，links = [
OriginLink（）
URDFLink（
命名= “肩”，
translation_vector = [ - 10，0，5 ]，
取向= [ 0，1.57，0 ]，
转动= [ 0，1，0 ]，
）
URDFLink（
命名= “肘”，
translation_vector = [ 25，0，0 ]，
取向= [ 0，0，0 ]，
转动= [ 0，1，0 ]，
）
URDFLink（
命名= “手腕”，
translation_vector = [ 22，0，0 ]，
取向= [ 0，0，0 ]，
转动= [ 0，1，0 ]，
）
]）</p>
<h1 id="-4"><a href="https://github.com/Phylliade/ikpy/wiki#getting-the-position-of-your-chain-aka-forward-kinematics-aka-fk"></a>获得你的链的位置（又名前进运动学，又名FK）</h1>
<p>只需<code>forward_kinematics</code>使用每个关节的位置调用链的方法即可。</p>
<p><code>my_chain.forward_kinematics([0] * 7)</code></p>
<p>这将返回一个4x4变换矩阵，给出空间位置和链尖的方向。如果您不知道这些矩阵，请转到下面的“使用齐次坐标”部分。</p>
<h1 id="-5"><a href="https://github.com/Phylliade/ikpy/wiki#setting-the-position-of-your-chain-aka-inverse-kinematics-aka-ik"></a>设置链条的位置（又名反向运动学，又称IK）</h1>
<p>只需将框架矩阵（4x4 <a href="https://en.wikipedia.org/wiki/Transformation_matrix#Other_kinds_of_transformations">方向+平移矩阵</a>）传递<code>inverse_kinematics</code>给链的方法即可。</p>
<p>例如，目标位置为[2,2,2]，方向矩阵为标识：</p>
<p><code>my_chain.inverse_kinematics([[1, 0, 0, 2],
[0, 1, 0, 2],
[0, 0, 1, 2],
[0, 0, 0, 1]])</code></p>
<p>会回来：</p>
<p><code>[  0.00000000e+00,  -7.85169183e-01, -9.71977343e-01, 8.39302626e-01,   7.03536053e-05,   7.31439909e-01,  0.00000000e+00]</code></p>
<p>要获得有关Inverse Kinematics选项的更多信息，请单击此<a href="https://github.com/Phylliade/ikpy/wiki/Inverse-Kinematics">链接</a>。</p>
<h2 id="-6"><a href="https://github.com/Phylliade/ikpy/wiki#using-homogeneous-coordinates"></a>使用齐次坐标</h2>
<p>如果您不知道这些坐标并且4x4矩阵似乎排斥，则此部分适合您！</p>
<p>该矩阵只是存储平移和旋转的简单方法。要使用这样的矩阵，有一个辅助<code>geometry_utils.to_transformation_matrix(translation_vector, orientation_matrix)</code>函数可以为您计算这个矩阵：</p>
<p><code>my_chain.inverse_kinematics(geometry_utils.to_transformation_matrix(
[2, 2, 2],
[[1, 0, 0],
[0, 1, 0],
[0, 0, 1]]))</code></p>
<p>将返回与上一节完全相同的内容。</p>
<p>请注意，orientation_matrix参数是可选的。</p>
<h1 id="-7"><a href="https://github.com/Phylliade/ikpy/wiki#plotting-your-chain"></a>绘制链条</h1>
<p>您可以使用<code>plot</code>链对象的方法显示运动链，并传递链的每个关节的位置。</p>
<p>这里我们使用以下给出的位置<code>inverse_kinematics</code>：</p>
<p><code>import matplotlib.pyplot
from mpl_toolkits.mplot3d import Axes3D
ax = matplotlib.pyplot.figure().add_subplot(111, projection='3d')</p>
<p>my_chain.plot(my_chain.inverse_kinematics([
[1, 0, 0, 2],
[0, 1, 0, 2],
[0, 0, 1, 2],
[0, 0, 0, 1]
]), ax)
matplotlib.pyplot.show()</code></p>
<p>例如 ： <img src="https://github.com/Phylliade/ikpy/raw/master/tutorials/ikpy/plotting.png" alt=""></p>
<p>要使用高级绘图功能，例如在同一图形上显示多个链，请遵循<a href="https://github.com/Phylliade/ikpy/wiki/Plotting">本指南</a>。</p>
<p>&quot;&quot;&quot;
反向运动学
Pierre Manceron编辑了此页面 on 22 Jan 2016 · 3次修订
反向运动学
活动链接
在IKPy中，您可以随意激活或停用某些功能</p>
<p>例如，在这4个链接链中，通过指定掩码：</p>
<p>[True, True, False, True]
您将激活每个链接，但第三个链接：</p>
<p>要使用链接掩码，请active_links_mask在创建Chain对象时使用该参数。</p>
<p>初始位置
要计算反向运动学，算法将需要链的初始位置。您可以使用方法的initial_position参数传递它inverse_kinematics。预期的数据类型是完全一样的预期值joints的的forward_kinematics方法。</p>
<p>这是一个非常重要的参数，并且可能对计算产生巨大影响（在持续时间和返回的解决方案方面）如果您不提供它，IKPy将使用填充零的数组作为初始位置。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[DRR配准相关]]></title>
        <id>https://blog.bioprinting.site/post/_81f-aeda</id>
        <link href="https://blog.bioprinting.site/post/_81f-aeda">
        </link>
        <updated>2019-05-15T04:53:46.000Z</updated>
        <content type="html"><![CDATA[<h1 id="使用模型代替体积的数字重建射线照相"><a href="https://discourse.slicer.org/t/digitally-reconstructed-radiograph-using-models-instead-of-volumes/3309">使用模型代替体积的数字重建射线照相</a></h1>
<p>是否可以使用切片器创建模拟的X射线图像，类似于数字重建的射线照片，将3D模型作为输入而不是体积数据（即CT扫描）？我想象一个场景，其中一个或多个骨骼/植入物/工具等的3D模型（例如STL文件）可以放置在3D场景中，分配X射线衰减值，并模拟X射线图像？需要使用python的解决方案对我来说是可行的选择。</p>
<p>我知道可以根据下面链接的帖子从CT扫描生成数字重建的射线照片，但是不确定是否可以使用更简化的有限数量结构的模型来进行，每个结构都有不断的X射线衰减。我知道可以将表面模型转换为体积数据，然后生成这些体积的DRR，但与直接计算射线三角形交叉点的东西相比，这似乎是一种相当低效的解决方案（计算上）。</p>
<p>在此先感谢您的帮助！</p>
<p><a href="https://sjc2.discourse-cdn.com/standard17/uploads/slicer/original/2X/c/cac1fb6dfe1d070cfc5b7e795b4cdbe3671aabc6.png" title="屏幕截图2018-06-26 at 9.00.22 PM.png"><img src="https://sjc2.discourse-cdn.com/standard17/uploads/slicer/optimized/2X/c/cac1fb6dfe1d070cfc5b7e795b4cdbe3671aabc6_2_562x500.png" alt="22％20PM"></a>
屏幕截图2018-06-26 at 9.00.22 PM.png1432×1274 148 KB</p>
<p>尝试一下......似乎工作得相当好，但不确定它是否有资格作为“模拟”。</p>
<p>使用Image Maker模块创建空图像卷。然后导入.stl文件或其他任何内容并转换为分段（分段模块 - &gt;导入模型）。使用线性衰减系数的值填充空图像体积中的体素（查看这些对于例如您感兴趣的光子能量的骨骼，软组织，肺组织......在这里我使用10 kVp并查找来自NIST数据库），用于每个组织; 您可以在GUI中编写脚本或使用Segmentations - &gt;“Mask Volume”和Add Scalar Volumes模块的组合。最后，完成线性衰减系数贴图（图像）后，使用简单滤镜模块 - &gt; MeanProjectionImageFilter或SumProjectionImageFilter。</p>
<p>结果在右下角。</p>
<p>最好，</p>
<p>如何做到这一点有很多选择。理想的解决方案取决于您的要求（您拥有多少输入模型，您需要的分辨率，物体移动的速度，几何体的复杂程度，可用的CPU和GPU等）。</p>
<p><a href="https://discourse.slicer.org/u/hamburgerfinger">@Hamburgerfinger</a>的建议很好。生成二进制或分数卷并使用GPU渲染它也很好（在生成卷之后，GPU渲染器可能会以高帧速率渲染DRR图像）。</p>
<p>获取类似DRR图像的最简单方法可能是使用Python设置厚切片显示。例如，将此代码片段复制粘贴到Python控制台中即可开始：</p>
<p>最大强度投影：</p>
<p><code>sliceNode = slicer.mrmlScene.GetNodeByID('vtkMRMLSliceNodeRed')
appLogic = slicer.app.applicationLogic()
sliceLogic = appLogic.GetSliceLogic(sliceNode)
sliceLayerLogic = sliceLogic.GetBackgroundLayer()
reslice = sliceLayerLogic.GetReslice()
reslice.SetSlabModeToMax()
reslice.SetSlabNumberOfSlices(600)
reslice.SetSlabSliceSpacingFraction(0.5)
sliceNode.Modified()</code></p>
<p>CTChest示例数据集的结果：</p>
<p><img src="https://sjc2.discourse-cdn.com/standard17/uploads/slicer/original/1X/c9eec191b459a546649043480efe82c708c1be57.png" alt="image_00036"></p>
<p>如果将slab模式更改为mean而不是max（<code>reslice.SetSlabModeToMean()</code>），则可以获得更多类似DRR的图像，但通常会使细节更难以查看。</p>
<p>具有类似DRR的平均板模式的相同数据集：</p>
<p><img src="https://sjc2.discourse-cdn.com/standard17/uploads/slicer/original/1X/a3202605d9b9d3621af76f9e347b6e423b7a71ce.png" alt="image_00035"></p>
<p><a href="http://slicer-devel-archive.65872.n3.nabble.com/Faster-slice-view-thick-slices-and-MIP-slice-view-mode-td4033264.html">在这里 </a>查看更多示例<a href="http://slicer-devel-archive.65872.n3.nabble.com/Faster-slice-view-thick-slices-and-MIP-slice-view-mode-td4033264.html">43</a>。</p>
<p>为了在3D视图中更快地更新和显示，您可以配置体积渲染模块以显示最大强度投影（MIP）。对于最逼真的DRR渲染，您可以尝试使用Plastimatch扩展。</p>
<h1 id="vtk中光线投射法实现体绘制转"><a href="https://www.cnblogs.com/yxnchinahlj/archive/2011/04/12/2013330.html">VTK中光线投射法实现体绘制【转】</a></h1>
<p>VTK中光线投射法实现体绘制</p>
<p><img src="http://hiphotos.baidu.com/hnulilei/pic/item/034f3116810e852f972b43ef.jpg" alt=""></p>
<p>1、体绘制函数
VTK 为使用者提供了三种用于光线投射法的函数分别是：
等值面绘制函数（vtkVolumeRayCastIsosurfaceFunction）；
最大密度投影函数（vtkVolumeRayCastMIPFunction）；
合成体绘制函数（vtkVolumeRayCastCompositeFunction）
其中最常用的是合成体绘制函数，最大密度投影函数在显示血管影像方面有比较好的作用。但是如图所看到的，MIP函数没有空间立体感，也就是不能提供深度的信息。</p>
<p><img src="http://hiphotos.baidu.com/hnulilei/pic/item/187de82391787879925807e9.jpg" alt=""></p>
<p>2、不透明度映射函数
不透明度映射函数是设置光线方向上的灰度值及其不透明度映射。
vtkPiecewiseFunction *opacityTransferFunction = vtkPiecewiseFunction::New();
opacityTransferFunction-&gt;AddPoint(10, 0.0);//灰度值及不透明度值
opacityTransferFunction-&gt;AddPoint(50,0.1);
opacityTransferFunction-&gt;AddPoint(200 ,0.1);
opacityTransferFunction-&gt;AddPoint(2900,0.1);
opacityTransferFunction-&gt;AddPoint(2950,0.8);
opacityTransferFunction-&gt;AddPoint(3050,1);//不透明度值为1则为完全不透明
opacityTransferFunction-&gt;ClampingOff();</p>
<p>3、颜色映射函数
颜色映射函数是设置灰度值与RGB颜色的映射。
vtkColorTransferFunction *colorTransferFunction = vtkColorTransferFunction::New();
colorTransferFunction-&gt;AddRGBPoint(0.0, 0.91, 0.65, 0.66); //灰度值及RGB颜色值
colorTransferFunction-&gt;AddRGBPoint(30.0, 0.91, 0.65, 0.66);
colorTransferFunction-&gt;AddRGBPoint(128.0, 0.91, 0.65, 0.66);
colorTransferFunction-&gt;AddRGBPoint(1200.0, 0.43, 0.43, 0.43);
colorTransferFunction-&gt;AddRGBPoint(1800.0, 0.43, 0.43, 0.43);
colorTransferFunction-&gt;AddRGBPoint(2950, .9, 0.0, 0.0);
colorTransferFunction-&gt;AddRGBPoint(3050, .9, 0.0, 0.0);
colorTransferFunction-&gt;ClampingOff();</p>
<p>4、梯度变换函数
梯度变换函数设置灰度值变换的大小与不透明度之间的映射。
vtkPiecewiseFunction *gradient=vtkPiecewiseFunction::New();
gradient-&gt;AddPoint(50,.2);//灰度值变化梯度与不透明度的关系
gradient-&gt;AddPoint(1500,.7);
gradient-&gt;AddPoint(2000,.1);
5、体数据属性设置
vtkVolumeProperty <em>volumeProperty = vtkVolumeProperty::New();
volumeProperty-&gt;SetColor(colorTransferFunction);//载入颜色映射函数
volumeProperty-&gt;SetScalarOpacity(opacityTransferFunction);//载入不透明度映射
volumeProperty-&gt;SetGradientOpacity(gradient);//载入梯度映射
volumeProperty-&gt;ShadeOn();
volumeProperty-&gt;SetInterpolationTypeToLinear();//采用线性插值
6、光线投射函数设置及体绘制映射
本程序采用合成体绘制函数：
vtkVolumeRayCastCompositeFunction</em>compositeFunction=
vtkVolumeRayCastCompositeFunction::New();
vtkVolumeRayCastMapper *volumeMapper = vtkVolumeRayCastMapper::New();
volumeMapper-&gt;SetVolumeRayCastFunction(compositeFunction);//载入体绘制方法
volumeMapper-&gt;SetInput(append-&gt;GetOutput());//载入图像数据
volumeMapper-&gt;SetSampleDistance(.5);
vtkVolume *volume = vtkVolume::New();
volume-&gt;SetMapper(volumeMapper);//设置映射
volume-&gt;SetProperty(volumeProperty);//设置属性</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Maddux机器人库]]></title>
        <id>https://blog.bioprinting.site/post/z21-pFg7m</id>
        <link href="https://blog.bioprinting.site/post/z21-pFg7m">
        </link>
        <updated>2019-05-13T10:46:16.000Z</updated>
        <content type="html"><![CDATA[<h1 id="maddux文档">Maddux文档</h1>
<p>Maddux是一个用于创建机器人手臂模拟和实验的python库。</p>
<p>Maddux支持：</p>
<ul>
<li>任意长度的武器</li>
<li>正向运动学</li>
<li>反向运动学</li>
<li>模拟环境（包括球，目标，障碍物等对象）</li>
<li>3D环境动画</li>
<li>3D手臂动画</li>
<li>末端效应器位置和速度</li>
<li>碰撞检测（武器和物体）</li>
</ul>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 发布： | 0.1 |
| 日期： | 2016年4月24日 |
<ul>
<li><a href="http://bencaine.me/maddux/overview.html">概观</a>
<ul>
<li><a href="http://bencaine.me/maddux/overview.html#goal">目标</a></li>
<li><a href="http://bencaine.me/maddux/overview.html#why-the-name">为什么这个名字？</a></li>
</ul>
</li>
<li><a href="http://bencaine.me/maddux/tutorial.html">教程</a>
<ul>
<li><a href="http://bencaine.me/maddux/tutorial.html#creating-arms">创造武器</a></li>
<li><a href="http://bencaine.me/maddux/tutorial.html#setting-up-and-plotting-an-environment">设置和绘制环境</a></li>
<li><a href="http://bencaine.me/maddux/tutorial.html#inverse-kinematics-and-animations">反向运动学和动画</a></li>
<li><a href="http://bencaine.me/maddux/tutorial.html#saving-paths-and-creating-videos">保存路径和创建视频</a></li>
<li><a href="http://bencaine.me/maddux/tutorial.html#conclusion">结论</a></li>
</ul>
</li>
<li><a href="http://bencaine.me/maddux/maddux.html">maddux包</a>
<ul>
<li><a href="http://bencaine.me/maddux/maddux.html#submodules">子模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.html#module-maddux.environment">maddux.environment模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.html#module-maddux.plot">maddux.plot模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.html#module-maddux.predefined_environments">maddux.predefined_environments模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.html#module-maddux">模块内容</a></li>
</ul>
</li>
<li><a href="http://bencaine.me/maddux/maddux.robots.html">maddux.robots包</a>
<ul>
<li><a href="http://bencaine.me/maddux/maddux.robots.html#submodules">子模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.robots.html#module-maddux.robots.arm">maddux.robots.arm模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.robots.html#module-maddux.robots.link">maddux.robots.link模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.robots.html#module-maddux.robots.predefined_robots">maddux.robots.predefined_robots模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.robots.html#module-maddux.robots.utils">maddux.robots.utils模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.robots.html#module-maddux.robots">模块内容</a></li>
</ul>
</li>
<li><a href="http://bencaine.me/maddux/maddux.objects.html">maddux.objects包</a>
<ul>
<li><a href="http://bencaine.me/maddux/maddux.objects.html#submodules">子模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.objects.html#module-maddux.objects.ball">maddux.objects.ball模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.objects.html#module-maddux.objects.dynamic">maddux.objects.dynamic模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.objects.html#module-maddux.objects.obstacle">maddux.objects.obstacle模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.objects.html#module-maddux.objects.static">maddux.objects.static模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.objects.html#module-maddux.objects.target">maddux.objects.target模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.objects.html#module-maddux.objects.throwable">maddux.objects.throwable模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.objects.html#module-maddux.objects">模块内容</a></li>
</ul>
</li>
<li><a href="http://bencaine.me/maddux/maddux.examples.html">maddux.examples包</a>
<ul>
<li><a href="http://bencaine.me/maddux/maddux.examples.html#submodules">子模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.examples.html#module-maddux.examples.arm_animation">maddux.examples.arm_animation模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.examples.html#module-maddux.examples.arm_ball_animation">maddux.examples.arm_ball_animation模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.examples.html#module-maddux.examples.ball_animation">maddux.examples.ball_animation模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.examples.html#module-maddux.examples.find_jacob0">maddux.examples.find_jacob0模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.examples.html#module-maddux.examples.obstacle_collision">maddux.examples.obstacle_collision模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.examples.html#module-maddux.examples.plot">maddux.examples.plot模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.examples.html#module-maddux.examples.plot_arm">maddux.examples.plot_arm模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.examples.html#module-maddux.examples.plot_obstacle">maddux.examples.plot_obstacle模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.examples.html#module-maddux.examples.tutorial">maddux.examples.tutorial模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.examples.html#module-maddux.examples">模块内容</a></li>
</ul>
</li>
<li><a href="http://bencaine.me/maddux/maddux.utils.html">maddux.utils包</a>
<ul>
<li><a href="http://bencaine.me/maddux/maddux.utils.html#submodules">子模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.utils.html#module-maddux.utils.animate_path">maddux.utils.animate_path模块</a></li>
<li><a href="http://bencaine.me/maddux/maddux.utils.html#module-maddux.utils">模块内容</a></li>
</ul>
</li>
</ul>
<h1 id="指数和表格">指数和表格</h1>
<ul>
<li>
<p><a href="http://bencaine.me/maddux/genindex.html">指数</a></p>
</li>
<li>
<p><a href="http://bencaine.me/maddux/py-modindex.html">模块索引</a></p>
</li>
<li>
<p><a href="http://bencaine.me/maddux/search.html">搜索页面</a></p>
</li>
<li>
<h1 id="概观">概观</h1>
<p>Maddux是一个Python语言软件包，用于与模拟环境交互的机器人操纵器的创建，实验和可视化。</p>
<p>使用Maddux，您可以创建任意机器人操纵器，其中包含由DH参数定义的一组链接，并在自定义环境中使用这些操纵器。设计易于修改，非常适合设置实验，让武器学习执行新任务。</p>
<h2 id="目标">目标</h2>
<p>Maddux的创建是为了拥有一个简单，易于理解的工具，可以快速实验教授机器人手臂来执行不同的任务。模拟环境并不是真实的，或者具有现实世界的约束。相反，重点是快速建立一个实验来测试一个想法。</p>
<h2 id="为什么这个名字">为什么这个名字？</h2>
<p>Maddux以Greg Maddux命名，Greg Maddux是一位退役的MLB投手，被广泛认为是有史以来最好的控球投手。他以其强大的机械，命令，沉着和机智而闻名，他是机器人手臂所希望的一切。</p>
<h1 id="教程">教程</h1>
<p>在本教程中，我们将简要介绍创建手臂，设置模拟环境，绘制和动画这些环境，保存机器人移动路径以及创建动画视频。</p>
<h2 id="创造武器">创造武器</h2>
<p>Maddux中的Arms由一系列Link对象组成，这些对象由<a href="https://en.wikipedia.org/wiki/Denavit%E2%80%93Hartenberg_parameters">DH参数</a>定义。每个链接都有θ（角度），偏移，长度和扭曲参数。每个链接还可以具有约束θ，最大速度和关节尺寸（用于可视化和碰撞）。</p>
<p>如果您不熟悉DH参数，我建议您先阅读它们，因为它们可能有点令人困惑。例如，从一个关节到另一个关节的距离可以由偏移或长度来定义。</p>
<p>以下是我们在maddux.robots.predefined_arms中为您定义的“简单人类手臂”的定义。</p>
<p>从 链接 导入 链接
从 手臂 进口 臂
进口 numpy的 为 NP</p>
<p>seg1_len  =  1.0
seg2_len  =  2.0</p>
<p>＃我们的七个“链接”。其中只有两个具有长度或偏移量。
L1  =  链接（0 ， 0 ， 0 ， 1.571 ）
L2  =  链接（0 ， 0 ， 0 ， - 1.571 ）
L3  =  链接（0 ， seg1_len ， 0 ， - 1.571 ）
L4  =  链接（0 ， 0 ， seg2_len ， - 1.571 ）
L5 =  链接（0 ， 0 ， 0 ， 1.571 ）
L6  =  链接（0 ， 0 ， 0 ， 1.571 ）
L7  =  链接（0 ， 0 ， 0 ， 0 ）</p>
<p>＃创建一个数组
links  =  np 。阵列（[ L1 ， L2 ， L3 ， L4 ， L5 ， L6 ， L7 ]）</p>
<p>＃为每个链接创建一个初始联合配置。
＃q0 [0]是Link1的theta
＃q0 [1]是Link2
＃
的theta ，依此类推。q0  =  np 。阵列（[ 0 ， 0 ， 0 ， - 2.0 ， 0 ， 0 ， 0 ]）</p>
<p>＃然后用这些链接创建一个arm，初始配置q0，名称
robot  =  Arm （links ， q0 ， 'simple_human_arm' ）</p>
<p>值得注意的是，只有两个链接具有偏移或长度，为我们提供了两个链接臂。L7根本不是必需的，只是替换可能的末端执行器。</p>
<h2 id="设置和绘制环境">设置和绘制环境</h2>
<p>环境是Maddux中所有模拟的核心。它们允许您将动态（可移动）和静态（静止）对象组以及机器人组合成各种类型的“房间”，以允许所有这些对象的交互。</p>
<p>要定义一个环境，我们将首先定义一些对象，然后我们将创建一个机器人（来自我们预定义的机器人），然后我们将这些添加到环境中。</p>
<p>导入 numpy的 是 NP
从 maddux.robots.predefined_robots  导入 simple_human_arm
从 maddux.objects  导入已 球， 目标， 障碍
来自 maddux.environment  进口 环境</p>
<p>＃创建一个具有特定配置和基准位置的臂
q0  =  np 。阵列（[ 0.5 ， 0.2 ， 0 ， 0.5 ， 0 ， 0 ， 0 ]）
base_pos  =  NP 。阵列（[ 2.0 ， 2.0 ， 0.0 ]）</p>
<p>长度2.0的＃和链路段
臂 =  simple_human_arm （2.0 ， 2.0 ， Q0 ， base_pos ）</p>
<p>＃然后，我们创造了一个球，目标，和障碍物
球 =  球（位置= [ 2.0 ， 0.0 ， 2.0 ]， 半径= 0.15 ）
目标 =  目标（位置= [ 5.0 ， 8.0 ， 2.0 ]， 半径= 0.5 ）
障碍物 =  障碍（[ 4 ， 4 ， 0 ]， [ 5 ， 5 ， 2 ]）</p>
<p>＃并使用这些以产生具有尺寸的环境10x10x10
ENV  =  环境（尺寸= [ 10 ， 10 ， 10 ]，
dynamic_objects = [ 球]，
static_objects = [ 障碍， 靶]，
机器人= 臂）</p>
<p>然后，我们可以与这些对象进行交互，绘制它们，为它们的交互设置动画等。</p>
<p>如果我们想要绘制这个环境，我们所要做的就是</p>
<p>ENV 。情节（）</p>
<p>哪个会生成如下所示的环境：</p>
<p><img src="http://bencaine.me/maddux/_images/tutorial_1.png" alt="_images / tutorial_1.png"></p>
<h2 id="反向运动学和动画">反向运动学和动画</h2>
<p>鉴于上述环境，假设我们想让手臂找到一个关节配置，让手臂的末端效应器接触球。给定球的位置，我们可以使用Arm类中内置的迭代反向运动学求解器来找到可能的关节配置。</p>
<p>手臂。ikine （球。位置）</p>
<p>我们的反向运动求解器自动将构成其路径的每组配置缓存到臂上的变量中。保存此路径后，我们可以通过调用指定持续时间的动画来设置此过程的动画。</p>
<p>ENV 。动画（3.0 ）</p>
<h2 id="保存路径和创建视频">保存路径和创建视频</h2>
<p>在上面的反向运动学示例中，ikine将其生成的路径保存到臂上的变量中。在调用一些修改联合配置（update_angles，update_link_angle，ikine）并让它缓存其更改的函数之后，我们可以将该路径写入文件。</p>
<p>手臂。save_path （'filename_to_save_to' ）</p>
<p>通过将一系列关节配置保存到文件中，我们以后可以使用它来重新运行动画，或者将动画保存为MP4视频。为此，我们只需在arm上调用save_path。我们假设我们的环境是在maddux.predefined_environments.py中定义的。</p>
<p>要简单地重新运行动画，我们就可以运行了</p>
<p>python maddux / utils / animate_path.py --input tutorial_path.npy --environment tutorial</p>
<p>如果我们想创建一个名为tutorial.mp4的视频，我们会将上述命令更改为此</p>
<p>python maddux / utils / animate_path.py --input tutorial_path.npy --environment tutorial --output tutorial.mp4</p>
<p>哪个会创建一个视频然后我变成这个GIF。</p>
<p><img src="http://bencaine.me/maddux/_images/tutorial.gif" alt="_images / tutorial.gif"></p>
<h2 id="结论">结论</h2>
<p>这是为了快速介绍工具包的不同方面。还有许多其他潜在有用的功能，例如动态物体具有速度和运动，让手臂握住并用其末端执行器移动物体，提供臂关节速度，以及根据关节速度计算末端执行器速度。希望这提供了一个轻量级和灵活的工具包，可以根据您的需求进行构建和修改，并让您尽快启动并运行疯狂的想法。</p>
<h1 id="maddux包">maddux包</h1>
<h2 id="子模块">子模块</h2>
<h2 id="madduxenvironment模块">maddux.environment模块</h2>
<p>我们的实验环境。</p>
<dt id="maddux.environment.Environment">_class_`maddux.environment.``Environment`（_dimension = None_，_dynamic_objects = None_，_static_objects = None_，_robot = None _）[[来源]](http://bencaine.me/maddux/_modules/maddux/environment.html#Environment)</dt>
<dt id="maddux.environment.Environment.animate">`animate`（_duration = None_，_save_path = None _）[[来源]](http://bencaine.me/maddux/_modules/maddux/environment.html#Environment.animate)</dt>
<p>动画程序的运行</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | 
<ul>
<li><strong>duration</strong>（<em>int或None</em>） - （可选）动画的持续时间（以秒为单位）</li>
<li><strong>save_path</strong>（<em>String或None</em>） - （可选）保存mp4而不是显示的路径</li>
</ul>
<p>|
| 返回类型： |</p>
<p><a href="https://docs.python.org/library/constants.html#None" title="（在Python v2.7中）">没有</a></p>
<p>|</p>
<dt id="maddux.environment.Environment.collision">`collision`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/environment.html#Environment.collision)</dt>
<p>检查是否有任何动态对象与任何静态对象或墙壁发生碰撞。</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 返回值： | 是否有碰撞 |
| 返回类型： | [布尔](https://docs.python.org/library/functions.html#bool "（在Python v2.7中）") |
<dt id="maddux.environment.Environment.hypothetical_landing_position">`hypothetical_landing_position`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/environment.html#Environment.hypothetical_landing_position)</dt>
<p>找到球落地（或击中墙壁）的位置</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 返回值： | 基于末端执行器速度的投掷物体的假设着陆位置的位置（x，y，z）。 |
| 返回类型： | numpy.ndarray或无 |
<dt id="maddux.environment.Environment.plot">`plot`（_ax = None_，_show = True _）[[来源]](http://bencaine.me/maddux/_modules/maddux/environment.html#Environment.plot)</dt>
<p>绘制投掷轨迹和球</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | 
<ul>
<li><strong>ax</strong>（<em>matplotlib.axes</em>） - 如果数字已经存在，则为当前轴</li>
<li><strong>show</strong>（<a href="https://docs.python.org/library/functions.html#bool" title="（在Python v2.7中）"><em>bool</em></a>） - （默认值：True）是否显示数字</li>
</ul>
<p>|
| 返回类型： |</p>
<p><a href="https://docs.python.org/library/constants.html#None" title="（在Python v2.7中）">没有</a></p>
<p>|</p>
<dt id="maddux.environment.Environment.run">`run`（_持续时间_）[[来源]](http://bencaine.me/maddux/_modules/maddux/environment.html#Environment.run)</dt>
<p>运行一段时间</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **duration**（_整数_） - 以秒为单位运行环境的持续时间 |
| 返回类型： | [没有](https://docs.python.org/library/constants.html#None "（在Python v2.7中）") |
<h2 id="madduxplot模块">maddux.plot模块</h2>
<dt id="maddux.plot.plot_sphere">`maddux.plot.``plot_sphere`（_位置_，_半径_，_轴_，_颜色='g'_，_线宽= 0 _）[[来源]](http://bencaine.me/maddux/_modules/maddux/plot.html#plot_sphere)</dt>
<p>绘制球体。</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | 
<ul>
<li><strong>position</strong>（<em>numpy.ndarray</em>） - 在球体的（x，y，z）中的位置</li>
<li><strong>radius</strong>（<a href="https://docs.python.org/library/functions.html#int" title="（在Python v2.7中）"><em>int</em></a>） - 球体半径</li>
<li><strong>ax</strong>（<em>matplotlib.axes</em>） - 要绘制的轴</li>
<li><strong>color</strong>（<a href="https://docs.python.org/library/functions.html#str" title="（在Python v2.7中）"><em>str</em></a>） - （可选）球体颜色</li>
<li><strong>linewidth</strong>（<a href="https://docs.python.org/library/functions.html#int" title="（在Python v2.7中）"><em>int</em></a>） - （可选）球网格线的宽度</li>
</ul>
<p>|
| 返回类型： |</p>
<p>matplotlib.axes</p>
<p>|</p>
<dt id="maddux.plot.plot_sphere_data">`maddux.plot.``plot_sphere_data`（_位置_，_半径_）[[来源]](http://bencaine.me/maddux/_modules/maddux/plot.html#plot_sphere_data)</dt>
<p>给定位置和半径，获取绘图所需的数据。</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | 
<ul>
<li><strong>position</strong>（<em>numpy.ndarray</em>） - 在球体的（x，y，z）中的位置</li>
<li><strong>radius</strong>（<a href="https://docs.python.org/library/functions.html#int" title="（在Python v2.7中）"><em>int</em></a>） - 球体半径</li>
</ul>
<p>|
| 返回值： |</p>
<p>（x，y，z）用于创建曲面的球体数据元组</p>
<p>|
| 返回类型： |</p>
<p>（np.ndarray，np.ndarray，np.ndarray）</p>
<p>|</p>
<h2 id="madduxpredefined_environments模块">maddux.predefined_environments模块</h2>
<dt id="maddux.predefined_environments.get_easy_environment">`maddux.predefined_environments.``get_easy_environment`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/predefined_environments.html#get_easy_environment)</dt>
<p>一个简单的难度环境，用于规划具有两个障碍的测试，一个球作为目标，一个简单的人类手臂。</p>
<dt id="maddux.predefined_environments.get_hard_environment">`maddux.predefined_environments.``get_hard_environment`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/predefined_environments.html#get_hard_environment)</dt>
<p>一个艰难的难度环境，用于规划具有五个障碍的测试，一个球作为目标，一个简单的人类手臂。</p>
<dt id="maddux.predefined_environments.get_medium_environment">`maddux.predefined_environments.``get_medium_environment`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/predefined_environments.html#get_medium_environment)</dt>
<p>一个中等难度的环境，用于规划具有两个障碍的测试，一个球作为目标，一个简单的人类手臂。</p>
<dt id="maddux.predefined_environments.get_noodle_environment">`maddux.predefined_environments.``get_noodle_environment`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/predefined_environments.html#get_noodle_environment)</dt>
<p>我们的面条臂进行规划测试的荒谬环境。它有五个障碍，一个球作为目标，我们的10个链接面条臂</p>
<dt id="maddux.predefined_environments.get_tutorial_environment">`maddux.predefined_environments.``get_tutorial_environment`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/predefined_environments.html#get_tutorial_environment)</dt>
<p>我们的环境来自文档教程</p>
<dt id="maddux.predefined_environments.get_very_hard_environment">`maddux.predefined_environments.``get_very_hard_environment`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/predefined_environments.html#get_very_hard_environment)</dt>
<p>一个非常困难的难度环境，用于规划具有三个障碍的测试，一个球作为目标，一个简单的人类手臂。</p>
<h2 id="模块内容">模块内容</h2>
<h1 id="madduxrobots包">maddux.robots包</h1>
<h2 id="子模块-2">子模块</h2>
<h2 id="madduxrobotsarm模块">maddux.robots.arm模块</h2>
<p>由一系列DH链接定义的机器人手臂</p>
<dt id="maddux.robots.arm.Arm">_class_`maddux.robots.arm.``Arm`（_links_，_q0_，_name_，_active_links = None_，_base = None_，_tool = None _）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/arm.html#Arm)</dt>
<dt id="maddux.robots.arm.Arm.end_effector_position">`end_effector_position`（_q =无_）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/arm.html#Arm.end_effector_position)</dt>
<p>返回末端执行器位置</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **q**（_numpy.ndarray或None_） - 配置计算给定1xN q向量的末端效应器位置 |
| 返回值： | 末端执行器的位置（x，y，z） |
| 返回类型： | numpy.ndarray |
<dt id="maddux.robots.arm.Arm.end_effector_velocity">`end_effector_velocity`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/arm.html#Arm.end_effector_velocity)</dt>
<p>给出其当前角速度，计算手臂的末端执行器速度。</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 返回值： | 返回每个维度（vx，vy，vz，wx，wy，wz）的线性和角速度。 |
| 返回类型： | np.ndarray |
<dt id="maddux.robots.arm.Arm.fkine">`fkine`（_q =无_，_链接=无_）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/arm.html#Arm.fkine)</dt>
<p>使用当前关节配置或给定的关节配置计算手臂的正向运动</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | 
<ul>
<li><strong>q</strong>（<em>numpy.ndarray或None</em>） - （可选）用于计算FK的联合配置的1xN向量</li>
<li><strong>links</strong>（<em>int或None</em>） - （可选）指定要在其上运行fkine的链接。例如：links = [1,2,3]。</li>
</ul>
<p>|
| 返回值： |</p>
<p>指定的链接列表或末端效应器末尾的同源坐标点</p>
<p>|
| 返回类型： |</p>
<p>4x4 numpy.array</p>
<p>|</p>
<dt id="maddux.robots.arm.Arm.get_current_joint_config">`get_current_joint_config`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/arm.html#Arm.get_current_joint_config)</dt>
<p>从链接获取当前联合配置</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 返回值： | 当前联合配置的1xN向量 |
| 返回类型： | numpy.ndarray |
<dt id="maddux.robots.arm.Arm.hold">`hold`（_obj _）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/arm.html#Arm.hold)</dt>
<p>持有一个特定的对象</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **obj**（_maddux.objects.DynamicObject_） - 要保留的对象 |
| 返回类型： | [没有](https://docs.python.org/library/constants.html#None "（在Python v2.7中）") |
<dt id="maddux.robots.arm.Arm.ikine">`ikine`（_p_，_num_iterations = 1000_，_alpha = 0.1 _）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/arm.html#Arm.ikine)</dt>
<p>计算反向运动学以找到到达给定点的正确关节配置</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | 
<ul>
<li><strong>p</strong>（<em>numpy.ndarray</em>） - 解决逆运动学的点（x，y，z）</li>
<li><strong>num_iterations</strong>（<a href="https://docs.python.org/library/functions.html#int" title="（在Python v2.7中）"><em>int</em></a>） - 放弃之前要尝试的迭代次数</li>
<li><strong>alpha</strong>（<a href="https://docs.python.org/library/functions.html#int" title="（在Python v2.7中）"><em>int</em></a>） - ikine求解器的步长（0.0 - 1.0）</li>
</ul>
<p>|
| 返回值： |</p>
<p>给定点p的关节配置的1xN向量。</p>
<p>|
| 返回类型： |</p>
<p>numpy.ndarray</p>
<p>|</p>
<dt id="maddux.robots.arm.Arm.is_in_collision">`is_in_collision`（_env_object _）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/arm.html#Arm.is_in_collision)</dt>
<p>检查手臂是否与给定物体发生碰撞</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **env_object**（_maddux.Objects.StaticObject_） - 检查与之冲突的对象 |
| 返回值： | 你是否点击了env_object |
| 返回类型： | [布尔](https://docs.python.org/library/functions.html#bool "（在Python v2.7中）") |
<dt id="maddux.robots.arm.Arm.jacob0">`jacob0`（_q =无_）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/arm.html#Arm.jacob0)</dt>
<p>通过在工具框架中找到它然后转换为世界框架来计算世界框架中的雅可比。</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **q**（_numpy.ndarray_） - （可选）1xN联合配置来计算jacobian |
| 返回值： | 世界框架中的6xN雅可比行列式 |
| 返回类型： | numpy.matrix |
<dt id="maddux.robots.arm.Arm.jacobn">`jacobn`（_q =无_）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/arm.html#Arm.jacobn)</dt>
<p>计算工具框架中的雅可比</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **q**（_1xN numpy.ndarray_） - （可选）1xN联合配置来计算jacobian |
| 返回值： | 工具框架中的6xN雅可比行列式 |
| 返回类型： | numpy.matrix |
<dt id="maddux.robots.arm.Arm.plot">`plot`（_ax _）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/arm.html#Arm.plot)</dt>
<p>将我们的机器人绘制到给定的轴上</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **ax**（_matplotlib.axes_） - 情节轴 |
| 返回类型： | [没有](https://docs.python.org/library/constants.html#None "（在Python v2.7中）") |
<dt id="maddux.robots.arm.Arm.release">`release`（_object_idx =无_）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/arm.html#Arm.release)</dt>
<p>释放一个或所有当前保留的对象</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **object_idx** - （可选）要释放的对象的索引 |
<p>：type object_idx = int或None</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 返回类型： | [没有](https://docs.python.org/library/constants.html#None "（在Python v2.7中）") |
<dt id="maddux.robots.arm.Arm.reset">`reset`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/arm.html#Arm.reset)</dt>
<p>将手臂重置回其静止状态，即q0</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 返回类型： | [没有](https://docs.python.org/library/constants.html#None "（在Python v2.7中）") |
<dt id="maddux.robots.arm.Arm.save_path">`save_path`（_文件名_）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/arm.html#Arm.save_path)</dt>
<p>将当前路径保存到文件：param filename：保存联合配置路径的文件名：键入filename：str</p>
<dt id="maddux.robots.arm.Arm.update_angles">`update_angles`（_new_angles_，_save = False _）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/arm.html#Arm.update_angles)</dt>
<p>更新所有链接的角度</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | 
<ul>
<li><strong>new_angles</strong>（<em>numpy.ndarray</em>） - 新链接角度的1xN向量</li>
<li><strong>save</strong> - 确定是否缓存更新的标志</li>
<li><strong>保存</strong> - 布尔</li>
</ul>
<p>|
| 返回类型： |</p>
<p><a href="https://docs.python.org/library/constants.html#None" title="（在Python v2.7中）">没有</a></p>
<p>|</p>
<dt id="maddux.robots.arm.Arm.update_link_angle">`update_link_angle`（_link_，_new_angle_，_save = False _）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/arm.html#Arm.update_link_angle)</dt>
<p>使用给定角度更新给定链接的角度</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | 
<ul>
<li><strong>link</strong>（<a href="https://docs.python.org/library/functions.html#int" title="（在Python v2.7中）"><em>int</em></a>） - 要更新的链接</li>
<li><strong>new_angle</strong>（<a href="https://docs.python.org/library/functions.html#int" title="（在Python v2.7中）"><em>int</em></a>） - 链接的新角度</li>
<li><strong>save</strong>（<a href="https://docs.python.org/library/functions.html#bool" title="（在Python v2.7中）"><em>bool</em></a>） - 确定是否缓存更新的标志</li>
</ul>
<p>|
| 返回类型： |</p>
<p><a href="https://docs.python.org/library/constants.html#None" title="（在Python v2.7中）">没有</a></p>
<p>|</p>
<dt id="maddux.robots.arm.Arm.update_link_positions">`update_link_positions`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/arm.html#Arm.update_link_positions)</dt>
<p>浏览所有链接并更新其位置。</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 返回类型： | [没有](https://docs.python.org/library/constants.html#None "（在Python v2.7中）") |
<dt id="maddux.robots.arm.Arm.update_link_velocity">`update_link_velocity`（_链接_，_加速_，_时间_）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/arm.html#Arm.update_link_velocity)</dt>
<p>在给定时间内以给定加速度更新给定链接的速度</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | 
<ul>
<li><strong>link</strong>（<a href="https://docs.python.org/library/functions.html#int" title="（在Python v2.7中）"><em>int</em></a>） - 要更新的链接</li>
<li><strong>accel</strong>（<a href="https://docs.python.org/library/functions.html#int" title="（在Python v2.7中）"><em>int</em></a>） - 加速度（每秒弧度^ 2）</li>
<li><strong>time</strong>（<a href="https://docs.python.org/library/functions.html#int" title="（在Python v2.7中）"><em>int</em></a>） - 时间（秒）</li>
</ul>
<p>|
| 返回类型： |</p>
<p><a href="https://docs.python.org/library/constants.html#None" title="（在Python v2.7中）">没有</a></p>
<p>|</p>
<h2 id="madduxrobotslink模块">maddux.robots.link模块</h2>
<p>Link对象包含与机器人链接相关的所有信息，例如DH参数和与世界相关的位置。</p>
<dt id="maddux.robots.link.Link">_class_`maddux.robots.link.``Link`（_theta_，_offset_，_length_，_twist_，_q_lim = None_，_max_velocity = 30.0_，_link_size = 0.1_，_connector_size = 0.1 _）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/link.html#Link)</dt>
<dt id="maddux.robots.link.Link.compute_transformation_matrix">`compute_transformation_matrix`（_q _）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/link.html#Link.compute_transformation_matrix)</dt>
<p>从当前theta到新theta的变换矩阵</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **q**（[_int_](https://docs.python.org/library/functions.html#int "（在Python v2.7中）")） - 新的theta |
| 返回值： | 从当前q到提供q的变换矩阵 |
| 返回类型： | 4x4 numpy矩阵 |
<dt id="maddux.robots.link.Link.display">`display`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/link.html#Link.display)</dt>
<p>很好地显示链接的属性</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 返回类型： | [没有](https://docs.python.org/library/constants.html#None "（在Python v2.7中）") |
<dt id="maddux.robots.link.Link.is_in_collision">`is_in_collision`（_env_object _）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/link.html#Link.is_in_collision)</dt>
<p>检查手臂是否与给定的静态物体发生碰撞</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **env_object**（_maddux.objects.StaticObject_） - 检查与之冲突的对象 |
| 返回值： | 链接是否命中提供的env_object |
| 返回类型： | [布尔](https://docs.python.org/library/functions.html#bool "（在Python v2.7中）") |
<dt id="maddux.robots.link.Link.plot">`plot`（_ax _）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/link.html#Link.plot)</dt>
<p>绘制给定matplotlib图上的链接</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **ax**（_matplotlib.axes_） - 用于绘制链接的图 |
| 返回类型： | [没有](https://docs.python.org/library/constants.html#None "（在Python v2.7中）") |
<dt id="maddux.robots.link.Link.set_theta">`set_theta`（_theta _）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/link.html#Link.set_theta)</dt>
<p>将theta设置为新的theta并计算新的变换矩阵</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **theta**（[_int_](https://docs.python.org/library/functions.html#int "（在Python v2.7中）")） - 链接的新theta |
| 返回类型： | [没有](https://docs.python.org/library/constants.html#None "（在Python v2.7中）") |
<dt id="maddux.robots.link.Link.update_velocity">`update_velocity`（_加速_，_时间_）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/link.html#Link.update_velocity)</dt>
<p>在一段时间内通过某种加速作用时，更新链路的当前速度</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | 
<ul>
<li><strong>accel</strong>（<a href="https://docs.python.org/library/functions.html#int" title="（在Python v2.7中）"><em>int</em></a>） - 作用于链路的加速度（每秒弧度^ 2）</li>
<li><strong>time</strong>（<a href="https://docs.python.org/library/functions.html#int" title="（在Python v2.7中）"><em>int</em></a>） - 应用加速度的时间（秒）</li>
</ul>
<p>|
| 返回类型： |</p>
<p><a href="https://docs.python.org/library/constants.html#None" title="（在Python v2.7中）">没有</a></p>
<p>|</p>
<h2 id="madduxrobotspredefined_robots模块">maddux.robots.predefined_robots模块</h2>
<dt id="maddux.robots.predefined_robots.noodle_arm">`maddux.robots.predefined_robots.``noodle_arm`（_seg_lens_，_q0_，_base = None _）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/predefined_robots.html#noodle_arm)</dt>
<p>创建一个包含10个段的复杂臂</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | 
<ul>
<li><strong>seg_lens</strong>（<em>numpy.ndarray</em>） - 每个部分长度的1x10向量</li>
<li><strong>q0</strong>（<em>numpy.ndarray</em>） - 起始关节配置的1xN向量</li>
<li><strong>base</strong>（<em>numpy.ndarray或None</em>） - （可选）arm的可选（x，y，z）基本位置</li>
</ul>
<p>|
| 返回值： |</p>
<p>“面条”的手臂</p>
<p>|
| 返回类型： |</p>
<p>maddux.robot.Arm</p>
<p>|</p>
<dt id="maddux.robots.predefined_robots.simple_human_arm">`maddux.robots.predefined_robots.``simple_human_arm`（_seg1_len_，_seg2_len_，_q0_，_base = None _）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/predefined_robots.html#simple_human_arm)</dt>
<p>创建一个简单的类似人类的机器人手臂，具有7个链接和2个具有所需长度和起始关节配置的段</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | 
<ul>
<li><strong>seg1_len</strong>（<a href="https://docs.python.org/library/functions.html#int" title="（在Python v2.7中）"><em>int</em></a>） - 手臂第一段的长度</li>
<li><strong>seg2_len</strong>（<a href="https://docs.python.org/library/functions.html#int" title="（在Python v2.7中）"><em>int</em></a>） - 手臂第二段的长度</li>
<li><strong>q0</strong>（<em>numpy.ndarray</em>） - 起始关节配置的1xN向量</li>
<li><strong>base</strong>（<em>numpy.ndarray或None</em>） - （可选）（x，y，z）手臂基座的位置</li>
</ul>
<p>|
| 返回值： |</p>
<p>7个链接，2段“人”手臂。</p>
<p>|
| 返回类型： |</p>
<p>maddux.robot.Arm</p>
<p>|</p>
<h2 id="madduxrobotsutils模块">maddux.robots.utils模块</h2>
<p>随机收集机器人使用的实用程序</p>
<dt id="maddux.robots.utils.create_homogeneous_transform_from_point">`maddux.robots.utils.``create_homogeneous_transform_from_point`（_p _）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/utils.html#create_homogeneous_transform_from_point)</dt>
<p>创建一个齐次变换以移动到给定点</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **p**（_numpy.ndarray_） - 我们希望我们的均匀变换移动到的（x，y，z）点 |
| 返回值： | 4x4点的均匀变换 |
| 返回类型： | numpy.matrix |
<dt id="maddux.robots.utils.create_point_from_homogeneous_transform">`maddux.robots.utils.``create_point_from_homogeneous_transform`（_T _）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/utils.html#create_point_from_homogeneous_transform)</dt>
<p>从齐次变换创建一个点</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **T**（_numpy矩阵_） - 4x4齐次变换 |
| 返回值： | 变换点的（x，y，z）坐标 |
| 返回类型： | np.ndarray |
<dt id="maddux.robots.utils.get_rotation_from_homogeneous_transform">`maddux.robots.utils.``get_rotation_from_homogeneous_transform`（_变换_）[[来源]](http://bencaine.me/maddux/_modules/maddux/robots/utils.html#get_rotation_from_homogeneous_transform)</dt>
<p>提取均匀变换的旋转部分</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **transform**（_numpy.ndarray_） - 4x4齐次变换从中提取旋转矩阵。 |
| 返回值： | 3x3旋转矩阵 |
| 返回类型： | numpy.matrix |
</li>
<li>
<h1 id="madduxobjects包">maddux.objects包</h1>
<h2 id="子模块-3">子模块</h2>
<h2 id="madduxobjectsball模块">maddux.objects.ball模块</h2>
<p>投掷的球对象。</p>
<dt id="maddux.objects.ball.Ball">_class_`maddux.objects.ball.``Ball`（_position_，_radius_，_target = False _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/ball.html#Ball)</dt>
<p>基地： <a href="http://bencaine.me/maddux/maddux.objects.html#maddux.objects.throwable.ThrowableObject" title="maddux.objects.throwable.ThrowableObject"><code>maddux.objects.throwable.ThrowableObject</code></a></p>
<dt id="maddux.objects.ball.Ball.plot">`plot`（_ax _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/ball.html#Ball.plot)</dt>
<p>在当前位置绘制球。</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **ax**（_matplotlib.axes_） - 图上绘图。 |
| 返回值： | Matplotlib图 |
| 返回类型： | matplotlib.axes |
<h2 id="madduxobjectsdynamic模块">maddux.objects.dynamic模块</h2>
<p>动态对象的抽象基类。</p>
<dt id="maddux.objects.dynamic.DynamicObject">_class_`maddux.objects.dynamic.``DynamicObject`（_position_，_target = False _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/dynamic.html#DynamicObject)</dt>
<p>基地： <a href="https://docs.python.org/library/functions.html#object" title="（在Python v2.7中）"><code>object</code></a></p>
<dt id="maddux.objects.dynamic.DynamicObject.attach">`attach`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/dynamic.html#DynamicObject.attach)</dt>
<p>附加到对象（停止移动）</p>
<dt id="maddux.objects.dynamic.DynamicObject.display">`display`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/dynamic.html#DynamicObject.display)</dt>
<p>显示信息</p>
<dt id="maddux.objects.dynamic.DynamicObject.plot">`plot`（_ax _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/dynamic.html#DynamicObject.plot)</dt>
<p>在当前位置绘制动态对象</p>
<dt id="maddux.objects.dynamic.DynamicObject.step">`step`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/dynamic.html#DynamicObject.step)</dt>
<p>及时前进（一毫秒）</p>
<h2 id="madduxobjectsobstacle模块">maddux.objects.obstacle模块</h2>
<p>一种固定的长方形固体，可能会碰撞</p>
<dt id="maddux.objects.obstacle.Obstacle">_class_`maddux.objects.obstacle.``Obstacle`（_pt1_，_pt2_，_color ='r' _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/obstacle.html#Obstacle)</dt>
<p>基地： <a href="http://bencaine.me/maddux/maddux.objects.html#maddux.objects.static.StaticObject" title="maddux.objects.static.StaticObject"><code>maddux.objects.static.StaticObject</code></a></p>
<dt id="maddux.objects.obstacle.Obstacle.display">`display`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/obstacle.html#Obstacle.display)</dt>
<p>显示障碍物属性</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 返回类型： | [没有](https://docs.python.org/library/constants.html#None "（在Python v2.7中）") |
<dt id="maddux.objects.obstacle.Obstacle.get_paths">`get_paths`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/obstacle.html#Obstacle.get_paths)</dt>
<p>返回矩形的每个曲面的路径以进行绘图。</p>
<p>：返回（底部，顶部，前部，后部，左侧，右侧）：rtype：6个4x3 numpy.ndarrays的列表</p>
<dt id="maddux.objects.obstacle.Obstacle.is_hit">`is_hit`（_位置_）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/obstacle.html#Obstacle.is_hit)</dt>
<p>检查矩形是否被点或路径击中</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **position**（_numpy.ndarray或numpy.matrix_） - 一个对象位置（x，y，z）或位置，如果它是一个路径（[x1，x2，..]，[y1，y2，..]，[z1， z2，..] |
| 返回值： | 障碍物是否被点或路径击中 |
| 返回类型： | [布尔](https://docs.python.org/library/functions.html#bool "（在Python v2.7中）") |
<dt id="maddux.objects.obstacle.Obstacle.is_hit_by_sphere">`is_hit_by_sphere`（_中心_，_半径_）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/obstacle.html#Obstacle.is_hit_by_sphere)</dt>
<p>检查矩形是否被球体击中</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | 
<ul>
<li><strong>中心</strong>（<em>numpy.ndarray</em>） - 球体的中心（x，y，z）</li>
<li><strong>radius</strong>（<a href="https://docs.python.org/library/functions.html#int" title="（在Python v2.7中）"><em>int</em></a>） - 球体的半径</li>
</ul>
<p>|
| 返回值： |</p>
<p>障碍物是否被球体击中</p>
<p>|
| 返回类型： |</p>
<p><a href="https://docs.python.org/library/functions.html#bool" title="（在Python v2.7中）">布尔</a></p>
<p>|</p>
<dt id="maddux.objects.obstacle.Obstacle.plot">`plot`（_ax _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/obstacle.html#Obstacle.plot)</dt>
<p>在其位置绘制障碍物</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **ax**（_matplotlib.axes_） - 图上绘图 |
| Rtpye： | 没有 |
<h2 id="madduxobjectsstatic模块">maddux.objects.static模块</h2>
<p>静态对象的抽象基类。</p>
<dt id="maddux.objects.static.StaticObject">_班_`maddux.objects.static.``StaticObject`[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/static.html#StaticObject)</dt>
<p>基地： <a href="https://docs.python.org/library/functions.html#object" title="（在Python v2.7中）"><code>object</code></a></p>
<dt id="maddux.objects.static.StaticObject.display">`display`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/static.html#StaticObject.display)</dt>
<p>显示有关静态对象的相关数据。</p>
<dt id="maddux.objects.static.StaticObject.is_hit">`is_hit`（_位置_）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/static.html#StaticObject.is_hit)</dt>
<p>判断另一个对象是否命中静态对象</p>
<dt id="maddux.objects.static.StaticObject.plot">`plot`（_ax _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/static.html#StaticObject.plot)</dt>
<p>绘制静态对象。</p>
<h2 id="madduxobjectstarget模块">maddux.objects.target模块</h2>
<p>某物可能与之碰撞的静止物体。</p>
<dt id="maddux.objects.target.Target">_class_`maddux.objects.target.``Target`（_position_，_radius _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/target.html#Target)</dt>
<p>基地： <a href="http://bencaine.me/maddux/maddux.objects.html#maddux.objects.static.StaticObject" title="maddux.objects.static.StaticObject"><code>maddux.objects.static.StaticObject</code></a></p>
<dt id="maddux.objects.target.Target.display">`display`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/target.html#Target.display)</dt>
<p>显示目标属性：rtpye：无</p>
<dt id="maddux.objects.target.Target.is_hit">`is_hit`（_位置_）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/target.html#Target.is_hit)</dt>
<p>检查目标是否被击中。</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **position**（_numpy.array_） - 对象的位置 |
| 返回类型： | 布尔 |
<dt id="maddux.objects.target.Target.plot">`plot`（_ax _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/target.html#Target.plot)</dt>
<p>在目标位置绘制目标。：param ax：图上的情节。：type ax：matplotlib图：rtype：matplotlib图</p>
<dt id="maddux.objects.target.Target.plot_data">`plot_data`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/target.html#Target.plot_data)</dt>
<p>获取目标位置的绘图数据：rtype：整数的3元组</p>
<h2 id="madduxobjectsthrowable模块">maddux.objects.throwable模块</h2>
<p>一个基本可抛出的对象类，它对重力，速度等特征进行编码。</p>
<dt id="maddux.objects.throwable.ThrowableObject">_class_`maddux.objects.throwable.``ThrowableObject`（_position_，_target = False _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/throwable.html#ThrowableObject)</dt>
<p>基地： <a href="http://bencaine.me/maddux/maddux.objects.html#maddux.objects.dynamic.DynamicObject" title="maddux.objects.dynamic.DynamicObject"><code>maddux.objects.dynamic.DynamicObject</code></a></p>
<dt id="maddux.objects.throwable.ThrowableObject.attach">`attach`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/throwable.html#ThrowableObject.attach)</dt>
<p>将对象附加到其当前位置</p>
<dt id="maddux.objects.throwable.ThrowableObject.display">`display`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/throwable.html#ThrowableObject.display)</dt>
<p>显示有关对象的信息</p>
<dt id="maddux.objects.throwable.ThrowableObject.step">`step`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/throwable.html#ThrowableObject.step)</dt>
<p>更新一个时间步（1毫秒）</p>
<dt id="maddux.objects.throwable.ThrowableObject.throw">`throw`（_速度_）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/throwable.html#ThrowableObject.throw)</dt>
<p>扔一个物体。</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **速度**（_np.ndarray_） - 投掷速度（vx，vy，vz） |
| 返回类型： | [没有](https://docs.python.org/library/constants.html#None "（在Python v2.7中）") |
</li>
<li>
<h1 id="madduxobjects包-2">maddux.objects包</h1>
<h2 id="子模块-4">子模块</h2>
<h2 id="madduxobjectsball模块-2">maddux.objects.ball模块</h2>
<p>投掷的球对象。</p>
<dt id="maddux.objects.ball.Ball">_class_`maddux.objects.ball.``Ball`（_position_，_radius_，_target = False _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/ball.html#Ball)</dt>
<p>基地： <a href="http://bencaine.me/maddux/maddux.objects.html#maddux.objects.throwable.ThrowableObject" title="maddux.objects.throwable.ThrowableObject"><code>maddux.objects.throwable.ThrowableObject</code></a></p>
<dt id="maddux.objects.ball.Ball.plot">`plot`（_ax _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/ball.html#Ball.plot)</dt>
<p>在当前位置绘制球。</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **ax**（_matplotlib.axes_） - 图上绘图。 |
| 返回值： | Matplotlib图 |
| 返回类型： | matplotlib.axes |
<h2 id="madduxobjectsdynamic模块-2">maddux.objects.dynamic模块</h2>
<p>动态对象的抽象基类。</p>
<dt id="maddux.objects.dynamic.DynamicObject">_class_`maddux.objects.dynamic.``DynamicObject`（_position_，_target = False _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/dynamic.html#DynamicObject)</dt>
<p>基地： <a href="https://docs.python.org/library/functions.html#object" title="（在Python v2.7中）"><code>object</code></a></p>
<dt id="maddux.objects.dynamic.DynamicObject.attach">`attach`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/dynamic.html#DynamicObject.attach)</dt>
<p>附加到对象（停止移动）</p>
<dt id="maddux.objects.dynamic.DynamicObject.display">`display`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/dynamic.html#DynamicObject.display)</dt>
<p>显示信息</p>
<dt id="maddux.objects.dynamic.DynamicObject.plot">`plot`（_ax _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/dynamic.html#DynamicObject.plot)</dt>
<p>在当前位置绘制动态对象</p>
<dt id="maddux.objects.dynamic.DynamicObject.step">`step`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/dynamic.html#DynamicObject.step)</dt>
<p>及时前进（一毫秒）</p>
<h2 id="madduxobjectsobstacle模块-2">maddux.objects.obstacle模块</h2>
<p>一种固定的长方形固体，可能会碰撞</p>
<dt id="maddux.objects.obstacle.Obstacle">_class_`maddux.objects.obstacle.``Obstacle`（_pt1_，_pt2_，_color ='r' _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/obstacle.html#Obstacle)</dt>
<p>基地： <a href="http://bencaine.me/maddux/maddux.objects.html#maddux.objects.static.StaticObject" title="maddux.objects.static.StaticObject"><code>maddux.objects.static.StaticObject</code></a></p>
<dt id="maddux.objects.obstacle.Obstacle.display">`display`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/obstacle.html#Obstacle.display)</dt>
<p>显示障碍物属性</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 返回类型： | [没有](https://docs.python.org/library/constants.html#None "（在Python v2.7中）") |
<dt id="maddux.objects.obstacle.Obstacle.get_paths">`get_paths`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/obstacle.html#Obstacle.get_paths)</dt>
<p>返回矩形的每个曲面的路径以进行绘图。</p>
<p>：返回（底部，顶部，前部，后部，左侧，右侧）：rtype：6个4x3 numpy.ndarrays的列表</p>
<dt id="maddux.objects.obstacle.Obstacle.is_hit">`is_hit`（_位置_）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/obstacle.html#Obstacle.is_hit)</dt>
<p>检查矩形是否被点或路径击中</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **position**（_numpy.ndarray或numpy.matrix_） - 一个对象位置（x，y，z）或位置，如果它是一个路径（[x1，x2，..]，[y1，y2，..]，[z1， z2，..] |
| 返回值： | 障碍物是否被点或路径击中 |
| 返回类型： | [布尔](https://docs.python.org/library/functions.html#bool "（在Python v2.7中）") |
<dt id="maddux.objects.obstacle.Obstacle.is_hit_by_sphere">`is_hit_by_sphere`（_中心_，_半径_）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/obstacle.html#Obstacle.is_hit_by_sphere)</dt>
<p>检查矩形是否被球体击中</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | 
<ul>
<li><strong>中心</strong>（<em>numpy.ndarray</em>） - 球体的中心（x，y，z）</li>
<li><strong>radius</strong>（<a href="https://docs.python.org/library/functions.html#int" title="（在Python v2.7中）"><em>int</em></a>） - 球体的半径</li>
</ul>
<p>|
| 返回值： |</p>
<p>障碍物是否被球体击中</p>
<p>|
| 返回类型： |</p>
<p><a href="https://docs.python.org/library/functions.html#bool" title="（在Python v2.7中）">布尔</a></p>
<p>|</p>
<dt id="maddux.objects.obstacle.Obstacle.plot">`plot`（_ax _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/obstacle.html#Obstacle.plot)</dt>
<p>在其位置绘制障碍物</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **ax**（_matplotlib.axes_） - 图上绘图 |
| Rtpye： | 没有 |
<h2 id="madduxobjectsstatic模块-2">maddux.objects.static模块</h2>
<p>静态对象的抽象基类。</p>
<dt id="maddux.objects.static.StaticObject">_班_`maddux.objects.static.``StaticObject`[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/static.html#StaticObject)</dt>
<p>基地： <a href="https://docs.python.org/library/functions.html#object" title="（在Python v2.7中）"><code>object</code></a></p>
<dt id="maddux.objects.static.StaticObject.display">`display`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/static.html#StaticObject.display)</dt>
<p>显示有关静态对象的相关数据。</p>
<dt id="maddux.objects.static.StaticObject.is_hit">`is_hit`（_位置_）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/static.html#StaticObject.is_hit)</dt>
<p>判断另一个对象是否命中静态对象</p>
<dt id="maddux.objects.static.StaticObject.plot">`plot`（_ax _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/static.html#StaticObject.plot)</dt>
<p>绘制静态对象。</p>
<h2 id="madduxobjectstarget模块-2">maddux.objects.target模块</h2>
<p>某物可能与之碰撞的静止物体。</p>
<dt id="maddux.objects.target.Target">_class_`maddux.objects.target.``Target`（_position_，_radius _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/target.html#Target)</dt>
<p>基地： <a href="http://bencaine.me/maddux/maddux.objects.html#maddux.objects.static.StaticObject" title="maddux.objects.static.StaticObject"><code>maddux.objects.static.StaticObject</code></a></p>
<dt id="maddux.objects.target.Target.display">`display`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/target.html#Target.display)</dt>
<p>显示目标属性：rtpye：无</p>
<dt id="maddux.objects.target.Target.is_hit">`is_hit`（_位置_）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/target.html#Target.is_hit)</dt>
<p>检查目标是否被击中。</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **position**（_numpy.array_） - 对象的位置 |
| 返回类型： | 布尔 |
<dt id="maddux.objects.target.Target.plot">`plot`（_ax _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/target.html#Target.plot)</dt>
<p>在目标位置绘制目标。：param ax：图上的情节。：type ax：matplotlib图：rtype：matplotlib图</p>
<dt id="maddux.objects.target.Target.plot_data">`plot_data`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/target.html#Target.plot_data)</dt>
<p>获取目标位置的绘图数据：rtype：整数的3元组</p>
<h2 id="madduxobjectsthrowable模块-2">maddux.objects.throwable模块</h2>
<p>一个基本可抛出的对象类，它对重力，速度等特征进行编码。</p>
<dt id="maddux.objects.throwable.ThrowableObject">_class_`maddux.objects.throwable.``ThrowableObject`（_position_，_target = False _）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/throwable.html#ThrowableObject)</dt>
<p>基地： <a href="http://bencaine.me/maddux/maddux.objects.html#maddux.objects.dynamic.DynamicObject" title="maddux.objects.dynamic.DynamicObject"><code>maddux.objects.dynamic.DynamicObject</code></a></p>
<dt id="maddux.objects.throwable.ThrowableObject.attach">`attach`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/throwable.html#ThrowableObject.attach)</dt>
<p>将对象附加到其当前位置</p>
<dt id="maddux.objects.throwable.ThrowableObject.display">`display`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/throwable.html#ThrowableObject.display)</dt>
<p>显示有关对象的信息</p>
<dt id="maddux.objects.throwable.ThrowableObject.step">`step`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/throwable.html#ThrowableObject.step)</dt>
<p>更新一个时间步（1毫秒）</p>
<dt id="maddux.objects.throwable.ThrowableObject.throw">`throw`（_速度_）[[来源]](http://bencaine.me/maddux/_modules/maddux/objects/throwable.html#ThrowableObject.throw)</dt>
<p>扔一个物体。</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | **速度**（_np.ndarray_） - 投掷速度（vx，vy，vz） |
| 返回类型： | [没有](https://docs.python.org/library/constants.html#None "（在Python v2.7中）") |
<hr>
<h1 id="madduxexamples包">maddux.examples包</h1>
<h2 id="子模块-5">子模块</h2>
<h2 id="madduxexamplesarm_animation模块">maddux.examples.arm_animation模块</h2>
<dt id="maddux.examples.arm_animation.arm_animation">`maddux.examples.arm_animation.``arm_animation`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/examples/arm_animation.html#arm_animation)</dt>
<p>动画手臂移动触摸球</p>
<h2 id="madduxexamplesarm_ball_animation模块">maddux.examples.arm_ball_animation模块</h2>
<dt id="maddux.examples.arm_ball_animation.arm_ball_animation">`maddux.examples.arm_ball_animation.``arm_ball_animation`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/examples/arm_ball_animation.html#arm_ball_animation)</dt>
<p>为拿着球的手臂设置动画，移动到任意位置。</p>
<h2 id="madduxexamplesball_animation模块">maddux.examples.ball_animation模块</h2>
<dt id="maddux.examples.ball_animation.ball_animation">`maddux.examples.ball_animation.``ball_animation`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/examples/ball_animation.html#ball_animation)</dt>
<p>制作几个球并让它们以不同的速度在环境中移动。</p>
<h2 id="madduxexamplesfind_jacob0模块">maddux.examples.find_jacob0模块</h2>
<dt id="maddux.examples.find_jacob0.find_jacob0">`maddux.examples.find_jacob0.``find_jacob0`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/examples/find_jacob0.html#find_jacob0)</dt>
<p>展示如何计算am arm的jacobian。</p>
<h2 id="madduxexamplesobstacle_collision模块">maddux.examples.obstacle_collision模块</h2>
<dt id="maddux.examples.obstacle_collision.obstacle_collision">`maddux.examples.obstacle_collision.``obstacle_collision`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/examples/obstacle_collision.html#obstacle_collision)</dt>
<p>测试最终配置的手臂是否与我们的任何一个障碍物接触。</p>
<h2 id="madduxexamplesplot模块">maddux.examples.plot模块</h2>
<dt id="maddux.examples.plot.plot">`maddux.examples.plot.``plot`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/examples/plot.html#plot)</dt>
<p>给出一个包含一些对象和机器人的环境的通用绘图示例。</p>
<h2 id="madduxexamplesplot_arm模块">maddux.examples.plot_arm模块</h2>
<dt id="maddux.examples.plot_arm.plot_arm">`maddux.examples.plot_arm.``plot_arm`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/examples/plot_arm.html#plot_arm)</dt>
<p>显示如何绘制手臂。</p>
<h2 id="madduxexamplesplot_obstacle模块">maddux.examples.plot_obstacle模块</h2>
<dt id="maddux.examples.plot_obstacle.plot_obstacle">`maddux.examples.plot_obstacle.``plot_obstacle`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/examples/plot_obstacle.html#plot_obstacle)</dt>
<p>在环境中创建并绘制障碍物。</p>
<h2 id="madduxexamplestutorial模块">maddux.examples.tutorial模块</h2>
<dt id="maddux.examples.tutorial.tutorial">`maddux.examples.tutorial.``tutorial`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/examples/tutorial.html#tutorial)</dt>
<p>我们的文档教程中的代码</p>
<h1 id="madduxutils包">maddux.utils包</h1>
<h2 id="子模块-6">子模块</h2>
<h2 id="madduxutilsanimate_path模块">maddux.utils.animate_path模块</h2>
<dt id="maddux.utils.animate_path.animate_path">`maddux.utils.animate_path.``animate_path`（_environment_，_input_file_，_output_file = None _）[[来源]](http://bencaine.me/maddux/_modules/maddux/utils/animate_path.html#animate_path)</dt>
<p>加载已保存的路径并为其设置动画</p>
<colgroup><col class="field-name"><col class="field-body"></colgroup>
| 参数： | 
<ul>
<li><strong>environment</strong>（<a href="https://docs.python.org/library/functions.html#str" title="（在Python v2.7中）"><em>str</em></a>） - 发生路径的环境</li>
<li><strong>input_file</strong>（<a href="https://docs.python.org/library/functions.html#str" title="（在Python v2.7中）"><em>str</em></a>） - 保存联合配置的文件</li>
<li><strong>output_file</strong>（<em>str或None</em>） - 将动画保存为.mp4的文件</li>
</ul>
<p>|
| Rtpye： |</p>
<p>没有</p>
<p>|</p>
<dt id="maddux.utils.animate_path.main">`maddux.utils.animate_path.``main`（）[[来源]](http://bencaine.me/maddux/_modules/maddux/utils/animate_path.html#main)</dt>
<p>运行CLI以获取动画参数</p>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RoboND-Kinematics-Project 为Kuka R210机器人手臂提供逆运动学分析]]></title>
        <id>https://blog.bioprinting.site/post/KQATQGv4O</id>
        <link href="https://blog.bioprinting.site/post/KQATQGv4O">
        </link>
        <updated>2019-05-12T14:23:16.000Z</updated>
        <content type="html"><![CDATA[<h2 id="项目运动学拾取和放置">项目：运动学拾取和放置</h2>
<h4 id=""><a href="https://github.com/zenetio/RoboND-Kinematics-Project#carlos-r-lacerda"></a>Carlos R. Lacerda</h4>
<hr>
<p><strong>概述：</strong></p>
<p>该项目的目标是为Kuka R210机器人手臂提供运动学分析。在模拟中，我们处理一个任务来挑选，移动和放下一个对象到一个盒子里。在这个项目中，我将使用ROS系统和Gazebo + Rviz作为模拟环境。使用反向运动学（IK），我们可以找到正确的轨迹来驱动手臂将物体放在所需的位置。可以在此<a href="https://github.com/zenetio/RoboND-Kinematics-Project.git">存储库中</a>找到完整的项目，这是<a href="https://youtu.be/Zh5tTvKKrH4">视频</a>。</p>
<p><a href="https://github.com/zenetio/RoboND-Kinematics-Project/blob/master/misc_images/first_try.png"><img src="https://github.com/zenetio/RoboND-Kinematics-Project/raw/master/misc_images/first_try.png" alt="替代文字"></a></p>
<p>图1。</p>
<h3 id="-2"><a href="https://github.com/zenetio/RoboND-Kinematics-Project#kinematic-analysis-model-of-6-dof-kuka-r210-robot"></a>6自由度Kuka R210机器人运动分析模型</h3>
<h4 id="-3"><a href="https://github.com/zenetio/RoboND-Kinematics-Project#1-forward-kinematic"></a>1.前进运动学</h4>
<p>运动学分析主要包括两个方面，即正向运动学分析（FK）和反向运动学分析（IK）。正向运动学分析意味着Kuka的末端执行器的姿态可以用链接的给定几何参数和关节的变量来计算。机器人具有平移或旋转关节。平移沿着给定的矢量方向在空间中移动有限距离，并且可以通过相邻链路之间的以下均匀变换矩阵来描述，如图2所示。</p>
<p><a href="https://github.com/zenetio/RoboND-Kinematics-Project/blob/master/misc_images/homo.png"><img src="https://github.com/zenetio/RoboND-Kinematics-Project/raw/master/misc_images/homo.png" alt="替代文字"></a></p>
<p>图2。</p>
<p>正向运动（FK）问题的解决方案是直线计算，其中我们可以使用关节角度并找到机器人手臂的末端执行器姿势（位置+方向）。下面的图3显示了FK和IK之间的分析模型。</p>
<p><a href="https://github.com/zenetio/RoboND-Kinematics-Project/blob/master/misc_images/fk_ik.png"><img src="https://github.com/zenetio/RoboND-Kinematics-Project/raw/master/misc_images/fk_ik.png" alt="替代文字"></a></p>
<p>图3。</p>
<p>但是什么是联系或联合角度？我们将在下一节中看到。可以使用Denavit-Hartenberg（DH）惯例导出机器人的链接和关节角度之间的关系。</p>
<h3 id="-4"><a href="https://github.com/zenetio/RoboND-Kinematics-Project#2-dh-parameters"></a>2. DH参数</h3>
<p>读取kr210.urdf.xacro文件以执行Kuka KR210机器人的运动学分析并得出其DH参数，得到下表1。</p>
<p><em>表格1。</em></p>
<table>
<thead>
<tr>
<th>链接</th>
<th>α（I-1）</th>
<th>一个第（i-1）</th>
<th>d（I-1）</th>
<th>THETA（ⅰ）</th>
</tr>
</thead>
<tbody>
<tr>
<td>0-&gt; 1</td>
<td>0</td>
<td>0</td>
<td>0.75</td>
<td>0</td>
</tr>
<tr>
<td>1-&gt; 2</td>
<td>-pi / 2</td>
<td>0.35</td>
<td>0</td>
<td>-pi / 2 + q2</td>
</tr>
<tr>
<td>2-&gt; 3</td>
<td>0</td>
<td>1.25</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>3-&gt; 4</td>
<td>-pi / 2</td>
<td>-0.054</td>
<td>1.50</td>
<td>0</td>
</tr>
<tr>
<td>4-&gt; 5</td>
<td>Pi / 2相</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>5-&gt; 6</td>
<td>-pi / 2</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>6-&gt; EE</td>
<td>0</td>
<td>0</td>
<td>0.303</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>DH参数由坐标系i-1到i的变换通过表1中给出的旋转和平移变换给出。注意，这是DH惯例的修改惯例。图4显示了表1中描述的每个变量的位置。</p>
<p><a href="https://github.com/zenetio/RoboND-Kinematics-Project/blob/master/misc_images/kr210_schematic.png"><img src="https://github.com/zenetio/RoboND-Kinematics-Project/raw/master/misc_images/kr210_schematic.png" alt="替代文字"></a></p>
<p>图4。</p>
<p>在Gazebo中，DH参数表由URDF文件描述。URDF文件中详细描述了所有关节和链接。下面的图5显示了Kuka R210 URDF文件的一部分。</p>
<p><a href="https://github.com/zenetio/RoboND-Kinematics-Project/blob/master/misc_images/urdf.png"><img src="https://github.com/zenetio/RoboND-Kinematics-Project/raw/master/misc_images/urdf.png" alt="替代文字"></a></p>
<p>图5。</p>
<p>例如，请注意，joint_3与父link_2和子link_3链接。</p>
<h3 id="-5"><a href="https://github.com/zenetio/RoboND-Kinematics-Project#3-implementation-of-forward-kinematics"></a>3.正向运动学的实现</h3>
<p>因此，使用表1中的值和图2中描述的均匀变换公式，我们可以创建关于每个关节的各个变换矩阵。此外，我们还可以仅使用末端效应器（抓取器）姿势在base_link和gripper_link之间生成广义齐次变换。</p>
<p>例如，base_link和link_1（T0_1）的同构变换可以写成如下：</p>
<p>def  Tn_m（th，alpha，a，d）：
t =矩阵（[[cos（th），             - sin（th），             0，a]，
[sin（th）* cos（alpha），cos（th）* cos（alpha），- sin（alpha），- sin（alpha）* d]，
[sin（th）* sin（alpha），cos（th）* sin（alpha），cos（alpha），cos（alpha）* d]，
[                    0，                    0，            0，                1 ]]）
＃从base_link到LINK_1转化
T0_1 = Tn_m（Q1，alpha0，A0，D1）.subs（S）</p>
<p>我们对所有其他链接重复相同的方法</p>
<p>＃从link_1到Link_2的转换
T1_2 = Tn_m（q2，alpha1，a1，d2）.subs（s）
＃从link_2到Link_3的
转换T2_3 = Tn_m（q3，alpha2，a2，d3）.subs（s）
＃来自link_3的转换到Link_4
T3_4 = Tn_m（q4，alpha3，a3，d4）.subs（s）
＃从link_4到Link_5的
转换T4_5 = Tn_m（q5，alpha4，a4，d5）.subs（s）
＃从link_5到Link_6的
转换T5_6 = Tn_m（q6，alpha5，a5，d6）.subs（s）
＃从link_6到夹子的转换G
T6_G  = Tn_m（q7，alpha6，a6，d7）.subs（s）</p>
<p>然后使用上面的等式，对于从base_link到gripper_link的每个同构变换，我们有：</p>
<p>T0_1 =矩阵（[[COS（Q1），-罪（Q1），0，     0 ]，
[罪（Q1），COS（Q1），0，     0 ]，
[       0，         0，1，0.75 ]，
[       0，         0，0，     1 ]]）</p>
<p>T1_2 =矩阵（[[罪（Q2），COS（Q2），0，0.35 ]，
[       0，         0，1，     0 ]，
[COS（Q2），-罪（Q2），0，     0 ]，
[       0，         0，0，     1 ]]）</p>
<p>T2_3 =矩阵（[[COS（Q3），-罪（Q3），0，1.25 ]，
[罪（Q3），COS（Q3），0，     0 ]，
[       0，         0，1，     0 ]，
[       0，        0，0，     1 ]]）</p>
<p>T3_4 =矩阵（[[COS（Q4），-罪（Q4），0，- 0.054 ]，
[        0，         0，1，     1.5 ]，
[ -罪（Q4），- COS （Q4），0，       0 ]，
[        0，         0，0，       1 ]]）</p>
<p>T4_5 =矩阵（[[COS（Q5），-罪（Q5），   0，0 ]，
[       0，         0，- 1，0 ]，
[罪（Q5），COS（Q5），   0，0 ]，
[       0，         0，   0，1 ]]）</p>
<p>T5_6 =矩阵（[[COS（Q6），- SIN（Q6），0，0 ]，
[        0，         0，1，0 ]，
[ - SIN（Q6），- COS（Q6），0，0 ]，
[        0，         0，0，1 ]]）T6_G =矩阵（[[ 1，0，0，      0 ]，
[ 0，1，0，      0 ]，
[ 0，0，1，0.303 ]，
[ 0，</p>
<p>0，0，      1 ]]）</p>
<p>因此，我们可以计算抓手姿势的完整FK。</p>
<p>注意，均匀变换具有平移和旋转部分。使用此属性，我们可以重新排列同构变换并编写以下内容：</p>
<p><a href="https://github.com/zenetio/RoboND-Kinematics-Project/blob/master/misc_images/wc.png"><img src="https://github.com/zenetio/RoboND-Kinematics-Project/raw/master/misc_images/wc.png" alt="替代文字"></a></p>
<p>图6。</p>
<p>它会导致手腕中心姿势。</p>
<h3 id="-6"><a href="https://github.com/zenetio/RoboND-Kinematics-Project#4-implementation-of-inverse-kinematics"></a>4.反向运动学的实现</h3>
<p>逆运动学分析与正向运动学分析相反。现在情况有点复杂了。给定期望的末端效应器姿势，我们需要找到将实现到目标位置的正确轨迹的关节角度的值。利用反向运动学解决方案，可以确定每个关节角度的值，以便将臂放置在期望的位置和方向。</p>
<p>也就是说，我们需要找到q1，q2，q3，q4，q5和q6的值，这些值会将手臂移动到所需的姿势。</p>
<p><a href="https://github.com/zenetio/RoboND-Kinematics-Project/blob/master/misc_images/geometry.png"><img src="https://github.com/zenetio/RoboND-Kinematics-Project/raw/master/misc_images/geometry.png" alt="替代文字"></a></p>
<p>图7。</p>
<p>使用臂的一些几何特性，q1，q2和q3的值非常严格，如图7所示</p>
<p>q1角度可以从手臂在平面X0-Y0上的投影中找到，我们得到：</p>
<p>theta1 = atan2（Wc [ 1 ]，Wc [ 0 ]）</p>
<p>我们可以从下面的图7和图8得到theta2和theta3。</p>
<p><a href="https://github.com/zenetio/RoboND-Kinematics-Project/blob/master/misc_images/misc3.png"><img src="https://github.com/zenetio/RoboND-Kinematics-Project/raw/master/misc_images/misc3.png" alt="替代文字"></a></p>
<p>图8。</p>
<p>＃使用几何计算三角形边
side_a = 1.501
side_b = sqrt（ pow（（sqrt（Wc [ 0 ] * Wc [ 0 ] + Wc [ 1 ] * Wc [ 1 ]） - 0.35）， 2） + pow（（ Wc [ 2 ] - 0.75）， 2））
side_c = 1.25
＃使用几何来计算三角形角度
angle_a = acos（（side_b）* side_b + side_c * side_c - side_a * side_a）/（2  * side_b * side_c））
angle_b = acos（（side_a * side_a + side_c * side_c - side_b * side_b）/（2  * side_a * side_c））
＃ calculate theta2
theta2 = np.pi /  2。- angle_a - atan2（Wc [2 ] -  0.75，SQRT（WC [ 0 ] * Wc中[ 0 ] + Wc中[ 1 ] * Wc中[ 1 ]）-  0.35）
＃计算theta3
theta3 = np.pi /  2。-（angle_b +  0.036）</p>
<p>最后，使用旋转矩阵R3_6和更多几何属性，我们可以找到剩余角度q4，q5和q6。</p>
<p>＃使用旋转矩阵来计算剩余的关节角度
＃从变换矩阵我们可以提取的旋转矩阵
R0_3 = oClass.T0_3 [ 0： 3， 0： 3 ]
R0_3 = R0_3.evalf（潜艇= {Q1：theta1，Q2：theta2， Q3：theta3}）
R3_6 = R0_3.T * Rot_G＃现在得到欧拉从旋转矩阵角度＃计算theta4
theta4 = ATAN2（R3_6 [ 2， 2 ]， - R3_6 [ 0</p>
<p>，2 ]）
＃计算theta5
theta5 = ATAN2（SQRT（R3_6 [ 0，2 ] * R3_6 [ 0，2 ] + R3_6 [ 2，2 ] * R3_6 [ 2，2 ]），R3_6 [ 1，2 ]）
＃计算theta6
theta6 = ATAN2（- R3_6 [ 1，1 ]，R3_6 [ 1，0 ]）
＃因为该模型具有某些奇点，我们可以考虑
如果（SIN（theta5）&lt;  0）：
theta4 = ATAN2（- R3_6 [ 2，2 ]，R3_6 [ 0，2 ]）
theta6 = ATAN2（R3_6 [ 1，1 ]，- R3_6 [ 1，0 ]）</p>
<h3 id="-7"><a href="https://github.com/zenetio/RoboND-Kinematics-Project#5-project-implementation"></a>5.项目实施</h3>
<ul>
<li>模拟环境：ROS运行Gazebo + Rviz</li>
<li>语言：Python和C ++</li>
<li>操作系统：在VMware Pro上运行的Ubuntu 16.04</li>
</ul>
<p>为了运行这个项目，我在<code>IK_server.py</code>脚本文件中实现了FK和IK的代码。python代码接收末端效应器姿势，处理运动学分析并返回具有关节角度的阵列列表，该关节角度将允许手臂移动到新的期望姿势。</p>
<h3 id="-8"><a href="https://github.com/zenetio/RoboND-Kinematics-Project#6-improvements"></a>6.改进</h3>
<p>我不得不优化Kuka手臂未能挑选物体的一些问题。IK正在从开始到结束放置位置正确地移动手臂但是该过程没有成功，因为夹子未能拾取对象。然后我在<code>trajectory_sampler.cpp</code>代码中做了两处更改：</p>
<ul>
<li>在抓手处理功能之前增加了4秒</li>
<li>夹持器角度从0.02增加到0.025</li>
</ul>
<p>然后这两个变化降低了抓手未能保持对象的概率。</p>
<p>另一个挑战是找到一个解决方案，以避免在循环内运行符号代码来管理从手臂接收到的姿势。符号变量的计算需要很长时间，主要是因为我们有很多矩阵运算。因此，例如，考虑完成符号操作60秒，然后乘以50,60,100个迭代，您将获得大量的计算时间。在最后，这将是每个周期无法接受的时间。</p>
<p>为了解决这个问题，我创建了一个类来管理所有符号变量和计算的创建。然后我执行了一次类代码，创建了一个被序列化并保存到磁盘的对象。所以，在项目中我<code>IK_server.py</code>只需要加载（反序列化）对象代码。这种方法只需几分之一秒，这意味着在循环中管理FK和IK分析的快速计算时间。</p>
<p><a href="https://github.com/zenetio/RoboND-Kinematics-Project/blob/master/misc_images/last_try.png"><img src="https://github.com/zenetio/RoboND-Kinematics-Project/raw/master/misc_images/last_try.png" alt="替代文字"></a></p>
<p>图9。</p>
<p>图9显示了10次尝试后的最终过程。请注意，框中有3个引脚，下拉框中有8个引脚。一个是第11周期，不得考虑。但是其他2个都在盒子里，因为即使夹子姿势是正确的，它也不能将物体保持在夹子中。</p>
<p>因此，我们可以得出结论，FK和IK计算中的误差非常低，如果我们有更好的抓手操作，我们可以在10次尝试中达到100％。</p>
<h3 id="-9"><a href="https://github.com/zenetio/RoboND-Kinematics-Project#future-improvements"></a>未来的改进</h3>
<p>改进夹具操作以避免即使夹具处于正确姿势时也会失败。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ROS-IGTL-Bridge：使用ROS环境进行图像引导治疗的开放式网络接口]]></title>
        <id>https://blog.bioprinting.site/post/AKuuLRT2E</id>
        <link href="https://blog.bioprinting.site/post/AKuuLRT2E">
        </link>
        <updated>2019-05-12T13:59:18.000Z</updated>
        <content type="html"><![CDATA[<h3 id="目的">目的</h3>
<p>随着人们对手术机器人系统先进图像引导的兴趣日益增加，机器人设备和医学图像计算软件的快速集成和测试在研究和开发中变得至关重要。最大限度地利用在不同领域广泛接受的平台上构建的现有工程资源，例如机器人中的机器人操作系统（ROS）和医学图像计算中的3D切片器可以简化这些任务。我们提出了一个集成在ROS中的新的开放式网桥接口，以确保无缝的跨平台数据共享。</p>
<h3 id="方法">方法</h3>
<p>实现了名为ROS-IGTL-Bridge的ROS节点。它使用OpenIGTLink协议在ROS环境和外部医学图像计算软件之间建立TCP / IP网络连接。该节点同时通过网络将ROS消息输出到外部软件，反之亦然，从而允许基于ROS的设备和医学图像计算平台之间的无缝和透明数据共享。</p>
<h3 id="结果">结果</h3>
<p>性能测试表明，网桥可以成功地在两个方向上以30 fps流式传输变换，字符串，点和图像。变换，字符串和点的数据传输延迟小于1.2 ms，而rrom VGA图像的数据传输延迟小于1.2 ms。另外一项测试还表明，该桥可以实现900 fps的变换。此外，该桥在两个具有代表性的系统中进行了演示：模拟图像引导的手术机器人设置，包括3D切片机，以及带有ROS的Lego Mindstorms，作为IGT研究的原型和教育平台; 和智能组织自主机器人（STAR）手术设置与3D切片机。</p>
<h3 id="结论">结论</h3>
<p>该研究表明，该桥实现了ROS与医学图像计算软件之间的跨平台数据共享。这将允许由诸如3D切片器的医学图像计算软件提供的基于图像的高级计划/导航快速且无缝地集成到基于ROS的手术机器人系统中。</p>
<p>**关键词：**ROS，OpenIGTLink，界面，手术机器人，图像引导治疗</p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/" title="转到此页面的其他部分">去：</a></p>
<h2 id="1简介">1简介</h2>
<p>机器人系统在图像引导治疗（IGT）中的应用已经在许多医学领域得到扩展，导致现代医学技术的不断发展[ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R1">1</a> ]。机器人辅助腹腔镜手术在美国和其他发达国家的根治性前列腺切除术中已经很常见[ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R2">2</a> ]并且在其他手术中扩大了其用途。机器人导管系统已被用于各种血管内手术[ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R3">3</a> ]和心律失常手术[ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R4">4</a> ]。机器人放射外科系统已被用于治疗肺，肝，胰腺，脊柱，肾，头部和颈部以及前列腺的肿瘤[ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R5">5</a> ]。</p>
<p>虽然今天的大多数临床机器人系统都是为了通过遵循他们的命令和计划来帮助外科医生，但人们越来越关注自动化辅助，其中机器人系统接管一些外科医生的常规任务，例如切割和缝合，让外科医生集中于高级别外科决策[ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R6">6</a>，<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R7">7</a> ]。随着对自主技术的兴趣日益增加，研究人员和外科医生在手术室中面临着各种各样的技术。这种不断增长的兴趣促使医疗机器人社区利用机器人操作系统（ROS）中的各种功能<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R8"> [8]</a>]，例如计算机视觉，传感，运动学，模拟和运动规划。机器人研究系统包括医疗机器人Raven II [ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R9">9</a> ]和达芬奇研究套件（dVRK）[ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R10">10</a> ]以及KUKA轻量重型机器人（LWR）[ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R11">11</a> ]已经使用ROS作为软件平台。</p>
<p>但是，ROS平台不是执行某些临床任务的理想环境。具体而言，现代手术计划和指导严重依赖于医学图像来识别和定位患病区域和关键结构。此外，必须将这种导航信息映射到物理空间，以实现安全和准确的处理。虽然ROS的多功能性允许研究人员自己实现这些功能，但其中许多已经在一些专门为医学图像计算和图像引导治疗开发的研究平台上可用，例如3D Slicer [ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R12">12</a> ]，IGSTK [ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R13">13</a> ]， MITK [ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R14">14</a> ]或NifTK [ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R15">15</a> ]，OsiriX [ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R16">16</a> ]，XIP-Builder <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R17"> [17]</a>]和MeVisLab [ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R18">18</a> ]。因此，将ROS等机器人研究平台与医学图像计算平台连接起来对于先进医疗机器人系统的开发正变得越来越重要。通过将两个研究领域广泛开发的流行平台结合在一起，研究人员可以利用这两个领域丰富的工程资源。</p>
<p>将ROS等流行平台与医学图像计算平台连接起来，将进一步有益于医学机器人研究。由于ROS支持的机器人硬件种类繁多，从爱好导向产品到工业级高灵敏度机器人，人们可以轻松切换硬件，或者将系统从概念验证原型扩展到完全 - 用于动物和人类研究的功能系统，无需显着改变软件架构。因此，该桥将使原型设计和测试的迭代变得更加容易和快速。</p>
<p>这项研究的目标是开发一个新的软件界面，连接ROS和流行的医学图像计算软件3D Slicer，并提供支持图像引导和机器人辅助手术系统开发的研究和工程工具。这两个软件平台使用开放式网络通信协议OpenIGTLink [ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R19">19</a> ] 通过TCP / IP网络无缝共享数据和命令。</p>
<p>在本文中，我们描述了系统架构及其实现，以及概念验证场景。ROS中实现的桥接结构以及ROS和OpenIGTLink消息之间的转换在“方法”部分中进行了解释。随后，网络通信性能测试的结果显示在实验部分，然后是用例部分，其中提供了网桥功能的展望。实验结果和用例在讨论部分讨论。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/" title="转到此页面的其他部分">去：</a></p>
<h2 id="2方法">2方法</h2>
<h3 id="21-ros-igtl-bridge节点">2.1 ROS-IGTL-Bridge节点</h3>
<p>我们软件界面的核心组件是名为ROS-IGTL-Bridge的ROS节点。ROS-IGTL-Bridge作为基于ROS的系统中的节点之一，与3D Slicer或配备有套接字接口的其他外部医学图像计算软件建立TCP / IP套接字连接。它可以配置为作为TCP / IP服务器或客户端运行。ROS提供了由多个节点组成的图形架构，这些节点通过对等网络连接并将数据一起处理。节点可以将ROS消息发布到给定_主题_，以及其他节点可以通过订阅主题来接收消息。ROS-IGTL-Bridge节点将ROS消息转换为OpenIGTLink消息，并通过TCP / IP连接将其发送到外部软件。它还接收OpenIGTLink消息，将其转换为ROS消息，并将其发布到ROS网络中（<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F1/">图1</a>）。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=5543207_nihms883782f1.jpg"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/bin/nihms883782f1.jpg" alt="包含图片，插图等的外部文件。对象名称为nihms883782f1.jpg" title="点击图片放大"></a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F1/">图。1</a></p>
<p>ROS-IGTL-Bridge作为支持图像导入，图像处理，手术计划和手术导航的医学图像计算软件（左）之间的消息接口，以及提供运动学计算，传感，模拟，运动规划和计算机的ROS环境。愿景（右）。</p>
<p>该界面支持在图像引导和机器人辅助治疗的背景下常用的数据类型。支持的数据类型将在下一节中列出。</p>
<p>ROS-IGTL-Bridge节点进程由两个独立的POSIX线程组成，允许同时发送和接收数据（<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F2/">图2</a>）。每个消息类型实现了用于OpenIGTLink通信的消息序列化和反序列化的方法作为回调函数，并由两个线程调用。通过OpenIGTLink连接接收的传入消息由消息的头信息评估，并发布到ROS网络中相应的ROS-Topic。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=5543207_nihms883782f2.jpg"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/bin/nihms883782f2.jpg" alt="包含图片，插图等的外部文件。对象名称为nihms883782f2.jpg" title="点击图片放大"></a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F2/">图2</a></p>
<p>桥接数据处理由两个独立的POSIX线程组成。线程“接收”（左）通过评估头信息并执行消息转换来处理传入的Open-IGTLink消息，随后将数据发布到相应的ROS主题。同时，线程“发送”在订阅的ROS主题上的先前触发的回调之后发送传出消息（右）。</p>
<p>ROS网络中创建的主题标记为OUT表示传出数据，IN表示传入数据。通过使用启动文件并设置参数服务器IP，端口和客户端/服务器标志，可以轻松配置ROS-IGTL-Bridge节点。此外，自主测试节点ROS-IGTL-Test可用于通过发送虚拟数据并在订阅的ROS主题上可视化接收的数据来评估功能。在测试例程期间，发送随机变换，点，包含20个点的点云，字符串和样本vtkPolyData模型。</p>
<h3 id="22-ros-igtl-bridge支持的消息类型">2.2 ROS-IGTL-Bridge支持的消息类型</h3>
<p>ROS-IGTL-Bridge支持IGT应用中经常使用的各种类型的数据。支持的类型包括字符串，变换，图像，多边形数据和点。以下段落详细介绍了支持的OpenIGT-Link消息以及ROS中的相应主题。为了确定从OpenIGTLink消息到相应ROS消息的转换方法，ROS-IGTL-Bridge使用OpenIGTLink消息的标题部分，该消息提供元数据，包括类型名称，设备名称，时间戳，正文大小和包状态（<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F3/">图3</a>）。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=5543207_nihms883782f3.jpg"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/bin/nihms883782f3.jpg" alt="包含图片，插图等的外部文件。对象名称为nihms883782f3.jpg" title="点击图片放大"></a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F3/">图3</a></p>
<p>OpenIGTLink消息的基本结构由通用头信息组成，包括数据类型，名称，时间戳，大小和包状态以及特定于数据类型的主体部分。</p>
<h4 id="221字符串">2.2.1字符串</h4>
<p>设备和外部图像计算软件之间的字符串消息交换允许发送和接收命令或状态更新。因此，外部软件的图形用户界面可以扩展为显示诸如关于接收数据的确认之类的信息，或者提供用于控制所用设备的指令（<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F4/">图4</a>）。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=5543207_nihms883782f4.jpg"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/bin/nihms883782f4.jpg" alt="包含图片，插图等的外部文件。对象名称为nihms883782f4.jpg" title="点击图片放大"></a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F4/">图4</a></p>
<p>OpenIGTLink和ROS-IGTL-Bridge的字符串消息中的相应数据字段。</p>
<h4 id="222变换">2.2.2变换</h4>
<p>变换消息可以包含表示设备，兴趣对象等的位置和方向的线性变换，由连接到ROS的传感器测量，或者在外部图像计算软件上生成。消息可用于监视工具，设备和对象的位置和方向，或向设备提供规划数据。OpenIGTLink igtlTransformMessage由4 <em>×</em> 4矩阵表示，并转换为ROS消息类型几何msgs / Transform，包含用于平移的向量和用于方向的四元数（<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F5/">图5</a>）。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=5543207_nihms883782f5.jpg"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/bin/nihms883782f5.jpg" alt="包含图片，插图等的外部文件。对象名称为nihms883782f5.jpg" title="点击图片放大"></a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F5/">图5</a></p>
<p>Open-IGTLink和ROS-IGTL-Bridge的转换消息中的相应数据字段。ROS标准数据类型_几何msgs / Transform_包含作为3元素向量的转换和作为四元数的旋转。</p>
<h4 id="223图像">2.2.3图像</h4>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F6/">图6</a>显示了相应图像消息的属性。图像由3D空间中每个维度的大小和间距参数组成。数据存储在具有图像尺寸大小的8位数组中。可以使用IGTL VIDEO OUT主题从ROS发送2D视频流，该主题支持常见的ROS消息类型传感器msgs / Image。因此，摄像机数据可以直接转发到网桥，不需要额外的消息转换。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=5543207_nihms883782f6.jpg"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/bin/nihms883782f6.jpg" alt="包含图片，插图等的外部文件。对象名称为nihms883782f6.jpg" title="点击图片放大"></a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F6/">图6</a></p>
<p>OpenIGTLink和ROS-IGTL-Bridge图像消息中的相应数据字段。消息包含卷的元信息，包括大小和间距以及像素数据。</p>
<h4 id="224多边形数据">2.2.4多边形数据</h4>
<p>多边形数据消息允许传输由点和附加表面信息组成的3D模型。多边形，三角形条带，线条或顶点表示网格的结构。由于缺少ROS中的vtkPolyData消息的显式等价物，因此提供了将vtkPolyData转换为ros igtl bridge :: igtlpolydata消息的方法。</p>
<h4 id="225点">2.2.5点</h4>
<p>点消息包括3D点数据，允许发送和获取目标点作为机器人的移动目的地，操纵器的位置或地标坐标用于登记目的或者还有点云和点列表形式的传感器数据（<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F8/">图8</a>）。此外，网桥能够以IGTL POINTCLOUD OUT主题上发布的几何msgs / Point形式发送点云。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=5543207_nihms883782f8.jpg"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/bin/nihms883782f8.jpg" alt="包含图片，插图等的外部文件。对象名称为nihms883782f8.jpg" title="点击图片放大"></a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F8/">图8</a></p>
<p>OpenIGTLink和ROS-IGTL-Bridge的点消息中的相应数据字段。_geometry msgs / Point_包含_点_的x，y和z坐标。</p>
<h3 id="23系统配置和消息方案">2.3系统配置和消息方案</h3>
<p>使用不同的消息类型取决于系统配置和操作IGT设置所需的消息方案。<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F10/">图10</a>显示了两个代表性的系统配置，作为使用ROS-IGTL-Bridge的示例应用程序。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=5543207_nihms883782f10.jpg"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/bin/nihms883782f10.jpg" alt="包含图片，插图等的外部文件。对象名称为nihms883782f10.jpg" title="点击图片放大"></a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F10/">图10</a></p>
<p>显示ROS-IGTL-Bridge功能的示例设置。（a）机器人和跟踪系统连接到ROS，并由3D Slicer通过ROS-IGTL-Bridge控制。使用OpenIGTLink接口将成像设备直接连接到3D Slicer。（b）机器人和成像设备（超声波）连接到由ROS操作的机器人，并由3D切片机通过ROS-IGTL桥控制。</p>
<p>第一个示例IGT设置包括机器人和跟踪系统，这两个系统都由ROS使用已经存在的ROS节点来操作。跟踪系统用于跟踪机器人的末端执行器。外部成像装置，例如光学相干断层扫描（OCT），超声或MRI，连接到医学图像计算平台，如3D切片器，其提供用于处理和可视化这种医学数据的方法（<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F10/">图10a）。</a>）。通过桥接ROS消息环境和医学图像计算平台，功能集可以有效地相互补充。使用桥的字符串消息转换来交换命令和状态更新，因此可以使用外科手术规划工具的用户界面来操作系统。转换消息允许获得连续刷新的跟踪数据或在六个自由度中命令某个位置。机器人模型数据可以作为多边形数据模型传输，以在3D切片机中可视化。可以将跟踪设备的原始点云或图像数据转发到图像处理平台，以便定位机器人位置或执行路径规划。</p>
<p>第二示例表示机器人引导的成像装置，其可能是附接到机器人末端执行器的超声探头（<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F10/">图10b）</a>）。机器人和成像设备由可下载的标准ROS节点控制，允许在所需设置中进行简单集成。为了在生成的ROS消息环境中访问或发布数据，使用ROS-IGTL-Bridge节点建立与诸如3D Slicer之类的外部手术计划平台的通信。因此，机器人控制以及图像设备命令和响应可以通过网桥作为字符串消息传输。另外，可以将作为点或转换消息的定位命令发送到ROS环境。获取的图像数据被转发到控制机器人的计划软件作为图像或点云消息，因此，图像处理和可视化方法可用于比较术中与术前数据。<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F9/">图9</a> 示出了ROS环境和手术计划平台之间可能的通信协议，同时在被命令到特定点位置之后执行图像采集。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=5543207_nihms883782f9.jpg"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/bin/nihms883782f9.jpg" alt="包含图片，插图等的外部文件。对象名称为nihms883782f9.jpg" title="点击图片放大"></a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F9/">图9</a></p>
<p>使用ROS IGTL桥作为网络接口的手术计划软件和ROS操作机器人之间可能的通信协议。初始化机器人，命令移动到一个点并获取具有附加变换信息的图像数据。最后，机器人关闭了。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/" title="转到此页面的其他部分">去：</a></p>
<h2 id="3实验">3实验</h2>
<p>我们使用模拟图像引导的手术机器人系统评估了ROS和3D切片机之间的网络通信性能。此外，我们在两个有代表性的用例场景中展示了该软件的可行性：基于Lego Mindstorms的教育/快速原型图像引导手术导航系统和自主缝合机器人。</p>
<h3 id="31实验设置">3.1实验设置</h3>
<p>模拟图像引导的手术机器人系统由两台计算机组成：基于Linux的计算机（Precision M3800，四核Intel Core i7-4712HQ 2.3 GHz，16 GB 1600MHz DDR3内存，Ubuntu Linux 14.04LTS，Dell Inc.，Round Rock ，TX）模仿机器人控制器和基于Mac的工作站（Mac Pro，双6核Intel Xeon 2.66 GHz和40 GB 1333 MHz DDR3内存，Mac OS X 10.10，Apple Inc.，Cupertino，CA）模仿用于手术计划和导航界面的工作站。这两台计算机通过Cat 5e电缆连接到8端口千兆以太网交换机（SG100D-08，Cisco Systems Inc.，San Jose，CA）。ROS Indigo安装在基于Linux的计算机上，带有ROS-IGTL-Bridge节点。在Mac工作站上，安装了3D Slicer 4.6，用于可视化从ROS传输的数据。</p>
<p>为了评估延迟，发送方根据发送方的内部时钟将数据生成时间嵌入到消息头中。一旦接收器接收到消息，接收器就会提取数据生成的时间，并将其与接收器的内部时钟进行比较，以计算两个模拟器之间数据传输所花费的时间。为了准确确定延迟，使用PTPd [ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R20">20</a> ] 同步两台计算机的内部时钟。PTPd使用IEEE 1588-2008标准中定义的精确时间协议（PTP）通过网络将内部时钟与主时钟同步。与广泛使用的网络时间协议（NTP）不同[ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R21">21</a>]，PTP旨在实现连接到局域网（LAN）的计算机之间更精确的时钟同步。</p>
<h3 id="32数据传输性能评估">3.2数据传输性能评估</h3>
<p>使用此设置，我们评估了变换，字符串，点和图像的数据传输性能。这些数据类型通常用于实时数据共享，例如工具跟踪，视频流和状态监控，因此确保以适当的帧速率和延迟进行数据传输至关重要。</p>
<p>我们分别在Linux计算机和Mac工作站上部署了两个自定义软件模拟器，即_ROS测试节点_和_IGTL测试服务器_。ROS测试节点是ROS节点，通过ROS网络与ROS-IGTL-Bridge通信，而IGT测试服务器是TCP / IP服务器，使用OpenIGTLink协议通过LAN与ROS-IGTL-Bridge通信。IGTL测试服务器模拟3D切片机或任何其他手术计划和导航软件的行为。两个模拟器都可以作为_发送者_或_接收者_; 当发送者角色分配给一个模拟器时，接收者角色被分配给另一个。发送方生成具有给定类型和消息大小的随机消息，并通过ROS-IGTL-Bridge节点将其发送到接收方。进行了两组测试：</p>
<ul>
<li>
<p>数据传输延迟的定性评估。我们测量了数据传输延迟，同时以每秒30帧（fps）的速度将消息从发送器流式传输到接收器。每个变换消息包含一个表示位置和方向的线性变换。每个字符串消息的大小固定为100个字节，这对于设备的命令就足够了。对于点消息，使用多个数据大小，从每个消息1个点到每个消息10000个点，考虑不同的用例场景，包括工具跟踪，地标跟踪和点云传输。对于图像信息，我们考虑五种图像格式的二维彩色图像（RGB）：VGA（640 <em>×</em> 480像素），SVGA（800 <em>×</em> 600像素），XGA（1024 <em>×</em> 768像素），HD（1280）<em>×</em> 720像素）和全高清（1920 <em>×</em> 1080像素）。</p>
</li>
<li>
<p>高帧率数据传输的演示。此外，我们使用变换数据类型测试高帧速率数据传输，高速率为1000 fps，考虑到感应数据（例如跟踪传感器，编码器）通过局域网在两台计算机之间传输的应用。</p>
</li>
</ul>
<p>在两个测试中，数据都从ROS测试节点传输到IGTL测试服务器，反之亦然。</p>
<h3 id="33多边形数据共享的演示">3.3多边形数据共享的演示</h3>
<p>此外，使用设置演示了多边形数据的传输。对于这种定性评估，称为ROS-IGTL-Test节点的模拟器程序用作ROS节点，而3D Slicer用作外部软件，其基于MRI数据生成3D多边形数据模型。ROS-IGTL-Test节点附带ROS-IGTL-Bridge软件，用于测试人体头部的3D模型。在文件_test.launch中_设置连接参数后，ROS-IGTL-Bridge和3D Slicer中的集成Open-IGTLinkIF模块建立连接，然后交换poly数据消息。</p>
<h3 id="34结果">3.4结果</h3>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/table/T1/">表1</a>中显示了1000帧的平均和标准差延迟。有些情况下，由于数据传输延迟大于消息传输的间隔，因此未传递某些消息。在测量期间，两台计算机之间的时钟偏移保持在0.00 <em>±</em> 0.28毫秒（平均值_±_SD）。</p>
<h3 id="表格1">表格1</h3>
<p>基于1000个消息传输中的测量的变换，点，字符串和图像消息的消息传送等待时间的均值和标准偏差（SD）。</p>
<table>
<thead>
<tr>
<th style="text-align:left">消息类型</th>
<th style="text-align:center">从ROS测试节点到IGTL测试服务器（毫秒）</th>
<th style="text-align:center">从IGTL测试服务器到ROS测试节点（毫秒）</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">转变</td>
<td style="text-align:center">1.1 <em>±</em> 0.5</td>
<td style="text-align:center">1.1 <em>±</em> 0.4</td>
</tr>
<tr>
<td style="text-align:left">字符串（100字节）</td>
<td style="text-align:center">1.1 <em>±</em> 0.5</td>
<td style="text-align:center">1.2 <em>±</em> 0.4</td>
</tr>
<tr>
<td style="text-align:left">点（1分）</td>
<td style="text-align:center">1.2 <em>±</em> 0.5</td>
<td style="text-align:center">1.2 <em>±</em> 0.4</td>
</tr>
<tr>
<td style="text-align:left">点（10分）</td>
<td style="text-align:center">1.2 <em>±</em> 0.5</td>
<td style="text-align:center">1.4 <em>±</em> 0.5</td>
</tr>
<tr>
<td style="text-align:left">点（100分）</td>
<td style="text-align:center">17.2 <em>±</em> 12.6</td>
<td style="text-align:center">3.8 <em>±</em> 5.4</td>
</tr>
<tr>
<td style="text-align:left">点（1000分）</td>
<td style="text-align:center">24.8 <em>±</em> 12.3</td>
<td style="text-align:center">20.9 <em>±</em> 26.7</td>
</tr>
<tr>
<td style="text-align:left">图像（VGA）</td>
<td style="text-align:center">25.2 <em>±</em> 4.3</td>
<td style="text-align:center">23.6 <em>±</em> 3.5</td>
</tr>
<tr>
<td style="text-align:left">图像（SVGA）</td>
<td style="text-align:center">33.6 <em>±</em> 4.6 *</td>
<td style="text-align:center">33.6 <em>±</em> 3.7 *</td>
</tr>
<tr>
<td style="text-align:left">图像（XGA）</td>
<td style="text-align:center">58.8 <em>±</em> 10.6 *</td>
<td style="text-align:center">58.5 <em>±</em> 6.0 *</td>
</tr>
<tr>
<td style="text-align:left">图像（HD）</td>
<td style="text-align:center">76.3 <em>±</em> 10.5 *</td>
<td style="text-align:center">67.2 <em>±</em> 6.1 *</td>
</tr>
<tr>
<td style="text-align:left">图像（全高清）</td>
<td style="text-align:center">NA *</td>
<td style="text-align:center">144.5 <em>±</em> 12.2 *</td>
</tr>
</tbody>
</table>
<p>星号（*）表示某些消息未传递给收件人。</p>
<p>为了演示高帧率数据传输，转换消息成功地以1000 fps从ROS测试节点传输到IGTL测试服务器。当消息以另一个方向传输时，数据传输成功达到900 fps。</p>
<p>在多数据传输的附加演示中，由超过60万个点和23万个面组成的多边形数据模型成功地从ROS转移到3D切片器，反之亦然。转移的多边形数据在两种环境中都成功可视化（<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F11/">图11</a>）。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=5543207_nihms883782f11.jpg"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/bin/nihms883782f11.jpg" alt="包含图片，插图等的外部文件。对象名称为nihms883782f11.jpg" title="点击图片放大"></a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F11/">图11</a></p>
<p>交换的vtkPolyData模型从样本数据生成，该样本数据在ROS侧（左侧）的vtkRenderWindow中可视化，并在3D Slicer场景（右侧）中进行比较。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/" title="转到此页面的其他部分">去：</a></p>
<h2 id="4个用例">4个用例</h2>
<h3 id="41-igt快速原型教育平台">4.1 IGT快速原型/教育平台</h3>
<p>使用3D Slicer，ROS和Lego Mindstorms EV3对概念验证图像引导机械手系统进行了原型设计。Lego Mindstorms已被用于教育背景下的IGT相关项目[ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R22">22</a> ]以及硬件/软件测试平台[ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R23">23</a> ]。该项目的目标有两个：（1）利用可扩展的软件系统为医疗机器人创建头脑风暴工具，促进从原型到研究和商业级系统的无缝转换; （2）为学生，工程师和科学家创建一个教育工具，以学习图像引导和医疗机器人。</p>
<p>该系统模仿手术机器人，其致动其末端执行器以跟随在手术导航软件上的3D医学图像（例如，CT，MRI）上定义的物理空间中的轨迹。可以通过3D图形监控该过程。该系统由一个主动的三自由度（DoF）并行链接机械手，控制砖，ROS主计算机和运行ROS主服务器和导航软件3D Slicer的导航计算机组成。控制计算机模块（Lego EV3可编程砖块）通过无线网络上的ROS主服务器与导航软件通信。我们使用大脑的MR图像和从图像创建的2D体模执行模拟程序。通过用其末端执行器物理地触摸它们来记录预定义地标的坐标，将操纵器登记到模型中，<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F12/">图12</a>）。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=5543207_nihms883782f12.jpg"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/bin/nihms883782f12.jpg" alt="包含图片，插图等的外部文件。对象名称为nihms883782f12.jpg" title="点击图片放大"></a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F12/">图12</a></p>
<p>使用3D切片器中的点配准算法在2D样本数据上匹配定义的和物理的界标。</p>
<p>然后，使用先前定义的从3D切片机传送到控制砖的轨迹点，执行2D体模上的绘制过程（<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F13/">图13a</a>）（<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F13/">图13b</a>）。这个模拟程序表明，这个基于乐高的系统可用于构建具有研究或商业级架构的机器人系统，并模拟真实的临床工作流程，使其成为快速原型设计和教育的理想工具。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=5543207_nihms883782f13.jpg"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/bin/nihms883782f13.jpg" alt="包含图片，插图等的外部文件。对象名称为nihms883782f13.jpg" title="点击图片放大"></a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F13/">图13</a></p>
<p>使用Lego Mindstorms构建的机器人手臂遵循2D体模（a）上的轨迹，该轨迹先前在3D切片器（b）中成功进行了图像到患者注册后的计划。</p>
<h3 id="42使用kuka-lwr进行自主缝合">4.2使用KUKA LWR进行自主缝合</h3>
<p>目的是测试ROS-IGTL-Bridge在规划和引导自主手术机器人方面的可行性。使用开发的ROS-IGTL-Bridge，我们开始改进智能组织自主机器人（STAR）的软件系统，该机器人使用KUKA LWR机器人。STAR包括基于商用腹腔镜Endo360°（EndoEvolution，Raynham）工具的机器人缝合工具，使用ROS实现图形用户界面（GUI）和相机集成的自定义控制，以及实时开放式机器人控制软件（OROCOS）控制[ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R11">11</a>，<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R24">24</a> ]。虽然我们使用STAR证明了卓越的一致性和爆破压力，但是42.2％的缝线需要手动操作员调整，与手动和远程操作机器人手术相比，手术时间更长[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R7">7</a> ]。需要操作员调整的大多数错过的缝线放置是由全光相机的噪声点云数据引起的，特别是沿着深度轴，这在ROS提供的二维缝线计划中是不明显的。通过使用ROS-IGTL-Bridge升级STAR，我们能够将3D点云从STAR转移到Slicer进行点云可视化（<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F14/">图14</a>）。这可以改善缝合位置的3D规划工作流程，更大的自主性和更短的手术时间。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=5543207_nihms883782f14.jpg"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/bin/nihms883782f14.jpg" alt="包含图片，插图等的外部文件。对象名称为nihms883782f14.jpg" title="点击图片放大"></a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F14/">图14</a></p>
<p>图为猪肠道吻合术（左），当前STAR缝合计划（中），以及使用3D切片机实现3D调整的缝合计划（右图）。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/" title="转到此页面的其他部分">去：</a></p>
<h2 id="5讨论">5讨论</h2>
<p>在这项工作中，ROS-IGTL-Bridge节点被实现为通过基于OpenIGTLink协议的通用开放网络接口来扩展ROS。该接口支持在基于ROS的系统和外部医学图像计算平台之间无缝共享IGT应用中经常使用的数据，包括字符串，变换，点，多边形数据和图像。生成匹配消息类型的转换方法以确保兼容性。虽然OpenIGTLink协议为传输线性变换提供了两种不同的消息类型，即TRANSFORM和TDATA，但由于其简单性和通用性，我们选择在当前实现中使用TRANSFORM。TRANSFORM消息表示仿射变换矩阵，可以很容易地将其转换为ROS _几何msgs / Transform_消息，可用于多种用途，从工具跟踪到坐标转换。未来可以支持TDATA，因为它为工具跟踪提供了便利的功能，例如多通道跟踪的传输。可以轻松调整创建的消息和转换，或者可以另外包含新的消息类型以满足特定于任务的需求。</p>
<p>使用ROS-IGTL-Bridge进行数据传输的性能足以满足许多实时IGT应用的需求。我们的测试表明，对于字符串，点和转换消息，每秒30帧的传入和传出消息的数据传输延迟小于1.2毫秒，对于图像（VGA），小于25毫秒。另外，对于变换消息，实现了高达900fps的高帧速率数据传输。此外，成功交换了超过60万点和23万面的大型多边形数据模型。传输大于XGA格式的图像无法达到完整的30 fps。我们目前正致力于扩展OpenIGTLink协议，以提供视频压缩，以获得更好的流媒体性能。</p>
<p>使用3D Slicer和Lego Mind-storm的模拟IGT系统证明了ROS-IGTL-Bridge允许构建原型系统并在有限时间内在模拟IGT程序中验证其功能。我们能够在2016年第22届NA-MIC冬季项目周期间建立这个演示设置，这是为期一周的黑客马拉松活动，重点关注开源医学图像计算软件基础设施[ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R25">25</a> ]。ROS-IGTL-Bridge也在高档IGT设置中得到了验证，该设置由具有自主控制系统的工业级高灵巧度机器人组成。ROS-IGTL-Bridge能够传输点云数据，并将3D Slicer提供的缝合定位的高级可视化和3D规划纳入系统。</p>
<p>该研究表明，ROS-IGTL-Bridge支持ROS和图像引导软件之间的跨平台数据共享，具有足够的数据传输性能。通过将ROS中的机器人控制，运动规划和感知等特定方法与3D切片机等手术规划工具的图像处理和可视化功能组合，该桥接器有益于IGT设置。这将允许快速无缝地将图像引导软件（如3D Slicer）提供的基于图像的高级计划/导航集成到基于ROS的手术机器人系统中。通过桥接两个不同的软件平台，研究人员可以从不同研究领域开发的最先进的工程资源中受益，包括机器人和医学图像计算，以开发先进的图像引导手术机器人系统。</p>
<p>一些研究已经证明了使用OpenIGTLink桥接两个研究平台的想法。特别是，OpenIGTLink已被广泛用于桥接数据抓取软件和可视化/用户交互软件，用于医学图像计算研究。Papademetris，Tokuda _等人_使用OpenIGTLink将商业导航系统与外部研究平台（包括3D Slicer [ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R19">19</a> ]和BioImage Suite [ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R26">26</a> ]）联系起来。图像引导外科工具包（IGSTK）[ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R27">27</a> ]，一个开放的软件平台提供与跟踪和成像设备的连接，支承OpenIGTLink跟踪和成像数据输出到其它平台，比如3D切片机和MITK [ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R28">28</a>，<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R29">29</a>]。最近，Lasso _等人_使用OpenIGTLink将其数据抓取软件PLUS与外部可视化软件桥接，以流式跟踪和超声图像数据[ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R30">30</a> ]。Clarkson _等人_开发了一个基于OpenIGTLink的消息库NiftyLink，用于集成数据抓取软件和用于可视化/用户交互的最终用户应用程序[ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R15">15</a> ]。其他开源软件包，例如CustusX [ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R31">31</a> ]，IBIS [ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R32">32</a> ]和MeVisLab [ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R18">18</a> ]，也适用于OpenIGTLink，以利用社区中现有的现有软件基础架构。</p>
<p>OpenIGTLink还被用于桥接医学图像计算领域之外的平台。医疗机器人平台CISST库提供了一个OpenIGTLink桥，可将图像可视化软件集成到医疗机器人应用中[ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R33">33</a> ]。OpenIGTLink还与基于ROS的机器人系统一起用于腹腔镜介入治疗[ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R34">34</a> ]。ROS-IGTL-Bridge是对那些旨在扩展医学图像计算领域中的成功模型的先前工作的概括，并且具有促进医学机器人和医学图像计算之间的工程资源共享的潜力。</p>
<p>ROS-IGTL-Bridge的源代码，指令和测试程序在GitHub [ <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/#R35">35</a> ]中作为开源软件提供。可以使用基于CMake的构建系统Catkin编译和安装代码。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=5543207_nihms883782f7.jpg"><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/bin/nihms883782f7.jpg" alt="包含图片，插图等的外部文件。对象名称为nihms883782f7.jpg" title="点击图片放大"></a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/figure/F7/">图7</a></p>
<p>OpenIGT-Link和ROS-IGTL-Bridge的poly数据消息中的相应数据字段。考虑的属性包括_名称，点，多边形，条带，线_和_顶点_。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543207/" title="转到此页面的其他部分">去：</a></p>
<h2 id="致谢">致谢</h2>
<p>该研究部分得到了美国国立卫生研究院（R01EB020667，R01CA111288，R01EB020610，P41EB015898）的支持。材料的内容完全由作者负责，并不一定代表这些机构的官方观点。作者感谢布莱根妇女医院的陈龙泉先生的技术支持。作者还感谢Christina Choi女士用Lego Mindstorms评估快速原型制作平台。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[青岛参加全国第三次数字医学会议山东省第四次数字医学会]]></title>
        <id>https://blog.bioprinting.site/post/euxBg5taN</id>
        <link href="https://blog.bioprinting.site/post/euxBg5taN">
        </link>
        <updated>2019-05-11T23:40:29.000Z</updated>
        <content type="html"><![CDATA[<p>青岛参加全国第三次数字医学会议山东省第四次数字医学会
<img src="https://blog.bioprinting.site/post-images/1557618060095.jpg" alt="">
<img src="https://blog.bioprinting.site/post-images/1557618066949.jpg" alt="">
<img src="https://blog.bioprinting.site/post-images/1557618070147.jpg" alt="">
<img src="https://blog.bioprinting.site/post-images/1557618073115.jpg" alt="">
<img src="https://blog.bioprinting.site/post-images/1557618075946.jpg" alt="">
<img src="https://blog.bioprinting.site/post-images/1557618078264.jpg" alt=""></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[UR机械臂运动学正逆解方法]]></title>
        <id>https://blog.bioprinting.site/post/IaZRC0R5i</id>
        <link href="https://blog.bioprinting.site/post/IaZRC0R5i">
        </link>
        <updated>2019-05-10T12:43:56.000Z</updated>
        <content type="html"><![CDATA[<p>最近几个月因为工作接触到了机械臂的项目，突然对机械臂运动方法产生了兴趣，也就是如何控制机械臂的位置和姿态。借用一张网上的图片，应该是ur5的尺寸。我用到的是ur3机械臂，除了尺寸不一样，各关节结构和初始位置和ur5是一样的。</p>
<p><img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527072933030-620074166.png" alt=""></p>
<p>ur机械臂是六自由度机械臂，由D-H参数法确定它的运动学模型，连杆坐标系的建立如上图所示。我当时在这个地方的理解上走了不少弯路，后来找个一个视频，我觉得讲解地比较容易理解，可以参考一下<a href="http://v.youku.com/v_show/id_XMzIwNDg4MDA0.html">Denavit-Hartenberg参数视频详解</a>。ur机械臂DH参数表如下，</p>
<p><img src="https://blog.bioprinting.site/post-images/1557492344029.jpg" alt=""></p>
<p>由此可以建立坐标系i在坐标系i-1的齐次变换矩阵，注意每次不管平移还是旋转是相对于当前的运动坐标系变换，矩阵右乘</p>
<p><img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527074816023-1520605604.png" alt=""><img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527074843571-1120839507.png" alt=""></p>
<p>那么把DH参数代入就可以得到所有相邻坐标系的变换矩阵</p>
<p><img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527144154446-776504147.png" alt=""><img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527144201988-926698801.png" alt=""><img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527144208183-1283913775.png" alt=""></p>
<p><img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527144216324-2007686439.png" alt=""><img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527144222807-1848807733.png" alt=""><img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527144229274-1250526175.png" alt=""></p>
<p>所以末端坐标系6到基座固定坐标系0的变换矩阵<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527074918840-716859445.png" alt="">。那么求正解就很简单了，只要输入六个关节角度θ<sub>i</sub>，就得到末端坐标在基坐标系的变换矩阵T。ur机械臂的视教板上末端点的坐标是用六个值[x, y, z, rx, ry, rz]表示的。前三个值[x, y, z]是三维笛卡尔坐标，表示空间位置，后三个值[rx, ry, rz]是坐标旋转向量，表示空间姿态。我们得到的变换矩阵T怎么变成六值坐标[x, y, z, rx, ry, rz]呢？设</p>
<p><img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527101025758-731072248.png" alt=""></p>
<p>T的左上角的3x3矩阵是旋转矩阵，旋转矩阵和旋转向量之间可以通过罗德里格斯（Rodrigues）变换进行转换。opencv里有相应的函数调用。算法也比较简单，不用opencv的函数自己写代码也不难。T的右上角3x1就是空间位置[x, y, z]。这样有变换矩阵T得到六值坐标，完成了正解。</p>
<p>逆解相对要复杂一些，由末端的空间位置和姿态，计算可能的关节角度。逆解的方法有解析法，迭代法和几何法。其中解析法用数学推导，可以得到全部根，但是计算复杂。有的机械臂可以得到无穷解，比如7轴机械臂。而ur的6轴机械臂是有有限解的。这里推导一下ur的逆解。</p>
<p>首先计算求变换矩阵T过程其中的一些中间矩阵。</p>
<p><img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527075100349-1228823736.png" alt="">，其中c<sub>23</sub>=cos(θ<sub>2</sub>+θ<sub>3</sub>)，s<sub>23</sub>=sin(θ<sub>2</sub>+θ<sub>3</sub>)。</p>
<p><img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527075112036-542481994.png" alt=""></p>
<p><img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527075122415-1330412513.png" alt=""></p>
<p>由<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527074918840-716859445.png" alt="">得到<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527103709077-1951572752.png" alt="">。计算</p>
<p><img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527103734056-649296405.png" alt="">，<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527103755560-1796142198.png" alt="">，得到</p>
<p><img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527103843392-60682071.png" alt=""></p>
<p>等式两边矩阵的行列应该分别相等，由第三行第四列得到<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527104011790-1934345364.png" alt="">，可解得<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527104135222-239033524.png" alt="">，有两个解。这里注意写程序的时候，求解这里的反正切是用atan2()这类的函数，返回之在(-π,+π]。而反余弦的返回值在[0,π]，从而保证在2π范围每个解是唯一的。</p>
<p>由第三行第三列得<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527104310579-69361694.png" alt="">，可解得<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527104407262-1490785602.png" alt="">，两个解。由第三行第二列得到<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527104524002-339481378.png" alt="">，可解得<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527104537576-1226429631.png" alt="">。</p>
<p>接着由</p>
<p><img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527105730267-1783435906.png" alt="">，</p>
<p>计算</p>
<p><img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527104721998-1489358485.png" alt="">，得出等式左边等于</p>
<p><img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527110916911-1640633834.png" alt="">。</p>
<p>由<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527105035307-1992381215.png" alt="">，两边平方，令<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527105109353-2076276978.png" alt="">，<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527105136636-532380401.png" alt="">。</p>
<p>同样由<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527105159632-1867985633.png" alt="">，令<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527105212250-1939136089.png" alt="">，<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527105228874-2044756350.png" alt="">。</p>
<p>两式相加得到<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527105303715-763704756.png" alt="">，则<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527105325825-263636398.png" alt="">，有两个解。</p>
<p>把θ<sub>3</sub>带入<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527105430393-47325808.png" alt="">和<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527105440038-1776404602.png" alt="">，得<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527105510239-957405523.png" alt="">，<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527105522558-2130327615.png" alt="">，其中t<sub>2</sub>=tanθ<sub>2</sub>。两式消去c<sub>2</sub>，得到<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527105608722-1428977705.png" alt="">。</p>
<p>最后得到<img src="https://images2018.cnblogs.com/blog/1095344/201805/1095344-20180527110033957-1768711475.png" alt="">，从而得到θ<sub>4</sub>。</p>
<p>综合有两个解的情况，ur机械臂逆解总共由2x2x2=8组解。</p>
<p>按照上面的算法，用python写了两个程序，一个正解一个逆解验证一下。工作手边是ur3的机械臂，上面的图和表都是ur5的，换成ur3的参数。正解算出来都没有问题，可以和实际机械臂的空间位姿对应。可是逆解算出来8组值，好像只有四组值是对的。一直还没理解到底是怎么回事，仔细检查了算法和程序好像都没有错阿，不知道是哪里出了问题。网上也没有找到答案，如果哪位大神知道，望不吝赐教！</p>
]]></content>
    </entry>
</feed>